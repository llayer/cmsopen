{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pediatric-force",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.20/06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selection\n",
    "import weights\n",
    "import btag\n",
    "import root_pandas\n",
    "import importlib\n",
    "import jetmet\n",
    "import test_weights\n",
    "import object_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sorted-future",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: T_TuneZ2_s isData: False isTT: True corrLevel cent invert_btag False\n",
      "(30, 10) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(selection)\n",
    "importlib.reload(jetmet)\n",
    "importlib.reload(test_weights)\n",
    "importlib.reload(object_selection)\n",
    "path = \"/eos/user/l/llayer/opendata_files/preselection_merged/\" + \"T_TuneZ2_s\" + \".root\"\n",
    "df, jet, tau, met, cut_flow = selection.event_selection(path, isData = False, isTT = True  )#, corrLevel = \"centJER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lined-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot_methods\n",
    "from coffea.analysis_objects import JaggedCandidateArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "controlled-wilderness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>pz</th>\n",
       "      <th>e</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>53.386703</td>\n",
       "      <td>13.169377</td>\n",
       "      <td>51.736904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.386703</td>\n",
       "      <td>53.386703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>37.015484</td>\n",
       "      <td>13.813532</td>\n",
       "      <td>-34.341408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.015484</td>\n",
       "      <td>37.015484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>116.506561</td>\n",
       "      <td>54.449005</td>\n",
       "      <td>-103.000404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.506561</td>\n",
       "      <td>116.506561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>52.724148</td>\n",
       "      <td>-45.491230</td>\n",
       "      <td>-26.653028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.724148</td>\n",
       "      <td>52.724148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>324.515289</td>\n",
       "      <td>314.713928</td>\n",
       "      <td>79.153648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.515289</td>\n",
       "      <td>324.515289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>127.260880</td>\n",
       "      <td>12.007481</td>\n",
       "      <td>126.693146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.260880</td>\n",
       "      <td>127.260880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>21.658754</td>\n",
       "      <td>21.551687</td>\n",
       "      <td>-2.150911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.658754</td>\n",
       "      <td>21.658754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>114.165321</td>\n",
       "      <td>-1.253546</td>\n",
       "      <td>114.158440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.165321</td>\n",
       "      <td>114.165321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>22.905081</td>\n",
       "      <td>-3.732536</td>\n",
       "      <td>-22.598913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.905081</td>\n",
       "      <td>22.905079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>48.891224</td>\n",
       "      <td>-48.183498</td>\n",
       "      <td>8.288689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.891224</td>\n",
       "      <td>48.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>58.048882</td>\n",
       "      <td>50.367134</td>\n",
       "      <td>-28.858694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.048882</td>\n",
       "      <td>58.048882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>42.279060</td>\n",
       "      <td>-40.457554</td>\n",
       "      <td>-12.276210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.279060</td>\n",
       "      <td>42.279060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>48.390121</td>\n",
       "      <td>41.370564</td>\n",
       "      <td>25.101395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.390121</td>\n",
       "      <td>48.390121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>41.387737</td>\n",
       "      <td>22.759224</td>\n",
       "      <td>34.568230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.387737</td>\n",
       "      <td>41.387737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>45.199810</td>\n",
       "      <td>31.399868</td>\n",
       "      <td>-32.512630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.199810</td>\n",
       "      <td>45.199810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>107.029106</td>\n",
       "      <td>93.234886</td>\n",
       "      <td>-52.559345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.029106</td>\n",
       "      <td>107.029106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>34.470093</td>\n",
       "      <td>-21.115807</td>\n",
       "      <td>-27.245369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.470093</td>\n",
       "      <td>34.470093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>20.466646</td>\n",
       "      <td>-11.132802</td>\n",
       "      <td>17.173944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.466646</td>\n",
       "      <td>20.466646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>154.285263</td>\n",
       "      <td>146.854584</td>\n",
       "      <td>-47.304054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.285263</td>\n",
       "      <td>154.285263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>153.828796</td>\n",
       "      <td>-74.694244</td>\n",
       "      <td>-134.477020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.828796</td>\n",
       "      <td>153.828796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>53.806496</td>\n",
       "      <td>-52.703968</td>\n",
       "      <td>-10.836556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.806496</td>\n",
       "      <td>53.806496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>24.258339</td>\n",
       "      <td>-6.998435</td>\n",
       "      <td>-23.226902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.258339</td>\n",
       "      <td>24.258337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pt          px          py   pz           e         met\n",
       "227    53.386703   13.169377   51.736904  0.0   53.386703   53.386703\n",
       "239    37.015484   13.813532  -34.341408  0.0   37.015484   37.015484\n",
       "255   116.506561   54.449005 -103.000404  0.0  116.506561  116.506561\n",
       "646    52.724148  -45.491230  -26.653028  0.0   52.724148   52.724148\n",
       "815   324.515289  314.713928   79.153648  0.0  324.515289  324.515289\n",
       "891   127.260880   12.007481  126.693146  0.0  127.260880  127.260880\n",
       "900    21.658754   21.551687   -2.150911  0.0   21.658754   21.658754\n",
       "918   114.165321   -1.253546  114.158440  0.0  114.165321  114.165321\n",
       "1144   22.905081   -3.732536  -22.598913  0.0   22.905081   22.905079\n",
       "1219   48.891224  -48.183498    8.288689  0.0   48.891224   48.891224\n",
       "1331   58.048882   50.367134  -28.858694  0.0   58.048882   58.048882\n",
       "1428   42.279060  -40.457554  -12.276210  0.0   42.279060   42.279060\n",
       "1429   48.390121   41.370564   25.101395  0.0   48.390121   48.390121\n",
       "1462   41.387737   22.759224   34.568230  0.0   41.387737   41.387737\n",
       "1563   45.199810   31.399868  -32.512630  0.0   45.199810   45.199810\n",
       "1690  107.029106   93.234886  -52.559345  0.0  107.029106  107.029106\n",
       "1721   34.470093  -21.115807  -27.245369  0.0   34.470093   34.470093\n",
       "1726   20.466646  -11.132802   17.173944  0.0   20.466646   20.466646\n",
       "1841  154.285263  146.854584  -47.304054  0.0  154.285263  154.285263\n",
       "1845  153.828796  -74.694244 -134.477020  0.0  153.828796  153.828796\n",
       "1846   53.806496  -52.703968  -10.836556  0.0   53.806496   53.806496\n",
       "1890   24.258339   -6.998435  -23.226902  0.0   24.258339   24.258337"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "included-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "met[\"scaled_e\"] = np.sqrt((met[\"px\"]*1.1)**2 + (met[\"py\"]*1.1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beginning-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "met[\"scaled_e2\"] = met[\"e\"]*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "gentle-foster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>pz</th>\n",
       "      <th>e</th>\n",
       "      <th>met</th>\n",
       "      <th>scaled_e</th>\n",
       "      <th>scaled_e2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>53.386703</td>\n",
       "      <td>13.169377</td>\n",
       "      <td>51.736904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.386703</td>\n",
       "      <td>53.386703</td>\n",
       "      <td>58.725372</td>\n",
       "      <td>58.725376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>37.015484</td>\n",
       "      <td>13.813532</td>\n",
       "      <td>-34.341408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.015484</td>\n",
       "      <td>37.015484</td>\n",
       "      <td>40.717033</td>\n",
       "      <td>40.717033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>116.506561</td>\n",
       "      <td>54.449005</td>\n",
       "      <td>-103.000404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.506561</td>\n",
       "      <td>116.506561</td>\n",
       "      <td>128.157211</td>\n",
       "      <td>128.157227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>52.724148</td>\n",
       "      <td>-45.491230</td>\n",
       "      <td>-26.653028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.724148</td>\n",
       "      <td>52.724148</td>\n",
       "      <td>57.996567</td>\n",
       "      <td>57.996563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>324.515289</td>\n",
       "      <td>314.713928</td>\n",
       "      <td>79.153648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.515289</td>\n",
       "      <td>324.515289</td>\n",
       "      <td>356.966797</td>\n",
       "      <td>356.966827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>127.260880</td>\n",
       "      <td>12.007481</td>\n",
       "      <td>126.693146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.260880</td>\n",
       "      <td>127.260880</td>\n",
       "      <td>139.986969</td>\n",
       "      <td>139.986969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>21.658754</td>\n",
       "      <td>21.551687</td>\n",
       "      <td>-2.150911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.658754</td>\n",
       "      <td>21.658754</td>\n",
       "      <td>23.824629</td>\n",
       "      <td>23.824631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>114.165321</td>\n",
       "      <td>-1.253546</td>\n",
       "      <td>114.158440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.165321</td>\n",
       "      <td>114.165321</td>\n",
       "      <td>125.581856</td>\n",
       "      <td>125.581856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>22.905081</td>\n",
       "      <td>-3.732536</td>\n",
       "      <td>-22.598913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.905081</td>\n",
       "      <td>22.905079</td>\n",
       "      <td>25.195587</td>\n",
       "      <td>25.195589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>48.891224</td>\n",
       "      <td>-48.183498</td>\n",
       "      <td>8.288689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.891224</td>\n",
       "      <td>48.891224</td>\n",
       "      <td>53.780350</td>\n",
       "      <td>53.780346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>58.048882</td>\n",
       "      <td>50.367134</td>\n",
       "      <td>-28.858694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.048882</td>\n",
       "      <td>58.048882</td>\n",
       "      <td>63.853771</td>\n",
       "      <td>63.853771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>42.279060</td>\n",
       "      <td>-40.457554</td>\n",
       "      <td>-12.276210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.279060</td>\n",
       "      <td>42.279060</td>\n",
       "      <td>46.506969</td>\n",
       "      <td>46.506966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>48.390121</td>\n",
       "      <td>41.370564</td>\n",
       "      <td>25.101395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.390121</td>\n",
       "      <td>48.390121</td>\n",
       "      <td>53.229130</td>\n",
       "      <td>53.229134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>41.387737</td>\n",
       "      <td>22.759224</td>\n",
       "      <td>34.568230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.387737</td>\n",
       "      <td>41.387737</td>\n",
       "      <td>45.526512</td>\n",
       "      <td>45.526512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>45.199810</td>\n",
       "      <td>31.399868</td>\n",
       "      <td>-32.512630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.199810</td>\n",
       "      <td>45.199810</td>\n",
       "      <td>49.719791</td>\n",
       "      <td>49.719791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>107.029106</td>\n",
       "      <td>93.234886</td>\n",
       "      <td>-52.559345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.029106</td>\n",
       "      <td>107.029106</td>\n",
       "      <td>117.732018</td>\n",
       "      <td>117.732018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>34.470093</td>\n",
       "      <td>-21.115807</td>\n",
       "      <td>-27.245369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.470093</td>\n",
       "      <td>34.470093</td>\n",
       "      <td>37.917103</td>\n",
       "      <td>37.917103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>20.466646</td>\n",
       "      <td>-11.132802</td>\n",
       "      <td>17.173944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.466646</td>\n",
       "      <td>20.466646</td>\n",
       "      <td>22.513313</td>\n",
       "      <td>22.513311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>154.285263</td>\n",
       "      <td>146.854584</td>\n",
       "      <td>-47.304054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.285263</td>\n",
       "      <td>154.285263</td>\n",
       "      <td>169.713791</td>\n",
       "      <td>169.713791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>153.828796</td>\n",
       "      <td>-74.694244</td>\n",
       "      <td>-134.477020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.828796</td>\n",
       "      <td>153.828796</td>\n",
       "      <td>169.211685</td>\n",
       "      <td>169.211685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>53.806496</td>\n",
       "      <td>-52.703968</td>\n",
       "      <td>-10.836556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.806496</td>\n",
       "      <td>53.806496</td>\n",
       "      <td>59.187149</td>\n",
       "      <td>59.187145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>24.258339</td>\n",
       "      <td>-6.998435</td>\n",
       "      <td>-23.226902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.258339</td>\n",
       "      <td>24.258337</td>\n",
       "      <td>26.684174</td>\n",
       "      <td>26.684174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pt          px          py   pz           e         met  \\\n",
       "227    53.386703   13.169377   51.736904  0.0   53.386703   53.386703   \n",
       "239    37.015484   13.813532  -34.341408  0.0   37.015484   37.015484   \n",
       "255   116.506561   54.449005 -103.000404  0.0  116.506561  116.506561   \n",
       "646    52.724148  -45.491230  -26.653028  0.0   52.724148   52.724148   \n",
       "815   324.515289  314.713928   79.153648  0.0  324.515289  324.515289   \n",
       "891   127.260880   12.007481  126.693146  0.0  127.260880  127.260880   \n",
       "900    21.658754   21.551687   -2.150911  0.0   21.658754   21.658754   \n",
       "918   114.165321   -1.253546  114.158440  0.0  114.165321  114.165321   \n",
       "1144   22.905081   -3.732536  -22.598913  0.0   22.905081   22.905079   \n",
       "1219   48.891224  -48.183498    8.288689  0.0   48.891224   48.891224   \n",
       "1331   58.048882   50.367134  -28.858694  0.0   58.048882   58.048882   \n",
       "1428   42.279060  -40.457554  -12.276210  0.0   42.279060   42.279060   \n",
       "1429   48.390121   41.370564   25.101395  0.0   48.390121   48.390121   \n",
       "1462   41.387737   22.759224   34.568230  0.0   41.387737   41.387737   \n",
       "1563   45.199810   31.399868  -32.512630  0.0   45.199810   45.199810   \n",
       "1690  107.029106   93.234886  -52.559345  0.0  107.029106  107.029106   \n",
       "1721   34.470093  -21.115807  -27.245369  0.0   34.470093   34.470093   \n",
       "1726   20.466646  -11.132802   17.173944  0.0   20.466646   20.466646   \n",
       "1841  154.285263  146.854584  -47.304054  0.0  154.285263  154.285263   \n",
       "1845  153.828796  -74.694244 -134.477020  0.0  153.828796  153.828796   \n",
       "1846   53.806496  -52.703968  -10.836556  0.0   53.806496   53.806496   \n",
       "1890   24.258339   -6.998435  -23.226902  0.0   24.258339   24.258337   \n",
       "\n",
       "        scaled_e   scaled_e2  \n",
       "227    58.725372   58.725376  \n",
       "239    40.717033   40.717033  \n",
       "255   128.157211  128.157227  \n",
       "646    57.996567   57.996563  \n",
       "815   356.966797  356.966827  \n",
       "891   139.986969  139.986969  \n",
       "900    23.824629   23.824631  \n",
       "918   125.581856  125.581856  \n",
       "1144   25.195587   25.195589  \n",
       "1219   53.780350   53.780346  \n",
       "1331   63.853771   63.853771  \n",
       "1428   46.506969   46.506966  \n",
       "1429   53.229130   53.229134  \n",
       "1462   45.526512   45.526512  \n",
       "1563   49.719791   49.719791  \n",
       "1690  117.732018  117.732018  \n",
       "1721   37.917103   37.917103  \n",
       "1726   22.513313   22.513311  \n",
       "1841  169.713791  169.713791  \n",
       "1845  169.211685  169.211685  \n",
       "1846   59.187149   59.187145  \n",
       "1890   26.684174   26.684174  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "continental-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_p4 = uproot_methods.classes.TLorentzVector.TLorentzVectorArray(met[\"px\"], met[\"py\"],\n",
    "                                                                   met[\"pz\"], met[\"e\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "underlying-greece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TLorentzVectorArray [TLorentzVector(13.169, 51.737, 0, 53.387) TLorentzVector(13.814, -34.341, 0, 37.015) TLorentzVector(54.449, -103, 0, 116.51) ... TLorentzVector(-74.694, -134.48, 0, 153.83) TLorentzVector(-52.704, -10.837, 0, 53.806) TLorentzVector(-6.9984, -23.227, 0, 24.258)] at 0x7f3ddeaf4dd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-period",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-kingston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upset-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['Run2011A_MultiJet', 'Run2011B_MultiJet']\n",
    "mc = ['T_TuneZ2_s', 'WJetsToLNu', 'DYJetsToLL', 'T_TuneZ2_tW', 'T_TuneZ2_t-channel',\n",
    "       'Tbar_TuneZ2_s', 'Tbar_TuneZ2_tW', 'Tbar_TuneZ2_t-channel', 'TTJets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "destroyed-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: T_TuneZ2_s isData: False isTT: False corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(30, 9) (30, 4)\n",
      "Processing: WJetsToLNu isData: False isTT: False corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(254, 9) (254, 4)\n",
      "Processing: DYJetsToLL isData: False isTT: False corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(728, 9) (728, 4)\n",
      "Processing: T_TuneZ2_tW isData: False isTT: False corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(632, 9) (632, 4)\n",
      "Processing: T_TuneZ2_t-channel isData: False isTT: False corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(251, 9) (251, 4)\n",
      "Processing: Tbar_TuneZ2_s isData: False isTT: False corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(15, 9) (15, 4)\n",
      "Processing: Tbar_TuneZ2_tW isData: False isTT: False corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(713, 9) (713, 4)\n",
      "Processing: Tbar_TuneZ2_t-channel isData: False isTT: False corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(150, 9) (150, 4)\n",
      "Processing: TTJets isData: False isTT: True corrLevel centJER invert_btag False\n",
      "SF 1.0 1.0\n",
      "(98977, 10) (98977, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/eos/home-l/llayer/cmsopen/columnar/test_weights.py:95: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights = pd.DataFrame({\"btag_weight1\" : pdata/pmc, \"btag_weight1_up\" : pdata_up/pmc,\n",
      "/eos/home-l/llayer/cmsopen/columnar/test_weights.py:96: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"btag_weight1_down\" : pdata_down/pmc})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before join 60493 73146\n",
      "after join 60493\n",
      "Processing: Run2011A_MultiJet isData: True isTT: False corrLevel cent invert_btag False\n",
      "Processing: Run2011A_MultiJet isData: True isTT: False corrLevel cent invert_btag True\n",
      "Processing: Run2011B_MultiJet isData: True isTT: False corrLevel cent invert_btag False\n",
      "Processing: Run2011B_MultiJet isData: True isTT: False corrLevel cent invert_btag True\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(selection)\n",
    "importlib.reload(jetmet)\n",
    "importlib.reload(test_weights)\n",
    "importlib.reload(object_selection)\n",
    "def event_selection():\n",
    "    \n",
    "    samples = {}\n",
    "    cut_flow = []\n",
    "    cut_flow_normed = {}\n",
    "    \n",
    "    for sample in mc + data:\n",
    "        \n",
    "        #!!!!!!! Careful with JER application before Tau?!\n",
    "        \n",
    "        if \"TTJets\" in sample: isTT = True\n",
    "        else: isTT = False\n",
    "            \n",
    "        if \"Run2011\" in sample: isData = True\n",
    "        else: isData = False\n",
    "        \n",
    "        path = \"/eos/user/l/llayer/opendata_files/preselection_merged/\" + sample + \".root\"\n",
    "        \n",
    "        if isData:\n",
    "            for inv_btag, suffix in zip([False, True], [\"\", \"_QCD\"]):\n",
    "                \n",
    "                df, _, _, ev_count = selection.event_selection(path, isData = isData, isTT = isTT, \n",
    "                                                                          invert_btag = inv_btag)\n",
    "                samples[sample + suffix] = df\n",
    "                ev_count[\"sample\"] = sample + suffix\n",
    "                cut_flow.append(ev_count)\n",
    "        else:\n",
    "            df, _, _, ev_count = selection.event_selection(path, isData = isData, isTT = isTT, corrLevel=\"centJER\")\n",
    "            samples[sample] = df\n",
    "            ev_count[\"sample\"] = sample\n",
    "            cut_flow.append(ev_count)\n",
    "\n",
    "        #print( cut_flow )        \n",
    "        \n",
    "    return samples, cut_flow\n",
    "\n",
    "samples, cut_flow = event_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "asian-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "technical-alpha",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Support for generic buffers has not been implemented.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5d2c4c007aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_yields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_flow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/eos/home-l/llayer/cmsopen/columnar/utils.py\u001b[0m in \u001b[0;36mprint_yields\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# Load df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# TO IMPLEMENT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tau_requirement_w\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mpath_or_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             raise NotImplementedError('Support for generic buffers has not '\n\u001b[0m\u001b[1;32m    356\u001b[0m                                       'been implemented.')\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Support for generic buffers has not been implemented."
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "utils.print_yields(cut_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eleven-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_samples(samples):\n",
    "    \n",
    "    # Concat and split MC in signal and background\n",
    "    new_samples = {}\n",
    "    new_samples[\"TTJets_signal\"] = samples[\"TTJets\"][samples[\"TTJets\"][\"isSignal\"] == True]\n",
    "    new_samples[\"TTJets_bkg\"] = samples[\"TTJets\"][samples[\"TTJets\"][\"isBkg\"] == True]\n",
    "    new_samples[\"WZJets\"] = pd.concat([samples['WJetsToLNu'], samples['DYJetsToLL']], axis=0)\n",
    "    new_samples[\"STJets\"] = pd.concat([samples['T_TuneZ2_s'], samples['T_TuneZ2_tW'], samples['T_TuneZ2_t-channel'], \n",
    "                              samples['Tbar_TuneZ2_s'], samples['Tbar_TuneZ2_tW'], \n",
    "                              samples['Tbar_TuneZ2_t-channel']], axis=0)\n",
    "\n",
    "    # Concat the data\n",
    "    new_samples[\"Data\"] = pd.concat([samples[\"Run2011A_MultiJet\"], samples[\"Run2011B_MultiJet\"]], axis=0)\n",
    "    new_samples[\"QCD\"] = pd.concat([samples[\"Run2011A_MultiJet_QCD\"], samples[\"Run2011B_MultiJet_QCD\"]], axis=0)\n",
    "    \n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fossil-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = rearrange_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "composed-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TTJets_signal', 'TTJets_bkg', 'WZJets', 'STJets', 'Data', 'QCD'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ambient-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-programmer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-auction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set random state\n",
      "Prepare training data\n",
      "['Jet_pt', 'Jet_px', 'Jet_py', 'Jet_pz', 'Jet_e', 'Jet_eta', 'Jet_phi', 'Jet_mass', 'Jet_csvDisc', 'Jet_flavour', 'Tau_pt', 'Tau_px', 'Tau_py', 'Tau_pz', 'Tau_charge', 'Tau_e', 'Tau_eta', 'Tau_phi', 'Tau_mass', 'MET_pt', 'MET_px', 'MET_py', 'MET_pz', 'MET_e', 'MET_met', 'event', 'run', 'luminosityBlock', 'HLT_QuadJet40_IsoPFTau40', 'HLT_QuadJet45_IsoPFTau45', 'PV_npvs', 'genEvent_tmeme', 'norm', 'norm_up', 'norm_down', 'trigger_weight', 'trigger_weight_up', 'trigger_weight_down', 'trigger_is40', 'isSignal', 'isBkg', 'btag_weight1', 'btag_weight1_up', 'btag_weight1_down', 'btag_weight2', 'btag_weight2_up', 'btag_weight2_down', 'pdf', 'pdf_up', 'pdf_down', 'h', 'ht', 'h_jet', 'ht_jet', 'chargeEta', 'met', 'mTauJet', 'mt', 'deltaPhiTauMet', 'nJets', 'aplanarity', 'sphericity', 'train_flag', 'label', 'bdt', 'weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/eos/home-l/llayer/cmsopen/columnar/ml.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['train_flag'] = np.select(cond, choice)\n",
      "/eos/home-l/llayer/cmsopen/columnar/ml.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  signal[\"label\"] = 0\n",
      "/eos/home-l/llayer/cmsopen/columnar/ml.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  signal_train[\"weights\"] = signal_train['trigger_weight'] * signal_train['btag_weight1']\n",
      "/eos/home-l/llayer/cmsopen/columnar/ml.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  signal_train[\"weights\"] = signal_train[\"weights\"] * (1. / np.mean(signal_train[\"weights\"]))\n",
      "/eos/home-l/llayer/cmsopen/columnar/ml.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  bkg_train[\"weights\"] = bkg_train['btag_weight2']\n",
      "/eos/home-l/llayer/cmsopen/columnar/ml.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  bkg_train[\"weights\"] = bkg_train[\"weights\"] * (1. / np.mean(bkg_train[\"weights\"]))\n",
      "/eos/home-l/llayer/cmsopen/columnar/ml.py:99: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  train_data = pd.concat([signal_train, bkg_train], axis=0)\n",
      "/eos/home-l/llayer/cmsopen/columnar/ml.py:100: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  test_data = pd.concat([signal_test, bkg_test], axis=0)\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_97apython3/x86_64-centos7-gcc8-opt/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ml)\n",
    "ml.train(new_samples, \".\", n_sig=5000, n_bkg=5000, ntrees=1000, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "joint-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "published-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    {\"var_name\" : \"bdt\", \"bins\" : 20, \"xlow\" : 0., \"xup\" : 1., \"xtitle\" : \"bdt\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fifteen-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTJets_signal bdt None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/eos/home-l/llayer/cmsopen/columnar/plot.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  sample['weight'] = sample['norm'] * sample['trigger_weight'] * sample['btag_weight1']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENORM TEMPLATE\n",
      "1.12869687015016 348.4666373400386 348.4666373400386\n",
      "TTJets_bkg bdt None\n",
      "WZJets bdt None\n",
      "STJets bdt None\n",
      "Data bdt None\n",
      "QCD bdt None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/eos/home-l/llayer/cmsopen/columnar/plot.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  sample['weight'] = sample['btag_weight2'] * scale_qcd\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(plot)\n",
    "plot.vars_to_histos(new_samples, variables, \"histos.root\", syst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "known-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "phantom-finder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFile**\t\thistos.root\t\n",
      " TFile*\t\thistos.root\t\n",
      "  KEY: TH1D\tTTJets_signal_bdt;1\tTTJets_signal_bdt\n",
      "  KEY: TH1D\tTTJets_bkg_bdt;1\tTTJets_bkg_bdt\n",
      "  KEY: TH1D\tWZJets_bdt;1\tWZJets_bdt\n",
      "  KEY: TH1D\tSTJets_bdt;1\tSTJets_bdt\n",
      "  KEY: TH1D\tData_bdt;1\tData_bdt\n",
      "  KEY: TH1D\tQCD_bdt;1\tQCD_bdt\n"
     ]
    }
   ],
   "source": [
    "f = ROOT.TFile(\"histos.root\")\n",
    "f.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "realistic-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "primary-prague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_bdt\n",
      "Data 3323.0\n",
      "TTJets_bkg 134.02305321634543\n",
      "WZJets 63.63409761653705\n",
      "STJets 30.263673621567058\n",
      "QCD_bdt\n",
      "QCD 2689.5053333309666\n",
      "TTJets_signal 348.46663734003823\n",
      "scale factor TTbar tau(h) QQ  0.9406445436483206 +- 0.07901935844875005\n",
      "scale factor MultiJet  1.0289237579093604 +- 0.0102381689979027\n",
      "[#1] INFO:DataHandling -- RooDataHist::adjustBinning(signal): fit range of variable x expanded to nearest bin boundaries: [0,350] --> [0,1]\n",
      "[#0] WARNING:InputArguments -- RooAbsPdf::fitTo(pdf) WARNING: a likelihood fit is requested of what appears to be weighted data.\n",
      "       While the estimated values of the parameters will always be calculated taking the weights into account,\n",
      "       there are multiple ways to estimate the errors of the parameters. You are advised to make an \n",
      "       explicit choice for the error calculation:\n",
      "           - Either provide SumW2Error(true), to calculate a sum-of-weights-corrected HESSE error matrix\n",
      "             (error will be proportional to the number of events in MC).\n",
      "           - Or provide SumW2Error(false), to return errors from original HESSE error matrix\n",
      "             (which will be proportional to the sum of the weights, i.e., a dataset with <sum of weights> events).\n",
      "           - Or provide AsymptoticError(true), to use the asymptotically correct expression\n",
      "             (for details see https://arxiv.org/abs/1911.01303).\n",
      "[#1] INFO:Minization -- RooMinimizer::optimizeConst: activating const optimization\n",
      "[#1] INFO:Minization --  The following expressions have been identified as constant and will be precalculated and cached: (signal,bkg)\n",
      " **********\n",
      " **   64 **SET PRINT           1\n",
      " **********\n",
      " **********\n",
      " **   65 **SET NOGRAD\n",
      " **********\n",
      " PARAMETER DEFINITIONS:\n",
      "    NO.   NAME         VALUE      STEP SIZE      LIMITS\n",
      "     1 c0           5.00000e-01  1.00000e-01    0.00000e+00  1.00000e+00\n",
      " **********\n",
      " **   66 **SET ERR         0.5\n",
      " **********\n",
      " **********\n",
      " **   67 **SET PRINT           1\n",
      " **********\n",
      " **********\n",
      " **   68 **SET STR           1\n",
      " **********\n",
      " NOW USING STRATEGY  1: TRY TO BALANCE SPEED AGAINST RELIABILITY\n",
      " **********\n",
      " **   69 **MIGRAD         500           1\n",
      " **********\n",
      " FIRST CALL TO USER FUNCTION AT NEW START POINT, WITH IFLAG=4.\n",
      " START MIGRAD MINIMIZATION.  STRATEGY  1.  CONVERGENCE WHEN EDM .LT. 1.00e-03\n",
      " FCN=-313.929 FROM MIGRAD    STATUS=INITIATE        4 CALLS           5 TOTAL\n",
      "                     EDM= unknown      STRATEGY= 1      NO ERROR MATRIX       \n",
      "  EXT PARAMETER               CURRENT GUESS       STEP         FIRST   \n",
      "  NO.   NAME      VALUE            ERROR          SIZE      DERIVATIVE \n",
      "   1  c0           5.00000e-01   1.00000e-01   2.01358e-01   1.27581e+03\n",
      "                               ERR DEF= 0.5\n",
      " MIGRAD MINIMIZATION HAS CONVERGED.\n",
      " MIGRAD WILL VERIFY CONVERGENCE AND ERROR MATRIX.\n",
      " COVARIANCE MATRIX CALCULATED SUCCESSFULLY\n",
      " FCN=-868.9 FROM MIGRAD    STATUS=CONVERGED      17 CALLS          18 TOTAL\n",
      "                     EDM=8.81167e-05    STRATEGY= 1      ERROR MATRIX ACCURATE \n",
      "  EXT PARAMETER                                   STEP         FIRST   \n",
      "  NO.   NAME      VALUE            ERROR          SIZE      DERIVATIVE \n",
      "   1  c0           1.05905e-01   8.89658e-03   5.80397e-04   3.24635e-01\n",
      "                               ERR DEF= 0.5\n",
      " EXTERNAL ERROR MATRIX.    NDIM=  25    NPAR=  1    ERR DEF=0.5\n",
      "  7.917e-05 \n",
      " **********\n",
      " **   70 **SET ERR         0.5\n",
      " **********\n",
      " **********\n",
      " **   71 **SET PRINT           1\n",
      " **********\n",
      " **********\n",
      " **   72 **HESSE         500\n",
      " **********\n",
      " COVARIANCE MATRIX CALCULATED SUCCESSFULLY\n",
      " FCN=-868.9 FROM HESSE     STATUS=OK              5 CALLS          23 TOTAL\n",
      "                     EDM=8.81157e-05    STRATEGY= 1      ERROR MATRIX ACCURATE \n",
      "  EXT PARAMETER                                INTERNAL      INTERNAL  \n",
      "  NO.   NAME      VALUE            ERROR       STEP SIZE       VALUE   \n",
      "   1  c0           1.05905e-01   8.89658e-03   1.16079e-04  -9.07864e-01\n",
      "                               ERR DEF= 0.5\n",
      " EXTERNAL ERROR MATRIX.    NDIM=  25    NPAR=  1    ERR DEF=0.5\n",
      "  7.917e-05 \n",
      "[#1] INFO:Minization -- RooMinimizer::optimizeConst: deactivating const optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TH1D::Sumw2>: Sum of squares of weights structure already created\n",
      "Warning in <TH1D::Sumw2>: Sum of squares of weights structure already created\n",
      "Warning in <TH1D::Sumw2>: Sum of squares of weights structure already created\n",
      "Warning in <TH1D::Sumw2>: Sum of squares of weights structure already created\n",
      "Warning in <TH1D::Sumw2>: Sum of squares of weights structure already created\n",
      "Warning in <TH1D::Sumw2>: Sum of squares of weights structure already created\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(fit)\n",
    "\n",
    "sample_names = [\"Data\", \"TTJets_bkg\", \"WZJets\", \"STJets\", \"QCD\", \"TTJets_signal\"]\n",
    "sf_tt_sig, sf_qcd = fit.fit(\"histos.root\", sample_names, \"bdt\", corr=\"centJER\")\n",
    "sfs = {}\n",
    "sfs[\"TTJets_signal\"] = sf_tt_sig\n",
    "sfs[\"QCD\"] = sf_qcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-trance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-cycling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fallen-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from coffea.lookup_tools import extractor\n",
    "ext_trig = extractor()\n",
    "\"\"\"\n",
    "ext_trig.add_weight_sets([\n",
    "    \"jet40_ * rootFilesTurnOn/TriggerEffHisto_data_match40_JETLEG.root\",\n",
    "    \"jet45_ * rootFilesTurnOn/TriggerEffHisto_data_match45_JETLEG.root\",\n",
    "    \"tau40_ * rootFilesTurnOn/TriggerEffHisto_match40_newTauID.root\",\n",
    "    \"tau45_ * rootFilesTurnOn/TriggerEffHisto_match45_newTauID.root\"\n",
    "])\n",
    "\"\"\"\n",
    "\n",
    "ext_trig.add_weight_sets([\n",
    "    \"* * data/trigger_eff.root\"\n",
    "])\n",
    "\n",
    "ext_trig.finalize()\n",
    "\n",
    "evaluator_trig = ext_trig.make_evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "grave-grove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['jet4_eff_40', 'jet4_eff_40_error', 'jet4_eff_45', 'jet4_eff_45_error', 'tau_eff_40', 'tau_eff_40_error', 'tau_eff_45', 'tau_eff_45_error'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_trig.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cathedral-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(btag)\n",
    "importlib.reload(weights)\n",
    "\n",
    "def candidates(sample, df, invert_btag = False, njets=-1):\n",
    "    \n",
    "    if \"Run2011\" in sample: isData = True\n",
    "    else: isData = False\n",
    "\n",
    "    print( \"Processing:\", sample,\"isData:\", isData, \"invert_btag:\", invert_btag)\n",
    "\n",
    "    df['nJets'] = df[\"Jet_pt\"].str.len()\n",
    "    \n",
    "    # b-tagging\n",
    "    df[\"Jet_nbtags\"] = df[\"Jet_csvDisc\"].apply( lambda x : btag.count_btags(x, njets=njets) )\n",
    "    if invert_btag:\n",
    "        df = btag.no_tag(df)\n",
    "    else:\n",
    "        df = btag.at_least_1tag(df)\n",
    "\n",
    "    # MET cut\n",
    "    df = selection.met_requirement(df)\n",
    "\n",
    "    \n",
    "    # HL features\n",
    "    #df = pd.concat([df, df.apply(lambda ev : pd.Series(hl.hlFeatures(ev, njets=njets)), axis=1)], axis=1)\n",
    "    \n",
    "\n",
    "    # MC weights\n",
    "    if not isData:\n",
    "\n",
    "        hlt_40, hlt_45 = weights.lumi()\n",
    "        total_lumi = hlt_40 + hlt_45\n",
    "        trigger_frac = hlt_40 / float(hlt_45)\n",
    "        df = pd.concat([df, df.apply(lambda ev: pd.Series(btag.eval_sf_eff(ev)), axis=1)], axis=1)\n",
    "        df[\"Jet_btag_weight1\"] = df.apply(lambda ev : btag.b_weight_method1(ev, njets=njets), axis=1)\n",
    "        #df[\"Jet_btag_weight2\"] = df.apply(lambda ev : btag.b_weight_method2(ev, njets=njets), axis=1)\n",
    "        # trigger weights\n",
    "        #df[\"trigger_weight\"] = df.apply(lambda ev : weights.trigger_weight(ev, trigger_frac), axis=1)\n",
    "        df = pd.concat([df, df.apply(lambda ev: pd.Series(weights.trigger_weight(ev, trigger_frac)), axis=1)], axis=1)\n",
    "        # normalization\n",
    "        counts_path = \"/eos/user/l/llayer/opendata_files/preselection_merged/\" + sample + \"_counts.root\"\n",
    "        total_counts = root_pandas.read_root(counts_path)\n",
    "        xsec = weights.get_xsec(sample)\n",
    "        weights.norm(df, total_counts, xsec, lumi = total_lumi)\n",
    "\n",
    "    # QCD\n",
    "    if isData & invert_btag:\n",
    "        \n",
    "        # Assume light flavour\n",
    "        def lf(nJets):\n",
    "            return np.zeros((nJets))\n",
    "        df[\"Jet_flavour\"] = df[\"nJets\"].apply(lf)\n",
    "        df = pd.concat([df, df.apply(lambda ev: pd.Series(btag.eval_sf_eff(ev)), axis=1)], axis=1)\n",
    "        df[\"btag_weight\"] = df.apply(lambda ev : btag.b_weight_method2(ev, njets=njets), axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_samples(samples):\n",
    "    \n",
    "    # Concat and split MC in signal and background\n",
    "    new_samples = {}\n",
    "    new_samples[\"TTJets_signal\"], new_samples[\"TTJets_bkg\"] = weights.classify_tt(samples[\"TTJets\"])\n",
    "    new_samples[\"WZJets\"] = pd.concat([samples['WJetsToLNu'], samples['DYJetsToLL']], axis=0)\n",
    "    new_samples[\"STJets\"] = pd.concat([samples['T_TuneZ2_s'], samples['T_TuneZ2_tW'], samples['T_TuneZ2_t-channel'], \n",
    "                              samples['Tbar_TuneZ2_s'], samples['Tbar_TuneZ2_tW'], \n",
    "                              samples['Tbar_TuneZ2_t-channel']], axis=0)\n",
    "\n",
    "    # Concat the data\n",
    "    new_samples[\"Data\"] = pd.concat([samples[\"Run2011A_MultiJet\"], samples[\"Run2011B_MultiJet\"]], axis=0)\n",
    "    new_samples[\"QCD\"] = pd.concat([samples[\"QCD_Run2011A_MultiJet\"], samples[\"QCD_Run2011B_MultiJet\"]], axis=0)\n",
    "    \n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_candidates(samples, njets = -1):\n",
    "    \n",
    "    cand_samples = {}\n",
    "    for sample in data:\n",
    "        cand_samples[sample] = candidates(sample, samples[sample], invert_btag = False, njets=njets)\n",
    "        cand_samples[\"QCD_\" + sample] = candidates(sample, samples[sample], invert_btag = True, njets=njets)\n",
    "    \n",
    "    \n",
    "    for sample in mc:\n",
    "        cand_samples[sample] = candidates(sample, samples[sample], invert_btag = False, njets=njets)   \n",
    "\n",
    "    new_samples = rearrange_samples(cand_samples)\n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = proc_candidates(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cands[\"Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from root_numpy import fill_hist\n",
    "\n",
    "def save_var(sample, name, var_name, bins = 20, xlow = 0., xup = 350):\n",
    "\n",
    "    hist = ROOT.TH1D(name + \"_\" + var_name, name + \"_\" + var_name, bins, xlow, xup)\n",
    "    hist.Sumw2()\n",
    "    \n",
    "    if name == \"Data\":\n",
    "        pass\n",
    "    elif name == \"QCD\":\n",
    "        if var_name == \"bdt\":\n",
    "            scale_qcd = 9.\n",
    "            sample = sample[sample[\"train_flag\"] == \"test\"]\n",
    "        else:\n",
    "            scale_qcd = 4.3\n",
    "        sample['weight'] = sample['btag_weight'] * scale_qcd\n",
    "    else:\n",
    "        #samples[sample]['new_trigger_weight'] = new_samples[sample].apply(lambda ev : weights.trigger_weight(ev), axis=1)\n",
    "        sample['weight'] = sample['norm'] * (1/1000) * sample['trigger_weight'] * sample['Jet_btag_weight1']\n",
    "        #print(sample, sum(samples[sample]['weight']))\n",
    "        #new_samples[sample]['btag_weight2']\n",
    "    \n",
    "    # Flatten if the column is a list\n",
    "    if \"Jet_\" in var_name:\n",
    "        series = sample[var_name].apply(pd.Series).stack().reset_index(drop=True)\n",
    "        if name != \"Data\":\n",
    "            sample['weight_stacked'] = sample.apply(lambda x : stack_weight(x[\"weight\"] ,x[\"nJets\"]), axis=1)\n",
    "            weights = sample['weight_stacked'].apply(pd.Series).stack().reset_index(drop=True)\n",
    "    else:\n",
    "        series = sample[var_name]\n",
    "        if name != \"Data\":\n",
    "            weights = sample[\"weight\"]\n",
    "    if name == \"Data\":\n",
    "        fill_hist(hist, series)\n",
    "    else:\n",
    "        fill_hist(hist, series, weights = weights)\n",
    "    #hist.Write()\n",
    "    return hist\n",
    "\n",
    "def vars_to_histos(samples, variables):\n",
    "    \n",
    "    hists = {}\n",
    "    for name, sample in samples.items():\n",
    "        for var in variables:\n",
    "            hists[name + \"_\" + var[\"var_name\"]] = save_var(sample, name, var[\"var_name\"], var[\"bins\"], var[\"xlow\"], var[\"xup\"])\n",
    "\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    {\"var_name\" : \"MET_met\", \"bins\" : 30, \"xlow\" : 0., \"xup\" : 400, \"xtitle\" : \"MET [GeV]\"}\n",
    "]\n",
    "\n",
    "hists = vars_to_histos(cands, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ROOT.TFile(\"histos_test.root\", \"RECREATE\")\n",
    "for s, hist in hists.items():\n",
    "\n",
    "    print( s, hist.Integral() )\n",
    "    hist.Write()\n",
    "    \n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(histos, fit_var, corr = \"central\"):\n",
    "        \n",
    "\n",
    "    bkg = histos['TTJets_bkg' + \"_\" + fit_var ].Clone()\n",
    "    bkg.Add(histos['WZJets' + \"_\" + fit_var ])\n",
    "    bkg.Add(histos['STJets' + \"_\" + fit_var ])\n",
    "\n",
    "    data = histos[\"Data\" + \"_\" + fit_var ].Clone()\n",
    "    data.Add(bkg, -1.)\n",
    "\n",
    "    signal = histos[\"TTJets_signal\" + \"_\" + fit_var ]\n",
    "\n",
    "    qcd = histos[\"QCD\" + \"_\" + fit_var ]\n",
    "\n",
    "    x = ROOT.RooRealVar(\"x\",\"x\",0.,350.)\n",
    "    rooSignal =  ROOT.RooDataHist(\"signal\",\"signal\",ROOT.RooArgList( x ), signal)\n",
    "    rooBkg = ROOT.RooDataHist(\"bkg\",\"bkg\", ROOT.RooArgList( x ), qcd)\n",
    "    signal_pdf = ROOT.RooHistPdf(\"signal\",\"signal\",ROOT.RooArgSet( x ), rooSignal)\n",
    "    bkg_pdf = ROOT.RooHistPdf(\"bkg\",\"bkg\",ROOT.RooArgSet( x ), rooBkg)\n",
    "\n",
    "    c0 = ROOT.RooRealVar(\"c0\",\"c0\",0.5,0.,1.)\n",
    "    pdf = ROOT.RooAddPdf(\"pdf\",\"pdf\", signal_pdf,bkg_pdf, c0)\n",
    "\n",
    "    dataFit = ROOT.RooDataHist(\"data\",\"data\",ROOT.RooArgList( x ), data);\n",
    "\n",
    "    fitResult = pdf.fitTo(dataFit)\n",
    "    #print( fitResult )\n",
    "\n",
    "    sf_tt_sig = (c0.getVal() * data.Integral()) / signal.Integral() \n",
    "    sf_tt_sig_err = (c0.getError() * data.Integral()) / signal.Integral()\n",
    "    \n",
    "    sf_qcd = ((1-c0.getVal())*data.Integral()) / qcd.Integral()\n",
    "    sf_qcd_err = (c0.getError() * data.Integral()) / qcd.Integral()\n",
    "    \n",
    "    \n",
    "    print( \"scale factor TTbar tau(h) QQ \", sf_tt_sig, \"+-\", sf_tt_sig_err )\n",
    "    print( \"scale factor MultiJet \", sf_qcd, \"+-\", sf_qcd_err )\n",
    "\n",
    "    return sf_tt_sig, sf_qcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(hists, \"MET_met\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-needle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
