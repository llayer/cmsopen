{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selection\n",
    "import weights\n",
    "import btag\n",
    "import root_pandas\n",
    "import importlib\n",
    "import jetmet\n",
    "import test_weights\n",
    "import object_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(selection)\n",
    "def event_selection():\n",
    "    \n",
    "    samples = {}\n",
    "    for sample in mc + data:\n",
    "        \n",
    "        #!!!!!!! Careful with JER application before Tau?!\n",
    "        \n",
    "        if \"TTJets\" in sample: isTT = True\n",
    "        else: isTT = False\n",
    "            \n",
    "        if \"Run2011\" in sample: isData = True\n",
    "        else: isData = False\n",
    "        \n",
    "        path = \"/eos/user/l/llayer/opendata_files/preselection_merged/\" + sample + \".root\"\n",
    "        \n",
    "        df, cut_flow = selection.event_selection(path, isData = isData, isTT = isTT)\n",
    "        \n",
    "        print( cut_flow )\n",
    "        \"\"\"\n",
    "        df.to_hdf(outpath + sample + \".h5\", \"central\", mode='w')\n",
    "                \n",
    "        if isData == False:\n",
    "            \n",
    "            for c in corrections:\n",
    "                df, cut_flow = selection.event_selection(path, isData = isData, isTT = isTT, corrLevel = c)\n",
    "                print( cut_flow )\n",
    "                df.to_hdf(outpath + sample + \".h5\", c, mode='a')  \n",
    "        \"\"\"\n",
    "        \n",
    "        samples[sample] = df\n",
    "        \n",
    "    return samples\n",
    "\n",
    "samples = event_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(btag)\n",
    "importlib.reload(weights)\n",
    "\n",
    "def candidates(sample, df, invert_btag = False, njets=-1):\n",
    "    \n",
    "    if \"Run2011\" in sample: isData = True\n",
    "    else: isData = False\n",
    "\n",
    "    print( \"Processing:\", sample,\"isData:\", isData, \"invert_btag:\", invert_btag)\n",
    "\n",
    "    df['nJets'] = df[\"Jet_pt\"].str.len()\n",
    "    \n",
    "    # b-tagging\n",
    "    df[\"Jet_nbtags\"] = df[\"Jet_csvDisc\"].apply( lambda x : btag.count_btags(x, njets=njets) )\n",
    "    if invert_btag:\n",
    "        df = btag.no_tag(df)\n",
    "    else:\n",
    "        df = btag.at_least_1tag(df)\n",
    "\n",
    "    # MET cut\n",
    "    df = selection.met_requirement(df)\n",
    "\n",
    "    \n",
    "    # HL features\n",
    "    #df = pd.concat([df, df.apply(lambda ev : pd.Series(hl.hlFeatures(ev, njets=njets)), axis=1)], axis=1)\n",
    "    \n",
    "\n",
    "    # MC weights\n",
    "    if not isData:\n",
    "\n",
    "        hlt_40, hlt_45 = weights.lumi()\n",
    "        total_lumi = hlt_40 + hlt_45\n",
    "        trigger_frac = hlt_40 / float(hlt_45)\n",
    "        df = pd.concat([df, df.apply(lambda ev: pd.Series(btag.eval_sf_eff(ev)), axis=1)], axis=1)\n",
    "        df[\"Jet_btag_weight1\"] = df.apply(lambda ev : btag.b_weight_method1(ev, njets=njets), axis=1)\n",
    "        #df[\"Jet_btag_weight2\"] = df.apply(lambda ev : btag.b_weight_method2(ev, njets=njets), axis=1)\n",
    "        # trigger weights\n",
    "        #df[\"trigger_weight\"] = df.apply(lambda ev : weights.trigger_weight(ev, trigger_frac), axis=1)\n",
    "        df = pd.concat([df, df.apply(lambda ev: pd.Series(weights.trigger_weight(ev, trigger_frac)), axis=1)], axis=1)\n",
    "        # normalization\n",
    "        counts_path = \"/eos/user/l/llayer/opendata_files/preselection_merged/\" + sample + \"_counts.root\"\n",
    "        total_counts = root_pandas.read_root(counts_path)\n",
    "        xsec = weights.get_xsec(sample)\n",
    "        weights.norm(df, total_counts, xsec, lumi = total_lumi)\n",
    "\n",
    "    # QCD\n",
    "    if isData & invert_btag:\n",
    "        \n",
    "        # Assume light flavour\n",
    "        def lf(nJets):\n",
    "            return np.zeros((nJets))\n",
    "        df[\"Jet_flavour\"] = df[\"nJets\"].apply(lf)\n",
    "        df = pd.concat([df, df.apply(lambda ev: pd.Series(btag.eval_sf_eff(ev)), axis=1)], axis=1)\n",
    "        df[\"btag_weight\"] = df.apply(lambda ev : btag.b_weight_method2(ev, njets=njets), axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_samples(samples):\n",
    "    \n",
    "    # Concat and split MC in signal and background\n",
    "    new_samples = {}\n",
    "    new_samples[\"TTJets_signal\"], new_samples[\"TTJets_bkg\"] = weights.classify_tt(samples[\"TTJets\"])\n",
    "    new_samples[\"WZJets\"] = pd.concat([samples['WJetsToLNu'], samples['DYJetsToLL']], axis=0)\n",
    "    new_samples[\"STJets\"] = pd.concat([samples['T_TuneZ2_s'], samples['T_TuneZ2_tW'], samples['T_TuneZ2_t-channel'], \n",
    "                              samples['Tbar_TuneZ2_s'], samples['Tbar_TuneZ2_tW'], \n",
    "                              samples['Tbar_TuneZ2_t-channel']], axis=0)\n",
    "\n",
    "    # Concat the data\n",
    "    new_samples[\"Data\"] = pd.concat([samples[\"Run2011A_MultiJet\"], samples[\"Run2011B_MultiJet\"]], axis=0)\n",
    "    new_samples[\"QCD\"] = pd.concat([samples[\"QCD_Run2011A_MultiJet\"], samples[\"QCD_Run2011B_MultiJet\"]], axis=0)\n",
    "    \n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_candidates(samples, njets = -1):\n",
    "    \n",
    "    cand_samples = {}\n",
    "    for sample in data:\n",
    "        cand_samples[sample] = candidates(sample, samples[sample], invert_btag = False, njets=njets)\n",
    "        cand_samples[\"QCD_\" + sample] = candidates(sample, samples[sample], invert_btag = True, njets=njets)\n",
    "    \n",
    "    \n",
    "    for sample in mc:\n",
    "        cand_samples[sample] = candidates(sample, samples[sample], invert_btag = False, njets=njets)   \n",
    "\n",
    "    new_samples = rearrange_samples(cand_samples)\n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = proc_candidates(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cands[\"Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from root_numpy import fill_hist\n",
    "\n",
    "def save_var(sample, name, var_name, bins = 20, xlow = 0., xup = 350):\n",
    "\n",
    "    hist = ROOT.TH1D(name + \"_\" + var_name, name + \"_\" + var_name, bins, xlow, xup)\n",
    "    hist.Sumw2()\n",
    "    \n",
    "    if name == \"Data\":\n",
    "        pass\n",
    "    elif name == \"QCD\":\n",
    "        if var_name == \"bdt\":\n",
    "            scale_qcd = 9.\n",
    "            sample = sample[sample[\"train_flag\"] == \"test\"]\n",
    "        else:\n",
    "            scale_qcd = 4.3\n",
    "        sample['weight'] = sample['btag_weight'] * scale_qcd\n",
    "    else:\n",
    "        #samples[sample]['new_trigger_weight'] = new_samples[sample].apply(lambda ev : weights.trigger_weight(ev), axis=1)\n",
    "        sample['weight'] = sample['norm'] * (1/1000) * sample['trigger_weight'] * sample['Jet_btag_weight1']\n",
    "        #print(sample, sum(samples[sample]['weight']))\n",
    "        #new_samples[sample]['btag_weight2']\n",
    "    \n",
    "    # Flatten if the column is a list\n",
    "    if \"Jet_\" in var_name:\n",
    "        series = sample[var_name].apply(pd.Series).stack().reset_index(drop=True)\n",
    "        if name != \"Data\":\n",
    "            sample['weight_stacked'] = sample.apply(lambda x : stack_weight(x[\"weight\"] ,x[\"nJets\"]), axis=1)\n",
    "            weights = sample['weight_stacked'].apply(pd.Series).stack().reset_index(drop=True)\n",
    "    else:\n",
    "        series = sample[var_name]\n",
    "        if name != \"Data\":\n",
    "            weights = sample[\"weight\"]\n",
    "    if name == \"Data\":\n",
    "        fill_hist(hist, series)\n",
    "    else:\n",
    "        fill_hist(hist, series, weights = weights)\n",
    "    #hist.Write()\n",
    "    return hist\n",
    "\n",
    "def vars_to_histos(samples, variables):\n",
    "    \n",
    "    hists = {}\n",
    "    for name, sample in samples.items():\n",
    "        for var in variables:\n",
    "            hists[name + \"_\" + var[\"var_name\"]] = save_var(sample, name, var[\"var_name\"], var[\"bins\"], var[\"xlow\"], var[\"xup\"])\n",
    "\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    {\"var_name\" : \"MET_met\", \"bins\" : 30, \"xlow\" : 0., \"xup\" : 400, \"xtitle\" : \"MET [GeV]\"}\n",
    "]\n",
    "\n",
    "hists = vars_to_histos(cands, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ROOT.TFile(\"histos_test.root\", \"RECREATE\")\n",
    "for s, hist in hists.items():\n",
    "\n",
    "    print( s, hist.Integral() )\n",
    "    hist.Write()\n",
    "    \n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(histos, fit_var, corr = \"central\"):\n",
    "        \n",
    "\n",
    "    bkg = histos['TTJets_bkg' + \"_\" + fit_var ].Clone()\n",
    "    bkg.Add(histos['WZJets' + \"_\" + fit_var ])\n",
    "    bkg.Add(histos['STJets' + \"_\" + fit_var ])\n",
    "\n",
    "    data = histos[\"Data\" + \"_\" + fit_var ].Clone()\n",
    "    data.Add(bkg, -1.)\n",
    "\n",
    "    signal = histos[\"TTJets_signal\" + \"_\" + fit_var ]\n",
    "\n",
    "    qcd = histos[\"QCD\" + \"_\" + fit_var ]\n",
    "\n",
    "    x = ROOT.RooRealVar(\"x\",\"x\",0.,350.)\n",
    "    rooSignal =  ROOT.RooDataHist(\"signal\",\"signal\",ROOT.RooArgList( x ), signal)\n",
    "    rooBkg = ROOT.RooDataHist(\"bkg\",\"bkg\", ROOT.RooArgList( x ), qcd)\n",
    "    signal_pdf = ROOT.RooHistPdf(\"signal\",\"signal\",ROOT.RooArgSet( x ), rooSignal)\n",
    "    bkg_pdf = ROOT.RooHistPdf(\"bkg\",\"bkg\",ROOT.RooArgSet( x ), rooBkg)\n",
    "\n",
    "    c0 = ROOT.RooRealVar(\"c0\",\"c0\",0.5,0.,1.)\n",
    "    pdf = ROOT.RooAddPdf(\"pdf\",\"pdf\", signal_pdf,bkg_pdf, c0)\n",
    "\n",
    "    dataFit = ROOT.RooDataHist(\"data\",\"data\",ROOT.RooArgList( x ), data);\n",
    "\n",
    "    fitResult = pdf.fitTo(dataFit)\n",
    "    #print( fitResult )\n",
    "\n",
    "    sf_tt_sig = (c0.getVal() * data.Integral()) / signal.Integral() \n",
    "    sf_tt_sig_err = (c0.getError() * data.Integral()) / signal.Integral()\n",
    "    \n",
    "    sf_qcd = ((1-c0.getVal())*data.Integral()) / qcd.Integral()\n",
    "    sf_qcd_err = (c0.getError() * data.Integral()) / qcd.Integral()\n",
    "    \n",
    "    \n",
    "    print( \"scale factor TTbar tau(h) QQ \", sf_tt_sig, \"+-\", sf_tt_sig_err )\n",
    "    print( \"scale factor MultiJet \", sf_qcd, \"+-\", sf_qcd_err )\n",
    "\n",
    "    return sf_tt_sig, sf_qcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(hists, \"MET_met\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-institute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
