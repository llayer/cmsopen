{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be88becb",
   "metadata": {},
   "source": [
    "# HEP-like INFERNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2112569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccab4c6",
   "metadata": {},
   "source": [
    "## 1. Interpolation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59901631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_inferno.inference import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "408e1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_function(x, smoothRegion = 1):\n",
    "    \n",
    "    mask_smooth_region = torch.abs(x) > smoothRegion\n",
    "    xnorm = x / smoothRegion\n",
    "    xnorm2 = xnorm*xnorm\n",
    "    \n",
    "    in_smooth = 0.125 * xnorm * (xnorm2 * (3.*xnorm2 - 10.) + 15)\n",
    "    out_smooth = torch.where(x>0, torch.ones(x.shape), -1*torch.ones(x.shape))\n",
    "    \n",
    "    return torch.where(mask_smooth_region, out_smooth, in_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a0888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f96dfae5780>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test \n",
    "x = torch.linspace(-2, 2, 1000)\n",
    "y = smooth_function(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f3c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph(x, nominal, lo, hi):\n",
    "        \n",
    "    dhi = hi - nominal\n",
    "    dlo = lo - nominal\n",
    "    #print(dhi)\n",
    "    #print(dlo)\n",
    "    diff_h = dhi - dlo\n",
    "    sum_h = dhi + dlo\n",
    "    alpha = x * 0.5 * ((diff_h) + (sum_h)*smooth_function(x))\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f09a91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "hi, y,_ = plt.hist(np.random.normal(loc=4, scale=2.0, size=10000), range=(0,10), alpha=0.5, density=True)\n",
    "nominal, y,_ = plt.hist(np.random.normal(loc=5, scale=2.0, size=10000), range=(0,10), alpha=0.5, density=True)\n",
    "lo, y,_ = plt.hist(np.random.normal(loc=6, scale=2.0, size=10000), range=(0,10), alpha=0.5, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca540cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_t = torch.Tensor(hi)\n",
    "nominal_t = torch.Tensor(nominal)\n",
    "lo_t = torch.Tensor(lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27987f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_stacked = torch.stack([hi_t, hi_t, hi_t])\n",
    "lo_stacked = torch.stack([lo_t, lo_t, lo_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3729520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_stacked = nominal_t.unsqueeze(0).repeat(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d321d5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f60d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.Tensor(np.array([-1, 0., 1.])).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8171de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_stacked = nominal_t.unsqueeze(0).repeat(x.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f226a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_stacked = nominal_t.unsqueeze(0).repeat(alpha.shape[0], 1)\n",
    "morphed = morph(alpha, nominal_stacked, lo_stacked, hi_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b16f1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_t += morphed.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84ec814a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0321, 0.0707, 0.1145, 0.1353, 0.1508, 0.1610, 0.1500, 0.0944, 0.0614,\n",
       "        0.0297])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bc95a",
   "metadata": {},
   "source": [
    "## 2. constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87df4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(theta, std):\n",
    "    return 1 + theta*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba930663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal(theta, kappa):\n",
    "    return torch.exp(theta * torch.log(kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b9b8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logKappaForX(x, logkappa_lo, logkappa_hi):\n",
    "    \n",
    "    logKhi =  logkappa_hi\n",
    "    logKlo = -logkappa_lo\n",
    "\n",
    "    kappa = torch.where(x >= 0, logkappa_hi, -logkappa_lo)\n",
    "    \n",
    "    avg = 0.5*(logKhi + logKlo) \n",
    "    halfdiff = 0.5*(logKhi - logKlo)\n",
    "    twox = x+x \n",
    "    twox2 = twox*twox\n",
    "    alpha = 0.125 * twox * (twox2 * (3*twox2 - 10.) + 15.)\n",
    "    ret = avg + alpha*halfdiff\n",
    "    return torch.where(torch.abs(x) >= 0.5, kappa, ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4133e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.Tensor([1.0])\n",
    "kappa = torch.Tensor([1.1])\n",
    "std = torch.Tensor([0.1])\n",
    "kappa_lo = torch.Tensor([0.9])\n",
    "kappa_hi = torch.Tensor([1.2])\n",
    "kappa_std_avg = (abs(kappa_hi-1)+abs(1-kappa_lo))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e44bb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f96d782c898>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test \n",
    "x = torch.linspace(-2, 2, 1000)\n",
    "y_logKappaForX = logKappaForX(x, kappa_lo, kappa_hi)\n",
    "plt.plot(x, y_logKappaForX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f88458cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asym_log_normal(theta, kappaLo, kappaHi):\n",
    "    return torch.exp(theta * logKappaForX(theta, torch.log(kappaLo), torch.log(kappaHi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46583526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1500])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa_std_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4373dcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f96d7815cf8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABCaUlEQVR4nO3dd1zV1f/A8ddhiaKI4B4s9wAFUVNETJxllpWllavMtGGmZTa+Ns1y5GyZillqO7PMrYgoblFzLwRcCAqK7Mv5/XGJHw4E8V4u4/18PHjEvZ/P/Zz35yO8+3A+532O0lojhBCi5LOydABCCCFMQxK6EEKUEpLQhRCilJCELoQQpYQkdCGEKCVsLNVw1apVtbu7u6WaF0KIEmn37t1xWutqt9tmsYTu7u7Orl27LNW8EEKUSEqpM3ltky4XIYQoJSShCyFEKSEJXQghSgmL9aHfTkZGBjExMaSmplo6FFEM2dvbU7duXWxtbS0dihDFUrFK6DExMVSqVAl3d3eUUpYORxQjWmvi4+OJiYnBw8PD0uEIUSwVqy6X1NRUXFxcJJmLWyilcHFxkb/ehLiDYpXQAUnmIk/ysyHEnRW7hC6EEKWV1pqv933N0ctHzXJ8Seg3UUoxduzYnNdTp07l/fffL9IYOnfuLEVXQpQyhiwDH4R/wBcRX7Dy9EqztCEJ/SblypXj999/Jy4urlCfz8zMNHFEQoiSLs2QxuubXue347/xvNfzvOr7qlnaKVajXIoDGxsbhg8fzvTp05k4ceIN2yIjI3n22WeJi4ujWrVqBAcH4+rqypAhQ7C3t2fv3r34+/tz+fJlypcvz969e4mNjWXBggUsWrSI8PBw2rVrx8KFCwEYOXIkO3fuJCUlhccff5wPPvjAAmcshDCnpPQkXt34Kjsu7ODNNm/yTLNnzNZWsU3oH/x1kEPnrpr0mM1qO/LeQ83z3e+ll17C29ubcePG3fD+K6+8wuDBgxk8eDALFixg1KhRLFu2DDAOudy6dSvW1tYMGTKEK1euEB4ezvLly+nTpw9btmxh3rx5tGnThoiICFq1asXEiRNxdnbGYDAQFBTE/v378fb2Nuk5CyEsJz4lnpHrRnL8ynEmBUyit2dvs7YnXS634ejoyKBBg5g1a9YN74eHh/PUU08BMHDgQMLCwnK29evXD2tr65zXDz30EEopvLy8qFGjBl5eXlhZWdG8eXMiIyMB+Pnnn/H19cXHx4eDBw9y6NAh85+cEKJIRF+LZtDKQZxOPM2sLrPMnsyhGN+hF+RO2pxGjx6Nr68vQ4cOLdD+Dg4ON7wuV64cAFZWVjnf//c6MzOT06dPM3XqVHbu3EmVKlUYMmSIjLEWopQ4FH+IF9e9SKbO5Nvu39KqeqsiaVfu0PPg7OzME088wfz583Pe69ChAz/++CMAixcvJiAgoNDHv3r1Kg4ODlSuXJmLFy+ycqV5nnoLIYpW+Llwhq4aip21HYt6LSqyZA6S0O9o7NixN4x2mT17NsHBwXh7e/P9998zc+bMQh+7ZcuW+Pj40KRJE5566in8/f1NEbIQwoJWnFrBi+tfpE6lOvzwwA94VvYs0vaV1vrOOyi1AOgNxGqtW9xhvzZAONBfa/1rfg37+fnpm8daHz58mKZNmxYkblFGyc+IKK6+O/gdU3dNxa+GHzO7zMTRztEs7Sildmut/W63rSB36AuBnvk0YA18Bqy56+iEEKIEy9JZTN05lam7ptLNrRtfd/vabMk8P/k+FNVahyql3PPZ7RXgN6CNKYISQoiSIMOQwbtb3uWf0//Qv3F/xrcdj7WVdf4fNJN7HuWilKoD9AXuJ5+ErpQaDgwHcHV1vdemhRDCYq5nXGf0xtFsO7+NV31f5bkWz1l8AjlTPBSdAbyptc7Kb0et9VyttZ/W2q9atdsuWi2EEMVeXEocQ1cNZeeFnXzk/xHDvIZZPJmDacah+wE/Zp9MVeABpVSm1nqZCY4thBDFypmrZ3hh7QtcTr3MrC6z6FS3k6VDynHPCV1rnbN8jFJqIfC3JHMhRGn0b9y/vLjuRTSaed3n4V2teE3VkW+Xi1JqKcbhiI2VUjFKqeeUUiOUUiPMH17Rq1ixosmPOWTIEOrUqUNaWhoAcXFxuLu7m7ydO1m4cCEvv/xykbYpRGkSEh3Cs6ufpYJtBb7v9X2xS+ZQsFEuAwp6MK31kHuKphSztrZmwYIFjBw58q4/m5mZiY1NsZ2lQYhS78cjPzJpxySaODfhi6AvqFq+qqVDui2pFC2AiIgI7rvvPry9venbty9XrlwBYOfOnXh7e9OqVSveeOMNWrTIs+6K0aNHM3369FvmS9da53zWy8uLn376CYCQkBACAgLo06cPzZo1IyQkhMDAQB5++GE8PT0ZP348ixcvpm3btnh5eXHy5EkA/vrrL9q1a4ePjw9du3bl4sWLZroqQpR+WTqLabumMXH7RALqBBDcI7jYJnMoxpNzsXI8XDhg2mPW9IJen971xwYNGsTs2bMJDAxkwoQJfPDBB8yYMYOhQ4fy7bff0r59e8aPH3/HY7i6utKxY0e+//57HnrooZz3f//9dyIiIti3bx9xcXG0adOGTp2MD1n27NnDv//+i4eHByEhIezbt4/Dhw/j7OyMp6cnw4YNY8eOHcycOZPZs2czY8YMOnbsyLZt21BKMW/ePCZPnsy0adPu+pyFKOvSDGm8vflt1pxZw5ONn2R82/HYWBXflAlyh56vxMREEhISCAwMBGDw4MGEhoaSkJDAtWvXaN++PUDOtLp38tZbbzFlyhSysv5/hGdYWBgDBgzA2tqaGjVqEBgYyM6dOwFo27YtHh45z5xp06YNtWrVoly5ctSvX5/u3bsD4OXllTMlb0xMDD169MDLy4spU6Zw8OBBk1wHIcqShNQEnl/zPGvOrGFM6zG80+6dYp/MoTjfoRfiTrq4GDp0KHv37qV27dr8888/Oe83bNiQVq1a8fPPPxfoOHlNyQs3Tsv735S8YFyEY8yYMfTp04eQkJAiXw9ViJIu+mo0L65/kXNJ55gSOIWe7nec+aRYkTv0fFSuXJkqVaqwefNmAL7//nsCAwNxcnKiUqVKbN++HSBnWl2A4OBgIiIibkjm/3nnnXeYOnVqzuuAgAB++uknDAYDly5dIjQ0lLZt2xY63sTEROrUqQPAd999V+jjCFEW7b+0n2dWPsOVtCt82/3bEpXMoTjfoVtIcnIydevWzXk9ZswYvvvuO0aMGEFycjKenp4EBwcDMH/+fJ5//nmsrKwIDAykcuXK+R6/efPm+Pr6smfPHgD69u1LeHg4LVu2RCnF5MmTqVmzJkeOHClU/O+//z79+vWjSpUqdOnShdOnTxfqOEKUNeuj1jM+dDxVy1fly65f4lHZI/8PFTP5Tp9rLqVh+tykpKScceuffvop58+fv6c50kX+StrPiCgZFh9ezGc7PsOrqhezuszCpbyLpUPK052mz5U79HuwYsUKJk2aRGZmJm5ubixcuNDSIQkh7oIhy8DUXVP54fAPdKnXhU87fUp5m/KWDqvQJKHfgyeffJInn3zS0mEIIQohOSOZt8PeZn3Uep5u+jRv+L1h0alvTUESuhCizIlNjuXl9S9z5PIRxrUZx8BmAy0dkklIQhdClCmH4w/z8oaXuZZ+jdldZhNYL9DSIZmMDFsUQpQZG6M2MnjVYBSK73t9X6qSOcgduhCiDNBas+jQIqbtmkYzl2bM7jKbahVK3yI7cod+G8uWLUMpVeix4EXFXFPiKqUYO3ZszuupU6cWecVp586duXlYqxCFkZGVwYfbPmTqrql0detKcM9gyybzK5GQmmiWQ0tCv42lS5fSsWNHli5daulQLKJcuXL8/vvvxMXFFerzN88oKYSlXE2/yovrXuTXY78yzGsYUwOnWm5YYpYBwr+AL9vDholmaUIS+k2SkpIICwtj/vz5N5Tznz9/nk6dOtGqVStatGjB5s2bWbBgAaNHj87Z59tvv+W1114jMjKSJk2aMGTIEBo1asTTTz/NunXr8Pf3p2HDhuzYsQMwVnUOHjyYgIAA3Nzc+P333xk3bhxeXl707NmTjIyMQp3D559/TosWLWjRogUzZszIef+jjz6icePGdOzYkQEDBtwwBUFuNjY2DB8+nOnTp9+yLTIyki5duuDt7U1QUBBRUVGAcRGPESNG0K5dO8aNG8eQIUMYOXIk9913H56enoSEhPDss8/StGlThgwZknO8kSNH4ufnR/PmzXnvvfcKdb5C3E70tWie+ecZdl3cxYcdPuRV31exUhZKeRcPwfzusPptcO8IHV4xSzPFtg/9sx2fceSyabs8mjg34c22b95xnz///JOePXvSqFEjXFxc2L17N61bt2bJkiX06NGDd955B4PBQHJyMj4+PkycOJEpU6Zga2tLcHAw33zzDQAnTpzgl19+YcGCBbRp04YlS5YQFhbG8uXL+eSTT1i2bBkAJ0+eZOPGjRw6dIj27dvz22+/MXnyZPr27cuKFSt45JFH7uocd+/eTXBwMNu3b0drTbt27QgMDCQzM5PffvuNffv2kZGRga+vL61bt87zOC+99BLe3t6MGzfuhvdfeeUVBg8ezODBg1mwYAGjRo3KOZeYmBi2bt2KtbU1Q4YM4cqVK4SHh7N8+XL69OnDli1bmDdvHm3atCEiIoJWrVoxceJEnJ2dMRgMBAUFsX//fry9i99KMKJk2Ru7l1c3vEoWWcztNpc2NdtYJpDMNNj8OWyeBvaO8Og88HoczLSgdEGWoFuglIpVSv2bx/aHlVL7lVIRSqldSqmOpg+z6CxdupT+/fsD0L9//5xulzZt2hAcHMz777/PgQMHqFSpEhUrVqRLly78/fffHDlyhIyMDLy8vADw8PDAy8sLKysrmjdvTlBQEEqpG6a6BejVqxe2trZ4eXlhMBjo2dM4GdDN+xVUWFgYffv2xcHBgYoVK/Loo4+yefNmtmzZwsMPP4y9vT2VKlW6YU7223F0dGTQoEHMmjXrhvfDw8NzpgoeOHAgYWFhOdv69euHtfX/F2Y89NBDOedco0aNG67Hf+f2888/4+vri4+PDwcPHuTQoUN3fc5C5Pb3qb95bvVzOJZzZPEDiy2XzKN3wDeBsOlTaP4IvLQDvPuZLZlDwe7QFwJzgEV5bF8PLNdaa6WUN/Az0OReA8vvTtocLl++zIYNGzhw4ABKKQwGA0oppkyZQqdOnQgNDWXFihUMGTKEMWPGMGjQIIYNG8Ynn3xCkyZNGDp0aM6xCjLVbe79rKyssLW1RWX/Y9+8n7lER0fnJPcRI0YwYsT/LxU7evRofH19bzivO8lrut/c5//f68zMTE6fPs3UqVPZuXMnVapUYciQIaSmpt7rKYkyKktn8UXEF8zdb7wjn955OpXL5T9hnsmlJsL6D2HnfHCsA0/9DI16FEnT+d6ha61Dgct32J6k/3+GLwfAMrN9mcCvv/7KwIEDOXPmDJGRkURHR+Ph4cHmzZs5c+YMNWrU4Pnnn2fYsGE5syW2a9eO6OholixZwoABBV5+1WwCAgJYtmwZycnJXL9+nT/++IOAgAD8/f3566+/SE1NJSkpib///huAevXqERERQURExA3JHMDZ2ZknnniC+fPn57zXoUOHnGcLixcvJiAgoNCxXr16FQcHBypXrszFixdZuXJloY8lyrbkjGTGhIxh7v65PNrwUb7p+o1lkvnhv+GLdsZk3m4EvLTtlmQeezWVhOR0szRvkj50pVRfYBJQHXjQFMe0hKVLl/Lmmzf+ZfDYY4+xdOlS7rvvvpy+8ooVK7Jo0f//wfLEE08QERFBlSpVzBLXhAkT8PPzo0+fPrdsW7hwYU4fNsC2bdsYMmRIzpzqw4YNw8fHB4A+ffrg7e2d0/1RkOl+x44dy5w5c3Jez549m6FDhzJlyhSqVauWM5VwYbRs2RIfHx+aNGlCvXr18Pf3L/SxRNl1NuksozaM4kTCCca3Hc9TTZ7K+Uu3yFw9B/+8AUf+hhot4MnFUPfGZ1QJyel8tekk322N5Jl2brzbu5np49Ba5/sFuAP/FmC/TsC6O2wfDuwCdrm6uuqbHTp06Jb3SoIHH3xQr1u3ztJh5OvatWtaa62vX7+uW7durXfv3m3hiO5eSf0ZEeax68IuHbA0QLdf0l5vidlS9AEYDFpvn6v1xDpaf1Rd682fa52ZfsMuSakZevb6Y7rFe6u0+/i/9egf9+ozcdcL3SSwS+eRY006ykVrHaqU8lRKVdVa3zKIWWs9F5gLxvnQTdm2JSQkJNC2bVtatmxJUFCQpcPJ1/Dhwzl06BCpqakMHjwYX19fS4ckRKH9duw3Pt7+MXUr1mV2l9m4V3Yv2gBiD8PyURCzAzw7Q+/p4OyZszkt08DS7VHM2XiCuKR0ujWrwdjujWhS09FsId1zQldKNQBOaq21UsoXKAfE33NkJYCTkxPHjh2zdBgFtmTJEkuHIMQ9y8zKZOquqSw+vBj/2v5MDpyMo535kuQtMlJh81QImwHlKkHfb8D7yZzRK4Ysze97Ypix7jhnE1Jo7+nC3EGN8XU1T5dsbvkmdKXUUqAzUFUpFQO8B9gCaK2/Bh4DBimlMoAU4MnsPwsKRWtd9P1fokS4hx8rUUokpiXyxqY3CD8fzsBmAxnTegw2VkVYThMZBn+9CvEnwLs/9JgIDlUB48/nqn8vMG3tMU7EJuFdtzKfPuZFxwZViyyn5XsltNZ3HLqhtf4M+MwUwdjb2xMfH4+Li4skdXEDrTXx8fHY29tbOhRhIacSTzFqwyjOJp3lww4f0rdh36JrPPkyrJ0Ae78HJzd45ndoYOxm1VoTdiKOKauPsj8mkfrVHPjqaV96tqhZ5HmsWFWK1q1bl5iYGC5dumTpUEQxZG9vf8MC3qLsCDsbxrhN47C1tmVBjwX4VPcpmoa1hoO/w8o3jUnd/1UIHA92FQDYE3WFKauOEn4qnjpO5ZnyuDd9fepgY22ZKQaKVUK3tbXFw6PkrbQthDAPnT3t7ee7P6ehU0Nmd5lNrYq1iqbxy6dgxetwcj3U9jHeldcyTktx9MI1pq45ytpDF3FxsOO9h5rxVDtXytlYdgm7YpXQhRDiP2mGND4K/4g/T/5JN7dufOz/MRVsK5i/4cw02DITQqeCtR30/AzaDANrG6Lik5m+7hjLIs5S0c6G17s3Yqi/Bw7likcqLR5RCCFELheuX2D0xtEcjD/IyJYjGdFyRNHMlHhqE6wYC/HHoXlf6DEJHGsRezWV2RuO8OPOKKyUYngnT0YG1sepgp35Y7oLktCFEMXKrgu7GLtpLGmGNGbeP5Murl3M32hSLKx5F/b/BFXc4enfoGFXEpMz+HrVEYK3nCbToHmyTT1GBTWkhmPxfDgvCV0IUSxorVl6ZClTdk6hbqW6zLx/Jp5Onvl/8F5kZcGehbDufUhPhk7jIGAMydqW4I0n+HrTSZLSMnm4ZW1e69YINxeH/I5oUZLQhRAWl7u/PLBuIJMCJlHJrpJ5G71wAP5+DWJ2gnsAPPg5aVXq8+OOaGZvOEFcUhpdm1ZnbPfGNK1VhIVL90ASuhDConL3l49oOYKRLUeat7887RqEfArbvoLyVaDvXAwt+vFHxDlmLNhEzJUU2nk4881AX1q7OZsvDjOQhC6EsJjc/eUz7p9BkKsZ50TS2jgb4so34epZaD0UHfQeq0+lMW3mZo7HJtGijiMT+3rRqWHRVXeakiR0IUSRK/L+8itnYOU4OLbKOL1tv4VsSfNkcvAh9kUn4FnNgS+f9qWXBao7TUkSuhCiSBVpf3lmGmydbRxTrqyg+0Qi6vRnyuoTbDmxnTpO5Zn8uDePWrC605QkoQshikzu/vIXvF/gxVYvmq+//Pg641355ZPQtA+n/N7l0y3XWLN8Oy4Odkzo3Yyn77N8dacpSUIXQhSJHed38EboG6Rmppq3vzwhCla9Zewvd2lA7MNL+fRYbf6Yd4KKdjaM6daIZzt6ULGYVHeaUuk7IyFEsaK1JvhgMDP3zMTN0Y3gHsHm6S/PTIOtsyB0GihFUsd3mHatKz/8egErdZ7hAZ6MCKxPFYfiVd1pSpLQhRBmcy39Gv/b8j/WR62nu1t3PvT/EAdbMxTnHF8HK9+Ay6fIaPQQ8xyGMWtTKumGC8bqzi4NqVm5eFZ3mpIkdCGEWRy/cpzXQl4j5loMb/i9wcBmA00/guTKGVj9Nhz5myzn+qzwnsM7+6tzNfU6fVrWZky3RrhXLd7VnaYkCV0IYXIrTq3gg/APcLB1YH6P+bSu0dq0DWSkGkevbJ6GVoq9DUfx8ukOnNuRRVATZ8Z2b0yz2iWjutOUJKELIUwmw5DB1F1TWXJkCb7VfZkaOJVqFaqZtpHja7NHr5wiplZ3Xr3yOLsPVKSthxOznmmMn3vJqu40pYKsKboA6A3Eaq1b3Gb708CbgAKuASO11vtMHagQoni7eP0iYzeNZd+lfQxqNojRrUdja2VrugZyda9cr+jOxxU+YOnphjSv7cjCvo0JbFStRBcFmUJB7tAXAnOARXlsPw0Eaq2vKKV6AXOBdqYJTwhREuQekjg1cCo93HuY7uAZKbBlFoR9jkErFjsM4eO4+6lb1YkvnmpMrxY1sbIq24n8PwVZJDpUKeV+h+1bc73cBsiij0KUEbmHJLo7ujO9x3TTDUnUGg4vh9XvQmIU28sH8NqVfmibunz0WEMe861bKqo7TcnUfejPASvz2qiUGg4MB3B1dTVx00KIopR7SGIP9x580OED0w1JvHjQOIlW5GZi7Dx4I/0djlr78OKD9XnmPjfsbUtPdacpmSyhK6Xux5jQO+a1j9Z6LsYuGfz8/LSp2hZCFK1D8YcYGzKWC9cvmHZIYvJlCJmE3jmPFOXAZxlDWKZ78GyXhnwbUDqrO03JJFdHKeUNzAN6aa3jTXFMIUTxo7Xmp6M/MXnnZFzKuxDcM5hW1Vvd+4GzDLA7mKz1EyE1gSWGIGbpJ3i4Qws2dm6Acymu7jSle07oSilX4HdgoNb62L2HJIQojpLSk/gg/ANWRa4ioE4An3T8BCd7p3s/cOQWDP+Mwzr2X3bpZryfOY6WrTvyZ1ADalUuf+/HL0MKMmxxKdAZqKqUigHeA2wBtNZfAxMAF+DL7D+5MrXWfuYKWAhR9I5ePsrYTWOJuRbDaN/RDG0x9N5nSUyIJnP1u9gcXsZFqvJx+iisW/Tli+6N8ShD1Z2mVJBRLgPy2T4MGGayiIQQxYbWmt+O/8anOz6lsl1l01R9ZqSQuXkmhE0nMyuL2RmPccRzCKN6taR57cqmCbyMkicMQojbSs5I5sNtH7Li1Ao61O7AJx0/waW8S+EPqDWGg3+SuuItHFLO8behHf/UfJGhD3bitTJc3WlKktCFELc4fuU4YzeN5czVM7zc6mWe937+nrpY9Pn9XPnjDZxjtxGV5cpCx0/o+VA/vpDqTpOShC6EuMGyE8uYuG0iDrYOfNvtW9rWalv4g127yMU/36XaiV9Q2oEZ9i/QoOfLTGpZT6o7zUASuhACgJTMFCZum8ifJ/+kbc22fNbpM6qWr1q4g2WkcH71NJx2z6FKVjo/2fTGrsubvHRfc2ylutNsJKELITh25RjjNo3jVOIpXvB+gZEtR2JtVYhqTK25sHUxths/pFbmRTbShksd3qFvl05S3VkEJKELUYZprfnl2C9M3jmZirYV+brb13So3aFQx4o9HEby8nG4pxzkiHZjo9dX9Ojdj0r2JpxxUdyRJHQhyqjEtEQ+CP+AtWfW4l/bn487flyoLpbL504R88ubeF9ZwyVdmb/d36LD46/yeCUpCipqktCFKIMiYiMYFzqOS8mXGNt6LIOaD7rrUSxXr17h4E8f4hPzPY2BDdUH0rTfe/SubuIFLUSBSUIXogwxZBlY8O8Cvoj4gpoONVnUaxFe1bzu6hgpaRls+2M2zY/Moj1X2OXYheqPTKJL/SZmiloUlCR0IcqIS8mXeCvsLbaf305P955MaD+BSnaVCvz5DEMWG1f/geuOj7if05ywa8q1ngvw8+1ixqjF3ZCELkQZsDlmM+9ueZfkjGQ+6PABfRv0LXBBT1aWZkPYFuw2fUh3w3YuWVXjhP9MGnQZDFIUVKxIQheiFMswZDBzz0y+O/QdDas0ZEGPBdR3ql+gz2qtCd17mKurPqJX2irSVTlOeb2Gx0PjqGZXwcyRi8KQhC5EKRV9NZo3Qt/gYPxBnmz8JK/7vY69jX2BPrv9aAwnln9Gn6RfqKDSiPJ8ErdHP8SzUnUzRy3uhSR0IUoZrTV/nfqLT7Z/gpWyYnrn6XR161qgzx6Iukz4H3N46HIw7dRlomt2wf7RT/Go0djMUQtTkIQuRCmSmJbIx9s+ZlXkKnyr+zIpYBK1K9bO93MnYpNYuewHusbMYbhVNBcre5H28PfUq5/nipKiGJKELkQpsfPCTt4Oe5u45DhG+Yzi2RbP5lu+fzYhhZ//WoHf8Rm8YnWAhAp1SOkxjxqtHpcHniWQJHQhSrgMQwZf7vuS+QfmU69SvQKNLY9LSuP71Vtw3zedV9VmUm0rcb3TRzj5vwA25YoocmFqktCFKMEiEyMZv3k8B+MP8mjDR3mzzZtUsM17BMrV1AwWbdhPue0zGck/WFsrrvuOpFLXN6G8U9EFLsyiIGuKLgB6A7Fa6xa32d4ECAZ8gXe01lNNHqUQ4gZaa34//juf7fwMWytbPu/8Od3cuuW5f2qGge/DjhMX+g3Ds37BRV3jWqNHsX/gA2ydXIswcmFOBblDXwjMARblsf0yMAp4xDQhCSHuJCE1gffD32d91Hra1WrHRP+J1HCocdt9MwxZ/LzzDEfWLuS5jKW4W10kqU4H6D2JSrVbFW3gwuwKskh0qFLK/Q7bY4FYpdSDpgxMCHGr8HPhvBv2LpfTLvO63+sMbDbwtpNqZWVp/tp3lrBVPzM45TuetorkuksT6DWHig27yQPPUqpI+9CVUsOB4QCurvJnnhAFlW5IZ+aemSw6tAjPyp580fULmjjfOhmW1poNR2L5c8Vf9E+czxTrQ6RUqovuPhcHr35gJasFlWZFmtC11nOBuQB+fn66KNsWoqQ6mXCSN0Pf5OiVozzZ+EnG+o2lvM2tc41vPxXP4hXr6Bk7j1nWO0gr70xWl88o7/cs2NhZIHJR1GSUixDFlNaan47+xNRdU3GwdWBOlzkE1gu8Zb9/zyYyb8UW2kXN5XObTWg7ewz+4ynn/zKUK/hsiqLkk4QuRDEUnxLPhK0TCI0JpWOdjnzk/9EtqwmdvJTEVyt30+DYt3xqswpbW432ex7bzuPAoZCLO4sSrSDDFpcCnYGqSqkY4D3AFkBr/bVSqiawC3AEspRSo4FmWuur5gpaiNIsNCaU/235H0npSbzV9i0GNBlww1S35xJS+HLNARz3z+d/1n/haJNMRvN+WHd9F6q4WTByYWkFGeUyIJ/tF4C6JotIiDIqNTOVz3d/ztIjS2lYpSHzus+jYZWGOdvjk9L4csNR0nd8xyvWv1HD5grpnt1R3d/DruYtJSKiDJIuFyGKgaOXj/Jm6JucTDzJwGYDedX3VcpZG0vwr6Vm8G3oSaLDlvIKP+Fpc560Wm2g54fYuXWwcOSiOJGELoQFZeksfjj0AzP2zKByucp83fVr/Ov4A9nVnVsjORDyMy8YltLc6gxpVRpBj88p17iXjCUXt5CELoSFxCbH8m7Yu4SfD6dzvc580OEDnO2dyTBk8cuuGLas/Z1n03/geavjpFV2ha5zKef1OOQzg6IouyShC2EBG6M2MmHrBFIzU/nfff+jX6N+aA3L951j1aq/eDrpO56yPkhaxVrQZQblfJ4Ba1tLhy2KOUnoQhSh1MxUpu6ayk9Hf6KJcxM+6/QZHo4ebDway28rVvFoQjBfWu8lvYIzuvMnlPN7DmwLtmycEJLQhSgix64c483QNzmRcILBzQYzyncUEVFJzPz+Z7pdnM8X1ttJt3ckK2ACdu1egHIVLR2yKGEkoQthZlprlh5ZyrRd06hkV4mvu35NZVrw9vyV3Bc9j8+tw8iys8fQ/nXs/F+ReclFoUlCF8KMLqdeZsKWCWyK2URAnQCGNRnPb+sO0/T4UCbZhKBsrcnyG4Ft4Fip7hT3TBK6EGay9dxW3gl7h8S0REZ6jSXumDt7vnmT/1mtxdY2i8xWgyh3/zhwzH8RZyEKQhK6ECaWZkhjzt45LDy4ELdKHnSwGonNsr8Yq1ZT3jqD9Ob9sO76NtZV3C0dqihlJKELYUKH4w/zdtjbnEg4QfPynem0P4FB+hUqWKWR2ugRrLq9hX21xpYOU5RSktCFMIHMrEzmHZjH1/u+wV5VpM+FhoxP/gUHlcr1hg9h1f0dKlS/dUEKIUxJEroQ9+hU4ine3vw2B+MP0vi6CzMuHaWu3k+C54NY9XyXSjWaWTpEUUZIQheikDKzMll0cBGz987BJlPzUVwijyRHEe/aEx6cgFON5pYOUZQxktCFKIR/L/3LGxvfJiblNAHX0/gw/hKGmkHogRNwqeVt6fBEGSUJXYi7kJyRzP82fsLac3/ibDAwI/4yTR07UOW597Cu3dLS4YkyThK6EAWgtWb+ziUEH5zONZXKE9eSeNzKi/pPLcG2bitLhycEIAldiHytO7yJGVvf4YxNIk0z0hmaWY/OfT6lvJufpUMT4gYFWVN0AdAbiNVa37LOlTIudjgTeABIBoZorfeYOlAhitqBM/uYsfZ1dtqcp4rK4qXrVRnQ4zMq129v6dCEuK2C3KEvBOYAi/LY3gtomP3VDvgq+79ClEgno/9l1prXCbOKIcsGeqc6MaLzx7g26Wzp0IS4o4IsEh2qlHK/wy4PA4u01hrYppRyUkrV0lqfN1WQQhSFs+cPMvuf11lvFUWGtaJjWmWe7zCBll49LB2aEAViij70OkB0rtcx2e/dktCVUsOB4QCurq4maFqIe3ciahtfrXuXTeoC6dbQJq0yz7Z9F3+fBywdmhB3pUgfimqt5wJzAfz8/HRRti1Eblpr9pxYxdwtkwjnMjZW0Dq1Cv383qK7nyRyUTKZIqGfBerlel03+z0hip2r6Vf5a99Cfjz4A5EqhYpZWQSm1OCRthMIatPZ0uEJcU9MkdCXAy8rpX7E+DA0UfrPRXGSmZXJzgs7WXFoCatiNpGmNE3T0+mT7Emn9u/TvW1bjIO1hCjZCjJscSnQGaiqlIoB3gNsAbTWXwP/YByyeALjsMWh5gpWiILKMGSw/cJ21p5Zy4bINSRkJFEhK4teSak4JfvQJOAdet7XCmsrSeSi9CjIKJcB+WzXwEsmi0iIQko3pBN+Lpw1Z9awMXoj19KvUUEr7r+eRMekTM6l3U/lwNH09W+JnY2VpcMVwuSkUlSUaKmZqWw5t4W1Z9ayKXoTSRlJVLIuT6e0LHrFxdIw2Y5f1IOc93+BZwK9qGAnP/Ki9JKfblHiJGckE3Y2zJjEYzaRkplCZbvKdHdsyP3Rh/C/eJSLuirB+il23zeY5zo3p3IFW0uHLYTZSUIXJcL1jOuExoSy9sxaNsdsJtWQirO9Mw+696RbOvhGLMP+6J+c0HV42zASB7/+vBjUhOqV7C0duhBFRhK6KLaSM5IJiQ5hVeQqtpzdQnpWOlXLV+XhBg/TvXZHfKP2YrX1K6yuX2S/bsCczNeo5NWH0d2bUM+5gqXDF6LISUIXxUpKZgqhMaGsjlxNaEwoaYY0qpWvRr/G/ejm1o1WDvWw3jEXvWQQKjWR7XgxI30YlRrfz+s9m9CoRiVLn4IQFiMJXVhcmiGNsLNhrD69mpCYEFIyU3C2d6Zvg770cO+Bbw1frK6eg61z0Hu+g4xkNlm14/O03lT0bMu4Ho3xca1i6dMQwuIkoQuLyMjKIPxcOKsjV7MhagNJGUk4lXPiQc8H6eneE78aflhbWUPsEfjzFfT+n9Bas9a6E5PTelGxTjPe7NkE/wZVLX0qQhQbktBFkTFkGdh9cTcrI1ey9sxaEtMSqWRXia5uXenp3pO2tdpia2ULWkNUOGyZCcdWYbC25x+7Hnya0I0K1T1445HG9GheQ6o7hbiJJHRhVlpr9sftZ9XpVayOXM2llEuUtylPF9cu9HTviX9tf2yts4cUZhng0HJjIj+7i4xyzvxRcSCT4vyp4FSD1/o1oq9PHanuFCIPktCFyWmtOXblGCtPr2RV5CrOJp3FzsqOgLoB9PLoRae6nShvU/7/P5CRAvuWwtbZcPkU6Y6u/Owyio/P+lCxoiOj+zSgf9t6lLOxttxJCVECSEIXJnPm6hlWnl7JytMrOZV4CmtlzX2172Nky5F0ce1CJbubRqAkX4ad82H715AcR1r1Viyp/T4fn25AhXJ2vNKjPkP93aW6U4gCkt8UcU8uXL/AqtOr+Of0Pxy+fBiFwreGL/9r+j+6unXF2d751g9dOQPbvoQ9iyAjmTSPrnxv1YdPD1fFxtqK4YEevNDJE6cKdkV/QkKUYJLQxV2LT4lnzZk1rDq9ij2xxvXAW7i04HW/1+nh3oOaDjVv/8Hz+2DLLDj4ByhFerPH+E71YVqENZkGzYC2rrzSpQHVHaW6U4jCkIQuCuRq+lXWn1nPytMr2X5hO1k6iwZODXjF5xV6uvfE1TGPJQW1hlMbjQ86T4WAXSXS247kB92L6duvk5SeySOtavFa10a4ukh1pxD3QhK6yNP1jOuERIewOnI1YWfDyMjKoG7FujzX4jl6efSiYZWGeX84Mx3+/Q3Cv4CLB6BiTTK7vMdPWUFMD4slLimRbs1qMLZ7I5rUdCyycxKiNJOELm6QnJHMpphNrI5czeaYzaRnpVO9fHX6N+nPAx4P0Nyl+Z3Hfydfhl0LYMe3kHQBqjUh66HZ/JHpz+cbz3A2IYb2ni7MHdQYX6nuFMKkJKELkjOSc+ZP2Xx28w3zp3R3606r6q2wUvksCBF3wvigM2IJZKZA/SD0I1+yKrkp09Yd50TsEbzrVubTx7zo2KCqFAUJYQYFSuhKqZ7ATMAamKe1/vSm7W7AAqAacBl4RmsdY+JYhQklZySz+ezmnDvxVEMqVctX5dGGj9LDvQc+1X3yT+JaQ+RmY7fKsVVgbQfeT6LvG0nY1epMWXWU/TF7qV/Nga+e9qVni5qSyIUwo4KsKWoNfAF0A2KAnUqp5VrrQ7l2mwos0lp/p5TqAkwCBpojYFF4KZkpbI7ZnHMnnpKZgou9C480eCQniVtbFaB4JzMdDv4O4XPgwgGoUBUCx0Ob59hz2ZbJfx5h26lI6jiVZ8rj3vT1qYONtSz5JoS5FeQOvS1wQmt9CkAp9SPwMJA7oTcDxmR/vxFYZsIYxT1IyUwh7GwYayLX5Kzu42zvTJ/6fYwzGVb3LVgSB2P/+O5g2D7X2D9etTE8NAu8n+BofCZTfjvKusMXqVrRjvcfasaAdq5S3SlEESpIQq8DROd6HQO0u2mffcCjGLtl+gKVlFIuWuv43DsppYYDwwFcXfMY5ibuWWpmKlvObmF15I3T0fap34fubt1pXaN1wZM4GPvHt39l7B/PSAbP++HhL6BBEFGXU5j++1GWRZylop0Nr3dvxFB/DxzKyeMZIYqaqX7rXgfmKKWGAKHAWcBw805a67nAXAA/Pz9torYFueYUj1zNpuhNJGcmU6VcFXp79qaHew9a12iNjdVd/HNrDZFhxgedR1eCtS14PQHtX4QazYm9msrsPw+ydEcU1laK4Z08GRlYX6o7hbCggvyGnwXq5XpdN/u9HFrrcxjv0FFKVQQe01onmChGkYf/HmyuO7OO0JhQkjOTcSrnxAOeD9DDvQd+NfzuLomDcaKsA7/C9m+M48cruEDgOPB7DirVICE5na9XHmHh1tNkGjRPtqnHqKCG1JDqTiEsriC/7TuBhkopD4yJvD/wVO4dlFJVgcta6yzgLYwjXoQZXEu/xqaYTayNXMuWc1tIM6ThbO/MA54P0M2tG21rtr37JA6QeBZ2zoPdCyHlMlRvDg/NBO8nwbY819MyCd5wnG9CT5GUlsnDLWvzWrdGuLk4mPwchRCFk+9vvtY6Uyn1MrAa47DFBVrrg0qpD4FdWuvlQGdgklJKY+xyecmMMZc5CakJbIzeyNozawk/H05mVibVy1fnsYaP0dWt69092MxNa4jebpzt8NByQEPjB6DdCHDvCEqRlmlg6ZbTzNl4grikdLo2rc7Y7o1pWkuqO4UobpTWlunK9vPz07t27bJI2yVBXEoc68+sZ23UWnZd2IVBG6hTsQ5dXbvS1a0r3tW88x8nnpfMNPj3d2MiPx8B9pXBdxC0GQZV3AEwZGn+2HuW6WuPcTYhhXYezozr2ZjWbreZPVEIUWSUUru11n632yZDEYqR80nnWRe1jnVn1rE3di8ajbujO8+2eJaubl1p6tz03gpzrp43luXvDobrl4zDDh/8HFr2Bztj14nWmtUHLzB1zTFOxCbhVacykx71IqChVHcKUdxJQrew6KvRrI1ay7oz6zgQdwCAhlUaMrLlSLq5daO+U/17T6Qxu4x34wf/MC7z1qgHtHvBOPww17HDjscxZfUR9sUk4lnNgS+f9qWXVHcKUWJIQreAkwknWXvGmMSPXjkKQHOX5rzq+yrd3Lrh5uh2741kpsOhP43jx8/uhnKO0Ha4sVvFpf4Nu+6NusKU1UfZejKeOk7lmfy4N49KdacQJY4k9CKgteZQ/CHWR61nXdQ6TieeBqBVtVa87vc6Xd26UqdiHdM0du2CcaTKrgWQdBFcGkCvKdBqAJS7cQm4oxeuMW3NUdYcuoiLgx0Tejfj6fukulOIkkoSuplkZGWw5+Ie1ketZ0PUBi4mX8RaWdO6RmsGNBlAkGsQ1StUN01jWsOZrbDzWzj8F2RlQv0gYzVn/SCwuvFOO/pyMtPXHuOP7OrOMd0a8WxHDypKdacQJZr8BptQSmYKW89uZUP0BkKiQ7iafpVy1uXoULsDr/i8QmDdQJzsnUzXYNo12P+TcaHl2EPG0SptX4A2z93SrQIQezWVORtPsHRHFFZKMTzAkxGB9aniINWdQpQGktDvUUJqAptiNrE+aj3h58JJNaTiaOdI53qd6VKvC+1rt6eCrYmXVrt01FgEFLEU0q9BTW/oMxtaPA52t7aVmJzB16EnCd5irO58ok09RnVpSM3KUt0pRGkiCb0QziedZ0P0BjZEbWD3xd0YtIEaFWrQt2FfglyD8K3hi62VrWkbNWTC0RXGlYAiNxvnHm/e1/iQs26bG0ar/Cc5PZPgLZF8s+kk19Iy6dOyNq91bYR7VanuFKI0koReAFprTiScYEPUBtZHrefw5cMA1K9cn2dbPEuQaxDNXJqZZ3jftYuw5zvYFQzXzkHlehA0AXwGQcVqt/1IemYWP+6MYtb6E8QlpRHUpDqv95DqTiFKO0noecjSWey/tD/noWbUtSgAvKt581rr1+hSrwvuld3N07jWEBVuvBs/vDz7IWcXeHCacQx5HmX+hizNsr1nmb7uGDFXUmjr4czXz/ji5y7VnUKUBZLQc0k3pLP9/HY2RG9gY9RG4lPjsbGyoV3NdgxuPpj7691PtQq3vys2ibQkOPAz7JgHsQf//yGn37NQtUGeH9Nas+bQRaatOcqxi0k0r+3Ix4+0ILBRNSkKEqIMKfMJ/UrqFUJjQgmJDmHrua0kZyZTwaYCHet0JMg1iIC6AVSyq5Tvce7J+f3Gcvz9v2Q/5PQyrgTk9XhOSX5etpyIY/Lqo+yLTsCzqgNfPGWs7rSykkQuRFlTJhP66cTThESHEBIdQsSlCLJ0FtXLV6e3Z2861+tM21ptKWddzrxBpCcb1+XcFQxnd4GNPTR/FPyG5vmQM7eI6ASmrD7ClhPx1Kpsz2ePefGYb12p7hSiDCsTCT0zK5N9l/blJPHIq5EANHFuwnDv4XSu15lmzmZ6qHmz2MPGJL7vR0hLNE6Q1fNT4wRZ5avk+/HjF68xdc1RVh+8iLODHf/r3Yyn27libyvVnUKUdaU2oV/PuM7Wc1sJiQ4hNCaUhLQEbKxsaFuzLU81fYrOdTtTq2KtogkmI9U4r8quBRC9zTjksNnD0HoouHXI924csqs71x1j2d6zVLCz4bWujXguQKo7hRD/r1RlgwvXL7ApehMbYzay4/wOMrIycLRzpFPdTnSu1xn/2v5UtKtYdAHFHc++G18CKVfAuT50+whaPQ0OLgU6xKVraczZcJwlO6JQSvFcRw9Gdm6As1R3CiFuUqITutaaI5ePEBIdwsbojTnjw10rufJUk6cIrBeIT3Wfwi3JVliZacb5VHYvNBYAWdlA04eMd+MenQp0Nw6QmJLB3NCTLAiLJN2QxRN+9RgV1IBalcubN34hRIlV4hJ6uiGdnRd2sjF6IyHRIVxMvohC0ap6K15r/Rqd63XGw9Gj6IfrXT5lTOJ7f4DkeHByg6D3wOcZqFjwSbhS0g0Ebz3N1yEnuZqayUMtazOmWyM8pLpTCJGPAiV0pVRPYCbGNUXnaa0/vWm7K/Ad4JS9z3it9T+mDdVoxakVTNg6gfI25elQuwMv13uZgDoBuJQvWBeGSWWkwpG/Yc8iOL0JlDU07mUcqeLZ5ZZZDu8kPTOLn3ZGMWvDCS5dS+P+xtV4vUdjmteubMYTEEKUJvmuKaqUsgaOAd2AGGAnMEBrfSjXPnOBvVrrr5RSzYB/tNbudzpuYdcUTUhNYH/cftrVamf+oYV5uXgQ9nwP+3809o07uYLPQOOX4909aDVkaf6MMFZ3Rl9Ooa27M2/0bEwbqe4UQtzGva4p2hY4obU+lX2wH4GHgUO59tHAfxOFVAbOFT7cO3Oyd6JT3U7mOnze0q4ZF1bes8g4btzaDpr0Ni6u7BF4V3fjYOz/X3voItPWHOPoxWs0q+VI8NAWdJbqTiFEIRUkodcBonO9jgHa3bTP+8AapdQrgAPQ9XYHUkoNB4YDuLq63m2sRU9riNlpnBzr3z8g4zpUawI9JoH3kwUeqXKzrSfjmLL6KHujjNWdc57y4YEWtaS6UwhxT0z1UHQAsFBrPU0p1R74XinVQmudlXsnrfVcYC4Yu1xM1LbpXY83dqfsWQSXjoCtA7R4FHwHQ12/Ao9Uudn+mASmrD7K5uNx1Kpsz6ePevF4a6nuFEKYRkES+lmgXq7XdbPfy+05oCeA1jpcKWUPVAViTRFkkcjKgtMhxiR++G/IyoA6fsY5VVo8est6nHfjROw1pq4+xqqDF6hSwZZ3H2zKM/e5SXWnEMKkCpLQdwINlVIeGBN5f+Cpm/aJAoKAhUqppoA9cMmUgZpN4lmIWAx7v4eEKGP5fZth4DsQajS/p0NHX05m5vrj/L4nhgp2Nozu2pDnOnpQyd7Ei18IIQQFSOha60yl1MvAaoxDEhdorQ8qpT4EdmmtlwNjgW+VUq9hfEA6ROc3fMaSMlLh6D8QsQROrgedZXywGfSe8UGn7b0tzXbpWhpfbDzB4u1nUErxrL8HL94v1Z1CCPMqUB969pjyf256b0Ku7w8B/qYNzcS0hnN7jUn8wC+QmgCOdaDja8bhhs4e99xEYkoG34aeYsGW06RlZtGvdV1GBTWktpNUdwohzK/EVYretaRY2P+TMZHHHgLrctC0t3E+Fc/Oea7+czdS0g18Fx7JVyEnSUzJoLd3LcZ0a4RntSKcN0YIUeaVzoSemQ7HV8PexXB8DWiD8QHng59Di8egvJNJmskwZPHjzmhmrz9O7LU0OjeuxuvdG9OijlR3CiGKXulK6BcOGJP4gZ+N86lUrAHtXzLejVdvYrJmsrI0y/ed4/O1x4i6nIyfWxXmPOVLWw+p7hRCWE7JT+jX44194hGL4cJ+sLI1zqfi8wzUDwJr052i1pp1h2OZtuYoRy5co2ktR4KHtKFzY6nuFEJYXslM6IZMOLHOmMSPrjSOGa/VEnpNBq9+UMH0d8rhJ+OZsvoIe6IScHepwKwBPvT2kupOIUTxUfIS+rHVsPwVSLoIFVyg7fPGLpWaLczS3IGYRCavPsLm43HUdLTnk75e9POri61UdwohipmSl9CdXKFOa2MSb9gdbMwztvtEbBLT1hxl5b/G6s53HmjKwPZS3SmEKL5KXkKv3hQGLDXb4c8mpDBj7TF+2xNDeVtrXg1qyLAAqe4UQhR/JS+hm0lcUnZ157YoUDDU34MXO9fHpaKF5lwXQoi7VOYT+tVUY3Xn/LDTpGYY6Ne6Hq92lepOIUTJU2YTemqGge+2RvLVppMkJGfwoFctxnRvRH2p7hRClFBlLqFnGLL4aWc0szcc5+LVNAIbVeONHlLdKYQo+cpMQs/K0vy131jdeSY+mdZuVZjV34d2nhZYXFoIIcyg1Cd0rTUbjsQyZbWxurNJzUosGOLH/Y2rS3WnEKJUKdUJfdupeKasPsruM1dwc6nAzP6teMi7tlR3CiFKpVKZ0P89m8jk1UcJPXaJGo7lmNi3BU/41ZPqTiFEqVaqEvrJS0l8vuYYKw6cx6mCLW8/0IRB7d2lulMIUSaUioR+NiGFmeuO8evuGOxtrRnVpQHDOnniKNWdQogypEAJXSnVE5iJcU3ReVrrT2/aPh24P/tlBaC61trJhHHeVnxSGl9sPMkP284AMLiDOy/d34CqUt0phCiD8k3oSilr4AugGxAD7FRKLc9eRxQArfVrufZ/BfAxQ6w5rqZmMG/zaeZvPkVKhoHHs9furFulgjmbFUKIYq0gd+htgRNa61MASqkfgYeBQ3nsPwB4zzTh3WrDkYuM+XkfCckZPOBVkzHdGtOgulR3CiFEQRJ6HSA61+sYoN3tdlRKuQEewIY8tg8HhgO4urreVaD/8ahakVb1nBjbrTFedaW6Uwgh/mPqh6L9gV+11obbbdRazwXmAvj5+enCNOBR1YGFQ9sWPkIhhCilCjIw+yxQL9frutnv3U5/wHyTlQshhMhTQRL6TqChUspDKWWHMWkvv3knpVQToAoQbtoQhRBCFES+CV1rnQm8DKwGDgM/a60PKqU+VEr1ybVrf+BHrXWhulKEEELcmwL1oWut/wH+uem9CTe9ft90YQkhhLhbMrmJEEKUEpLQhRCilJCELoQQpYQkdCGEKCWUpQalKKUuAWcK+fGqQJwJwzGV4hoXFN/YJK67I3HdndIYl5vWutrtNlgsod8LpdQurbWfpeO4WXGNC4pvbBLX3ZG47k5Zi0u6XIQQopSQhC6EEKVESU3ocy0dQB6Ka1xQfGOTuO6OxHV3ylRcJbIPXQghxK1K6h26EEKIm0hCF0KIUqJEJHSl1BSl1BGl1H6l1B9KKac89uuplDqqlDqhlBpfBHH1U0odVEplKaXyHIKklIpUSh1QSkUopXYVo7iK9Hplt+mslFqrlDqe/d8qeexnyL5eEUqpW6ZrNlEsdzx/pVQ5pdRP2du3K6XczRFHIeIaopS6lOv6DCuiuBYopWKVUv/msV0ppWZlx71fKeVbTOLqrJRKzHW9JtxuPzPEVU8ptVEpdSj79/HV2+xj2mumtS72X0B3wCb7+8+Az26zjzVwEvAE7IB9QDMzx9UUaAyEAH532C8SqFqE1yvfuCxxvbLbnQyMz/5+/O3+LbO3JZk5jnzPH3gR+Dr7+/7AT0VwfQoS1xBgTlH9POVqtxPgC/ybx/YHgJWAAu4DtheTuDoDf1vgetUCfLO/rwQcu82/pUmvWYm4Q9dar9HGedkBtmFcNelmOYtZa63Tgf8WszZnXIe11kfN2UZhFDCuIr9e2R4Gvsv+/jvgkSJo83YKcv65Y/0VCFJKqWIQl0VorUOBy3fY5WFgkTbaBjgppWoVg7gsQmt9Xmu9J/v7axjXk6hz024mvWYlIqHf5FmM/0e72e0Ws7754lmKBtYopXZnL5RdHFjqetXQWp/P/v4CUCOP/eyVUruUUtuUUo+YIY6CnH/OPtk3FImAixliudu4AB7L/hP9V6VUvdtst4Ti/DvYXim1Tym1UinVvKgbz+6u8wG237TJpNfM1ItEF5pSah1Q8zab3tFa/5m9zztAJrC4OMVVAB211meVUtWBtUqpI9l3FZaOyyzuFFvuF1prrZTKa9ysW/Y18wQ2KKUOaK1PmjrWEuovYKnWOk0p9QLGvyK6WDim4mwPxp+nJKXUA8AyoGFRNa6Uqgj8BozWWl81Z1vFJqFrrbveabtSagjQGwjS2Z1PN7mbxaxNFlcBj3E2+7+xSqk/MP5ZfU8J3QRxmeV6wZ1jU0pdVErV0lqfz/7TMjaPY/x3zU4ppUIw3t2YMqEX5Pz/2ydGKWUDVAbiTRhDoeLSWueOYR7G5xLFgdl+pu5F7iSqtf5HKfWlUqqq1trsk3YppWwxJvPFWuvfb7OLSa9ZiehyUUr1BMYBfbTWyXnsVqDFrIuaUspBKVXpv+8xPuC97dP4Imap67UcGJz9/WDglr8mlFJVlFLlsr+vCvgDh0wcR0HOP3esjwMb8riZKNK4bupj7YOxb7Y4WA4Myh65cR+QmKt7zWKUUjX/e/ahlGqLMe+Z+3/MZLc5Hzistf48j91Me82K+slvIZ8Wn8DYzxSR/fXfyIPawD83PTE+hvFO7p0iiKsvxj6vNOAisPrmuDCOVtiX/XWwuMRlieuV3aYLsB44DqwDnLPf9wPmZX/fATiQfc0OAM+ZKZZbzh/4EOONA4A98Ev2z98OwLOIrlF+cU3K/lnaB2wEmhRRXEuB80BG9s/Xc8AIYET2dgV8kR33Ae4w8quI43o51/XaBnQoorg6Ynx+tj9X7nrAnNdMSv+FEKKUKBFdLkIIIfInCV0IIUoJSehCCFFKSEIXQohSQhK6EEKUEpLQhRCilJCELoQQpcT/AU1b6jmA8fTsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test \n",
    "x = torch.linspace(-2, 2, 1000)\n",
    "y_norm = normal(x, kappa_std_avg)\n",
    "y_ln = log_normal(x, (1+kappa_std_avg))\n",
    "y_lnasym = asym_log_normal(x, kappa_lo, kappa_hi)\n",
    "plt.plot(x, y_norm, label=\"Normal\")\n",
    "plt.plot(x, y_ln, label=\"Log-Normal\")\n",
    "plt.plot(x, y_lnasym, label=\"Asymm. Log-Normal\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f96b00",
   "metadata": {},
   "source": [
    "## 3. NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bfa70570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from torch import Tensor\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f4f55564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hep_nll(s_true:float, b_true:float, mu:Tensor, f_s_nom:Tensor, f_b_nom:Tensor,\n",
    "             shape_alpha:Optional[Tensor]=None, s_norm_alpha:Optional[Tensor]=None, b_norm_alpha:Optional[Tensor]=None,\n",
    "             f_s_up:Optional[Tensor]=None, f_s_dw:Optional[Tensor]=None,\n",
    "             f_b_up:Optional[Tensor]=None, f_b_dw:Optional[Tensor]=None,\n",
    "             shape_norm_sigma:Optional[Tensor]=None, s_norm_sigma:Optional[Tensor]=None, \n",
    "             b_norm_sigma:Optional[Tensor]=None, \n",
    "             interp_algo:str=\"fast_vertical\") -> Tensor:\n",
    "    r'''Compute negative log-likelihood for specified parameters.'''\n",
    "    \n",
    "    #  Interpolate shapes\n",
    "    if interp_algo == \"fast_vertical\":\n",
    "        f_s = fast_vertical(shape_alpha, f_s_nom, f_s_up, f_s_dw) if shape_alpha is not None and f_s_up is not None else f_s_nom\n",
    "        f_b = fast_vertical(shape_alpha, f_b_nom, f_b_up, f_b_dw) if shape_alpha is not None and f_b_up is not None  else f_b_nom        \n",
    "    else:\n",
    "        print(shape_alpha)\n",
    "        print(f_s_nom, f_s_up, f_s_dw)\n",
    "        f_s = interp_shape(shape_alpha, f_s_nom, f_s_up, f_s_dw) if shape_alpha is not None and f_s_up is not None else f_s_nom\n",
    "        f_b = interp_shape(shape_alpha, f_b_nom, f_b_up, f_b_dw) if shape_alpha is not None and f_b_up is not None  else f_b_nom\n",
    "    \n",
    "    # Normalizations !!! careful if signal and background shapes mix!!\n",
    "    print(\"shape_norm_sigma\", shape_norm_sigma)\n",
    "    s_exp, b_exp = mu, b_true\n",
    "    if len(shape_alpha) > 0:\n",
    "        print(\"Norms shape\", normal(shape_alpha, shape_norm_sigma))\n",
    "        mu *= normal(shape_alpha, shape_norm_sigma).prod()    \n",
    "    if len(s_norm_alpha) > 0:\n",
    "        mu *= normal(s_norm_alpha, s_norm_sigma).prod()\n",
    "    if len(b_norm_alpha) > 0:\n",
    "        b_exp *= normal(b_norm_alpha, b_norm_sigma).prod()\n",
    "    #  Compute NLL\n",
    "    t_exp = (s_exp*f_s)+(b_exp*f_b)\n",
    "    asimov = (s_true*f_s_nom)+(b_true*f_b_nom)\n",
    "    nll = -torch.distributions.Poisson(t_exp, False).log_prob(asimov).sum()\n",
    "    # Constrain shape +norm nuisances\n",
    "    for a in shape_alpha: nll = nll - Normal(0,1).log_prob(a)\n",
    "    for a in b_norm_alpha: nll = nll - Normal(0,1).log_prob(a)\n",
    "    for a in s_norm_alpha: nll = nll - Normal(0,1).log_prob(a)\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e43288",
   "metadata": {},
   "source": [
    "## 4. Setup INFERNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f3feb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_inferno.inferno import *\n",
    "from fastcore.all import store_attr, delegates, is_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "03c3bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HEPInferno(AbsInferno):\n",
    "    r'''Implementation of INFERNO with HEP like systematics'''\n",
    "    @delegates(AbsInferno)\n",
    "    def __init__(self, interp_algo:str=\"default\", shape_norm_sigma:Optional[List[float]]=None,\n",
    "                 s_norm_sigma:Optional[List[float]]=None, b_norm_sigma:Optional[List[float]]=None, \n",
    "                 rate_param_bkg:bool=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.interp_algo = interp_algo\n",
    "        self.shape_norm_sigma = torch.Tensor(shape_norm_sigma)\n",
    "        self.s_norm_sigma = s_norm_sigma\n",
    "        self.b_norm_sigma = b_norm_sigma\n",
    "        # Compute nuisance indeces\n",
    "        self.poi_idx = [0]\n",
    "        self.shape_idxs = list(range(1,self.n_shape_alphas+1))\n",
    "        self.n_alpha = 1+self.n_shape_alphas\n",
    "        self.s_norm_idxs = list(range(self.n_alpha, self.n_alpha+len(self.s_norm_aux)))\n",
    "        self.n_alpha += len(self.s_norm_aux)\n",
    "        self.b_norm_idxs = list(range(self.n_alpha, self.n_alpha+len(self.b_norm_aux)+self.nonaux_b_norm))\n",
    "        self.n_alpha += len(self.b_norm_aux)+self.nonaux_b_norm\n",
    "\n",
    "        print(\"*********************\")\n",
    "        print(\"Summary INFERNO setup\")\n",
    "        print(\"b_true\", self.b_true)\n",
    "        print(\"mu_true\", self.mu_true)\n",
    "        print(\"nshape_alphas\", self.n_shape_alphas)\n",
    "        print(\"shape idx\", self.shape_idxs)\n",
    "        print(\"shape_aux\", self.shape_aux)\n",
    "        print(\"s_norm_aux\", self.s_norm_aux)\n",
    "        print(\"shape_norm_sigma\", self.shape_norm_sigma)\n",
    "        print(\"rate_param_bkg\", rate_param_bkg)\n",
    "        print(\"n_alpha\", self.n_alpha)\n",
    "        print(\"interp_algo\", self.interp_algo)\n",
    "        print(\"*********************\")\n",
    "\n",
    "    def _aug_data(self): pass  # Override abs method\n",
    "    def on_batch_begin(self) -> None: pass\n",
    "    def on_batch_end(self) -> None: pass\n",
    "\n",
    "    def on_train_begin(self) -> None:\n",
    "        self.wrapper.loss_func = None  # Ensure loss function is skipped, callback computes loss value in `on_forwards_end`\n",
    "        for c in self.wrapper.cbs:\n",
    "            if hasattr(c, 'loss_is_meaned'): c.loss_is_meaned = False  # Ensure that average losses are correct        \n",
    "        self.shape_norm_sigma = self.shape_norm_sigma.to(self.wrapper.device)\n",
    "        \n",
    "    def _get_up_down(self, x_s:Tensor, x_b:Tensor, w_s:Optional[Tensor]=None, w_b:Optional[Tensor]=None) -> Tuple[Tuple[Optional[Tensor],Optional[Tensor]],Tuple[Optional[Tensor],Optional[Tensor]]]:\n",
    "\n",
    "        u,d = [],[]\n",
    "        # modified template variations\n",
    "        for i in range(self.n_shape_alphas):\n",
    "            idx_up = 1 + 2*i\n",
    "            idx_down = 2 + 2*i\n",
    "            up_batch = self.to_shape(self.wrapper.model(x_s[:,:,idx_up]))\n",
    "            down_batch = self.to_shape(self.wrapper.model(x_s[:,:,idx_down]))\n",
    "            u.append(up_batch)\n",
    "            d.append(down_batch)    \n",
    "        return (torch.stack(u),torch.stack(d)), (None,None)\n",
    "\n",
    "    def get_ikk(self, f_s_nom:Tensor, f_b_nom:Tensor, f_s_up:Optional[Tensor], f_s_dw:Optional[Tensor], f_b_up:Optional[Tensor], f_b_dw:Optional[Tensor]) -> Tensor:\n",
    "        r'''Compute full hessian at true param values, or at random starting values with Newton updates'''\n",
    "        alpha = torch.zeros((self.n_alpha), requires_grad=True, device=self.wrapper.device)\n",
    "        with torch.no_grad(): alpha[self.poi_idx] += self.mu_true\n",
    "        print(\"alpha\", alpha)\n",
    "        get_nll = partialler(hep_nll, s_true=self.mu_true, b_true=self.b_true, # Expectation values\n",
    "                             f_s_nom=f_s_nom, f_b_nom=f_b_nom, # Nominal shapes\n",
    "                             f_s_up=f_s_up, f_s_dw=f_s_dw, # Signal shapes\n",
    "                             f_b_up=f_b_up, f_b_dw=f_b_dw, #Background shapes\n",
    "                             shape_norm_sigma = self.shape_norm_sigma, # Norm unct on shapes\n",
    "                             s_norm_sigma = self.shape_norm_sigma, b_norm_sigma = self.b_norm_sigma # Norm unct on sig and bkg\n",
    "                            ) \n",
    "        nll = get_nll(mu=alpha[self.poi_idx], s_norm_alpha=alpha[self.s_norm_idxs], b_norm_alpha=alpha[self.b_norm_idxs], shape_alpha=alpha[self.shape_idxs],\n",
    "                     interp_algo = self.interp_algo)\n",
    "        _,h = calc_grad_hesse(nll, alpha, create_graph=True)\n",
    "        return torch.inverse(h)[self.poi_idx,self.poi_idx]\n",
    "\n",
    "    def on_forwards_end(self) -> None:\n",
    "        r'''Compute loss and replace wrapper loss value'''\n",
    "        b = self.wrapper.y.squeeze() == 0\n",
    "        w_s = self.wrapper.w[~b] if self.wrapper.w is not None else None\n",
    "        w_b = self.wrapper.w[b] if self.wrapper.w is not None else None\n",
    "        f_s = self.to_shape(self.wrapper.y_pred[~b], w_s)\n",
    "        f_b = self.to_shape(self.wrapper.y_pred[b], w_b)\n",
    "        (f_s_up,f_s_dw),(f_b_up,f_b_dw)= self._get_up_down(self.wrapper.x[~b], self.wrapper.x[b], w_s, w_b)\n",
    "        self.wrapper.loss_val = self.get_ikk(f_s_nom=f_s, f_b_nom=f_b, f_s_up=f_s_up, f_s_dw=f_s_dw, f_b_up=f_b_up, f_b_dw=f_b_dw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6d2a324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************\n",
      "Summary INFERNO setup\n",
      "b_true 2689.5053333309675\n",
      "mu_true 348.45252731445095\n",
      "nshape_alphas 2\n",
      "shape idx [1, 2]\n",
      "shape_aux None\n",
      "s_norm_aux []\n",
      "shape_norm_sigma tensor([0.0500, 0.0200])\n",
      "n_alpha 3\n",
      "*********************\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.1647, 0.0299, 0.0142, 0.1581, 0.3327, 0.0108, 0.1109, 0.0910, 0.0340,\n",
      "        0.0537], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.1674, 0.0312, 0.0144, 0.1513, 0.3336, 0.0108, 0.1089, 0.0976, 0.0336,\n",
      "         0.0513],\n",
      "        [0.1653, 0.0300, 0.0142, 0.1578, 0.3338, 0.0108, 0.1097, 0.0907, 0.0338,\n",
      "         0.0538]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.1617, 0.0287, 0.0139, 0.1645, 0.3317, 0.0108, 0.1128, 0.0852, 0.0344,\n",
      "         0.0562],\n",
      "        [0.1641, 0.0298, 0.0142, 0.1583, 0.3313, 0.0108, 0.1121, 0.0914, 0.0343,\n",
      "         0.0536]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.1584, 0.0345, 0.0150, 0.1864, 0.2669, 0.0128, 0.0990, 0.1220, 0.0330,\n",
      "        0.0720], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.1616, 0.0362, 0.0153, 0.1748, 0.2684, 0.0127, 0.0980, 0.1320, 0.0327,\n",
      "         0.0683],\n",
      "        [0.1589, 0.0346, 0.0151, 0.1865, 0.2677, 0.0128, 0.0976, 0.1218, 0.0327,\n",
      "         0.0723]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.1549, 0.0329, 0.0147, 0.1974, 0.2653, 0.0128, 0.0998, 0.1130, 0.0331,\n",
      "         0.0759],\n",
      "        [0.1578, 0.0345, 0.0150, 0.1864, 0.2661, 0.0128, 0.1004, 0.1222, 0.0332,\n",
      "         0.0718]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.1388, 0.0383, 0.0153, 0.2125, 0.2176, 0.0133, 0.0832, 0.1573, 0.0289,\n",
      "        0.0948], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.1418, 0.0400, 0.0156, 0.1975, 0.2200, 0.0132, 0.0826, 0.1698, 0.0286,\n",
      "         0.0910],\n",
      "        [0.1394, 0.0383, 0.0153, 0.2128, 0.2182, 0.0133, 0.0821, 0.1568, 0.0287,\n",
      "         0.0951]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.1356, 0.0367, 0.0150, 0.2271, 0.2148, 0.0133, 0.0836, 0.1462, 0.0292,\n",
      "         0.0984],\n",
      "        [0.1382, 0.0383, 0.0153, 0.2123, 0.2169, 0.0133, 0.0843, 0.1579, 0.0291,\n",
      "         0.0945]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.1264, 0.0424, 0.0149, 0.2368, 0.1740, 0.0131, 0.0671, 0.2057, 0.0254,\n",
      "        0.0941], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.1296, 0.0441, 0.0152, 0.2173, 0.1751, 0.0129, 0.0668, 0.2236, 0.0250,\n",
      "         0.0903],\n",
      "        [0.1273, 0.0423, 0.0149, 0.2375, 0.1744, 0.0132, 0.0657, 0.2045, 0.0252,\n",
      "         0.0950]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.1230, 0.0407, 0.0147, 0.2556, 0.1724, 0.0133, 0.0673, 0.1896, 0.0258,\n",
      "         0.0978],\n",
      "        [0.1255, 0.0425, 0.0150, 0.2363, 0.1735, 0.0131, 0.0685, 0.2068, 0.0256,\n",
      "         0.0932]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.1062, 0.0427, 0.0142, 0.2568, 0.1305, 0.0119, 0.0594, 0.2559, 0.0203,\n",
      "        0.1022], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.1089, 0.0440, 0.0143, 0.2355, 0.1308, 0.0118, 0.0589, 0.2750, 0.0200,\n",
      "         0.1009],\n",
      "        [0.1070, 0.0426, 0.0142, 0.2581, 0.1307, 0.0120, 0.0585, 0.2542, 0.0202,\n",
      "         0.1027]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.1035, 0.0412, 0.0141, 0.2774, 0.1299, 0.0120, 0.0598, 0.2384, 0.0206,\n",
      "         0.1031],\n",
      "        [0.1055, 0.0427, 0.0142, 0.2556, 0.1302, 0.0119, 0.0603, 0.2576, 0.0204,\n",
      "         0.1016]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0909, 0.0417, 0.0123, 0.2870, 0.0998, 0.0101, 0.0505, 0.3148, 0.0165,\n",
      "        0.0765], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0934, 0.0428, 0.0123, 0.2632, 0.1001, 0.0099, 0.0491, 0.3377, 0.0161,\n",
      "         0.0753],\n",
      "        [0.0916, 0.0416, 0.0123, 0.2883, 0.1002, 0.0101, 0.0495, 0.3127, 0.0164,\n",
      "         0.0772]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0882, 0.0405, 0.0122, 0.3099, 0.0991, 0.0102, 0.0517, 0.2939, 0.0169,\n",
      "         0.0774],\n",
      "        [0.0901, 0.0417, 0.0123, 0.2858, 0.0994, 0.0101, 0.0515, 0.3167, 0.0166,\n",
      "         0.0757]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0760, 0.0383, 0.0111, 0.2934, 0.0748, 0.0088, 0.0362, 0.3706, 0.0130,\n",
      "        0.0779], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0779, 0.0391, 0.0110, 0.2674, 0.0747, 0.0086, 0.0349, 0.3968, 0.0127,\n",
      "         0.0769],\n",
      "        [0.0766, 0.0380, 0.0111, 0.2953, 0.0750, 0.0089, 0.0354, 0.3679, 0.0129,\n",
      "         0.0789]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0742, 0.0372, 0.0110, 0.3182, 0.0747, 0.0090, 0.0373, 0.3465, 0.0133,\n",
      "         0.0785],\n",
      "        [0.0755, 0.0385, 0.0111, 0.2915, 0.0746, 0.0088, 0.0370, 0.3732, 0.0131,\n",
      "         0.0767]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0623, 0.0343, 0.0097, 0.3030, 0.0600, 0.0079, 0.0290, 0.4074, 0.0109,\n",
      "        0.0755], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0639, 0.0350, 0.0097, 0.2752, 0.0598, 0.0077, 0.0281, 0.4355, 0.0107,\n",
      "         0.0744],\n",
      "        [0.0628, 0.0341, 0.0097, 0.3044, 0.0601, 0.0079, 0.0284, 0.4052, 0.0108,\n",
      "         0.0765]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0604, 0.0335, 0.0096, 0.3294, 0.0599, 0.0080, 0.0298, 0.3822, 0.0111,\n",
      "         0.0763],\n",
      "        [0.0618, 0.0345, 0.0096, 0.3017, 0.0599, 0.0079, 0.0297, 0.4094, 0.0110,\n",
      "         0.0744]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0505, 0.0293, 0.0081, 0.3206, 0.0455, 0.0067, 0.0228, 0.4343, 0.0085,\n",
      "        0.0737], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0521, 0.0296, 0.0082, 0.2919, 0.0454, 0.0066, 0.0220, 0.4621, 0.0083,\n",
      "         0.0739],\n",
      "        [0.0510, 0.0292, 0.0081, 0.3223, 0.0457, 0.0067, 0.0223, 0.4319, 0.0084,\n",
      "         0.0743]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0489, 0.0289, 0.0081, 0.3480, 0.0454, 0.0068, 0.0236, 0.4086, 0.0086,\n",
      "         0.0730],\n",
      "        [0.0501, 0.0294, 0.0081, 0.3190, 0.0454, 0.0067, 0.0232, 0.4364, 0.0085,\n",
      "         0.0731]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0407, 0.0250, 0.0067, 0.3262, 0.0359, 0.0057, 0.0199, 0.4564, 0.0071,\n",
      "        0.0764], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0415, 0.0253, 0.0068, 0.2988, 0.0357, 0.0055, 0.0188, 0.4839, 0.0068,\n",
      "         0.0769],\n",
      "        [0.0411, 0.0249, 0.0068, 0.3286, 0.0361, 0.0057, 0.0195, 0.4531, 0.0070,\n",
      "         0.0772]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0398, 0.0248, 0.0067, 0.3524, 0.0359, 0.0058, 0.0210, 0.4314, 0.0073,\n",
      "         0.0749],\n",
      "        [0.0403, 0.0252, 0.0067, 0.3240, 0.0357, 0.0056, 0.0204, 0.4596, 0.0071,\n",
      "         0.0755]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0343, 0.0206, 0.0058, 0.3612, 0.0291, 0.0049, 0.0156, 0.4609, 0.0059,\n",
      "        0.0618], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0349, 0.0208, 0.0058, 0.3317, 0.0289, 0.0048, 0.0149, 0.4892, 0.0057,\n",
      "         0.0633],\n",
      "        [0.0348, 0.0206, 0.0058, 0.3636, 0.0294, 0.0049, 0.0153, 0.4571, 0.0059,\n",
      "         0.0625]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0336, 0.0204, 0.0057, 0.3887, 0.0293, 0.0049, 0.0161, 0.4351, 0.0060,\n",
      "         0.0602],\n",
      "        [0.0338, 0.0206, 0.0057, 0.3591, 0.0288, 0.0048, 0.0158, 0.4644, 0.0058,\n",
      "         0.0611]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0293, 0.0173, 0.0050, 0.3703, 0.0241, 0.0045, 0.0118, 0.4683, 0.0050,\n",
      "        0.0644], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0304, 0.0175, 0.0050, 0.3367, 0.0242, 0.0044, 0.0112, 0.5008, 0.0049,\n",
      "         0.0650],\n",
      "        [0.0296, 0.0172, 0.0050, 0.3727, 0.0242, 0.0045, 0.0115, 0.4648, 0.0050,\n",
      "         0.0656]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0281, 0.0171, 0.0049, 0.4015, 0.0238, 0.0045, 0.0124, 0.4390, 0.0051,\n",
      "         0.0637],\n",
      "        [0.0291, 0.0174, 0.0050, 0.3679, 0.0240, 0.0045, 0.0121, 0.4718, 0.0050,\n",
      "         0.0632]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0240, 0.0146, 0.0042, 0.3924, 0.0194, 0.0038, 0.0097, 0.4629, 0.0040,\n",
      "        0.0651], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0249, 0.0146, 0.0042, 0.3627, 0.0194, 0.0037, 0.0094, 0.4918, 0.0039,\n",
      "         0.0655],\n",
      "        [0.0242, 0.0144, 0.0042, 0.3946, 0.0194, 0.0038, 0.0095, 0.4600, 0.0039,\n",
      "         0.0659]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0229, 0.0144, 0.0041, 0.4206, 0.0192, 0.0038, 0.0101, 0.4365, 0.0040,\n",
      "         0.0643],\n",
      "        [0.0238, 0.0147, 0.0042, 0.3905, 0.0193, 0.0038, 0.0100, 0.4655, 0.0040,\n",
      "         0.0643]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0211, 0.0138, 0.0040, 0.3809, 0.0181, 0.0036, 0.0093, 0.4865, 0.0038,\n",
      "        0.0588], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0214, 0.0138, 0.0039, 0.3500, 0.0180, 0.0035, 0.0087, 0.5177, 0.0037,\n",
      "         0.0592],\n",
      "        [0.0213, 0.0138, 0.0040, 0.3831, 0.0181, 0.0036, 0.0091, 0.4834, 0.0038,\n",
      "         0.0600]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0207, 0.0138, 0.0040, 0.4101, 0.0181, 0.0037, 0.0099, 0.4572, 0.0039,\n",
      "         0.0586],\n",
      "        [0.0210, 0.0139, 0.0040, 0.3788, 0.0180, 0.0036, 0.0096, 0.4896, 0.0038,\n",
      "         0.0577]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0180, 0.0122, 0.0034, 0.3990, 0.0155, 0.0032, 0.0082, 0.4804, 0.0034,\n",
      "        0.0566], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0186, 0.0123, 0.0034, 0.3700, 0.0157, 0.0032, 0.0078, 0.5083, 0.0034,\n",
      "         0.0573],\n",
      "        [0.0181, 0.0121, 0.0034, 0.4012, 0.0156, 0.0033, 0.0081, 0.4775, 0.0034,\n",
      "         0.0573]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0174, 0.0121, 0.0034, 0.4262, 0.0154, 0.0033, 0.0087, 0.4546, 0.0034,\n",
      "         0.0554],\n",
      "        [0.0179, 0.0123, 0.0034, 0.3969, 0.0155, 0.0032, 0.0085, 0.4829, 0.0034,\n",
      "         0.0560]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0163, 0.0111, 0.0033, 0.4497, 0.0140, 0.0031, 0.0082, 0.4393, 0.0035,\n",
      "        0.0517], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0166, 0.0110, 0.0032, 0.4151, 0.0138, 0.0030, 0.0076, 0.4741, 0.0033,\n",
      "         0.0524],\n",
      "        [0.0165, 0.0111, 0.0033, 0.4529, 0.0140, 0.0031, 0.0081, 0.4353, 0.0035,\n",
      "         0.0523]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0157, 0.0109, 0.0033, 0.4818, 0.0139, 0.0031, 0.0086, 0.4082, 0.0035,\n",
      "         0.0509],\n",
      "        [0.0162, 0.0111, 0.0033, 0.4465, 0.0139, 0.0030, 0.0083, 0.4433, 0.0035,\n",
      "         0.0509]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0142, 0.0099, 0.0030, 0.4607, 0.0125, 0.0029, 0.0063, 0.4308, 0.0027,\n",
      "        0.0571], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0146, 0.0101, 0.0030, 0.4292, 0.0127, 0.0028, 0.0061, 0.4605, 0.0027,\n",
      "         0.0584],\n",
      "        [0.0143, 0.0098, 0.0030, 0.4642, 0.0126, 0.0029, 0.0062, 0.4267, 0.0027,\n",
      "         0.0576]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0139, 0.0097, 0.0030, 0.4894, 0.0125, 0.0029, 0.0065, 0.4043, 0.0028,\n",
      "         0.0552],\n",
      "        [0.0140, 0.0099, 0.0030, 0.4573, 0.0125, 0.0029, 0.0065, 0.4347, 0.0027,\n",
      "         0.0565]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0131, 0.0086, 0.0028, 0.4506, 0.0117, 0.0028, 0.0056, 0.4391, 0.0024,\n",
      "        0.0633], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0137, 0.0087, 0.0029, 0.4207, 0.0119, 0.0028, 0.0054, 0.4684, 0.0024,\n",
      "         0.0633],\n",
      "        [0.0132, 0.0085, 0.0028, 0.4544, 0.0117, 0.0028, 0.0055, 0.4345, 0.0024,\n",
      "         0.0642]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0126, 0.0086, 0.0028, 0.4784, 0.0115, 0.0028, 0.0059, 0.4120, 0.0024,\n",
      "         0.0631],\n",
      "        [0.0129, 0.0086, 0.0028, 0.4471, 0.0117, 0.0028, 0.0057, 0.4435, 0.0024,\n",
      "         0.0624]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0117, 0.0082, 0.0025, 0.4682, 0.0108, 0.0025, 0.0053, 0.4426, 0.0022,\n",
      "        0.0461], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0120, 0.0081, 0.0025, 0.4418, 0.0108, 0.0024, 0.0049, 0.4686, 0.0021,\n",
      "         0.0466],\n",
      "        [0.0119, 0.0081, 0.0025, 0.4716, 0.0108, 0.0025, 0.0051, 0.4382, 0.0022,\n",
      "         0.0470]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0113, 0.0083, 0.0025, 0.4928, 0.0107, 0.0025, 0.0058, 0.4178, 0.0023,\n",
      "         0.0460],\n",
      "        [0.0116, 0.0082, 0.0025, 0.4648, 0.0107, 0.0025, 0.0055, 0.4470, 0.0022,\n",
      "         0.0450]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0107, 0.0077, 0.0024, 0.4798, 0.0099, 0.0024, 0.0053, 0.4301, 0.0022,\n",
      "        0.0494], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0114, 0.0078, 0.0025, 0.4490, 0.0101, 0.0024, 0.0050, 0.4586, 0.0022,\n",
      "         0.0510],\n",
      "        [0.0107, 0.0077, 0.0024, 0.4832, 0.0099, 0.0024, 0.0052, 0.4267, 0.0022,\n",
      "         0.0497]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0101, 0.0077, 0.0024, 0.5083, 0.0096, 0.0024, 0.0056, 0.4038, 0.0022,\n",
      "         0.0479],\n",
      "        [0.0107, 0.0078, 0.0024, 0.4764, 0.0099, 0.0024, 0.0055, 0.4336, 0.0022,\n",
      "         0.0492]], device='cuda:0', grad_fn=<StackBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0105, 0.0079, 0.0024, 0.4810, 0.0098, 0.0025, 0.0051, 0.4298, 0.0021,\n",
      "        0.0488], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0109, 0.0080, 0.0024, 0.4512, 0.0099, 0.0025, 0.0048, 0.4581, 0.0021,\n",
      "         0.0501],\n",
      "        [0.0106, 0.0079, 0.0024, 0.4841, 0.0098, 0.0025, 0.0050, 0.4263, 0.0021,\n",
      "         0.0493]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0102, 0.0079, 0.0024, 0.5081, 0.0098, 0.0025, 0.0054, 0.4043, 0.0021,\n",
      "         0.0473],\n",
      "        [0.0105, 0.0080, 0.0024, 0.4781, 0.0098, 0.0025, 0.0052, 0.4332, 0.0021,\n",
      "         0.0482]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0109, 0.0073, 0.0025, 0.4783, 0.0097, 0.0025, 0.0053, 0.4231, 0.0023,\n",
      "        0.0582], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0111, 0.0074, 0.0025, 0.4424, 0.0096, 0.0024, 0.0050, 0.4588, 0.0021,\n",
      "         0.0586],\n",
      "        [0.0110, 0.0073, 0.0024, 0.4830, 0.0096, 0.0025, 0.0052, 0.4179, 0.0023,\n",
      "         0.0589]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0104, 0.0071, 0.0024, 0.5114, 0.0094, 0.0025, 0.0055, 0.3920, 0.0023,\n",
      "         0.0570],\n",
      "        [0.0109, 0.0074, 0.0025, 0.4739, 0.0097, 0.0025, 0.0054, 0.4281, 0.0023,\n",
      "         0.0574]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0093, 0.0066, 0.0022, 0.4940, 0.0085, 0.0022, 0.0047, 0.4187, 0.0021,\n",
      "        0.0518], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0097, 0.0067, 0.0022, 0.4618, 0.0086, 0.0022, 0.0045, 0.4484, 0.0021,\n",
      "         0.0539],\n",
      "        [0.0093, 0.0066, 0.0022, 0.4968, 0.0085, 0.0022, 0.0045, 0.4156, 0.0021,\n",
      "         0.0522]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0089, 0.0065, 0.0021, 0.5234, 0.0083, 0.0022, 0.0048, 0.3918, 0.0021,\n",
      "         0.0499],\n",
      "        [0.0092, 0.0067, 0.0022, 0.4914, 0.0085, 0.0022, 0.0048, 0.4216, 0.0021,\n",
      "         0.0513]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0084, 0.0062, 0.0020, 0.4741, 0.0075, 0.0021, 0.0044, 0.4289, 0.0019,\n",
      "        0.0645], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0090, 0.0063, 0.0021, 0.4408, 0.0078, 0.0022, 0.0042, 0.4594, 0.0019,\n",
      "         0.0664],\n",
      "        [0.0085, 0.0061, 0.0020, 0.4781, 0.0075, 0.0021, 0.0043, 0.4245, 0.0019,\n",
      "         0.0651]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0078, 0.0061, 0.0019, 0.5028, 0.0070, 0.0021, 0.0047, 0.4035, 0.0018,\n",
      "         0.0623],\n",
      "        [0.0084, 0.0062, 0.0020, 0.4701, 0.0075, 0.0022, 0.0046, 0.4335, 0.0019,\n",
      "         0.0637]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0090, 0.0067, 0.0023, 0.4949, 0.0085, 0.0024, 0.0053, 0.4160, 0.0021,\n",
      "        0.0528], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0092, 0.0068, 0.0023, 0.4611, 0.0084, 0.0023, 0.0051, 0.4495, 0.0021,\n",
      "         0.0534],\n",
      "        [0.0091, 0.0067, 0.0023, 0.4982, 0.0085, 0.0024, 0.0052, 0.4120, 0.0021,\n",
      "         0.0536]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0087, 0.0066, 0.0023, 0.5267, 0.0084, 0.0024, 0.0053, 0.3856, 0.0021,\n",
      "         0.0520],\n",
      "        [0.0089, 0.0068, 0.0023, 0.4919, 0.0084, 0.0024, 0.0053, 0.4200, 0.0021,\n",
      "         0.0519]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0094, 0.0067, 0.0023, 0.4785, 0.0088, 0.0025, 0.0056, 0.4212, 0.0022,\n",
      "        0.0626], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0097, 0.0069, 0.0023, 0.4463, 0.0089, 0.0024, 0.0054, 0.4519, 0.0022,\n",
      "         0.0642],\n",
      "        [0.0094, 0.0066, 0.0023, 0.4825, 0.0088, 0.0025, 0.0054, 0.4172, 0.0022,\n",
      "         0.0631]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0091, 0.0067, 0.0023, 0.5075, 0.0087, 0.0025, 0.0060, 0.3942, 0.0022,\n",
      "         0.0608],\n",
      "        [0.0094, 0.0069, 0.0023, 0.4750, 0.0088, 0.0025, 0.0059, 0.4249, 0.0022,\n",
      "         0.0621]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0090, 0.0065, 0.0021, 0.4996, 0.0081, 0.0022, 0.0047, 0.4103, 0.0020,\n",
      "        0.0555], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0089, 0.0064, 0.0021, 0.4683, 0.0080, 0.0022, 0.0044, 0.4399, 0.0019,\n",
      "         0.0581],\n",
      "        [0.0090, 0.0064, 0.0021, 0.5035, 0.0081, 0.0022, 0.0046, 0.4063, 0.0020,\n",
      "         0.0557]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0089, 0.0066, 0.0021, 0.5291, 0.0081, 0.0022, 0.0050, 0.3829, 0.0021,\n",
      "         0.0528],\n",
      "        [0.0089, 0.0066, 0.0021, 0.4960, 0.0081, 0.0022, 0.0049, 0.4140, 0.0020,\n",
      "         0.0552]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0095, 0.0069, 0.0023, 0.4692, 0.0084, 0.0023, 0.0050, 0.4401, 0.0020,\n",
      "        0.0542], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0098, 0.0068, 0.0023, 0.4394, 0.0084, 0.0023, 0.0048, 0.4681, 0.0019,\n",
      "         0.0563],\n",
      "        [0.0097, 0.0069, 0.0023, 0.4734, 0.0085, 0.0024, 0.0049, 0.4352, 0.0020,\n",
      "         0.0548]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0095, 0.0069, 0.0023, 0.4972, 0.0085, 0.0024, 0.0055, 0.4137, 0.0021,\n",
      "         0.0519],\n",
      "        [0.0094, 0.0069, 0.0023, 0.4656, 0.0083, 0.0023, 0.0051, 0.4445, 0.0020,\n",
      "         0.0535]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0079, 0.0062, 0.0020, 0.4859, 0.0072, 0.0021, 0.0043, 0.4266, 0.0017,\n",
      "        0.0562], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0081, 0.0060, 0.0020, 0.4538, 0.0072, 0.0021, 0.0041, 0.4570, 0.0016,\n",
      "         0.0581],\n",
      "        [0.0080, 0.0061, 0.0020, 0.4890, 0.0073, 0.0021, 0.0042, 0.4226, 0.0017,\n",
      "         0.0571]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0077, 0.0063, 0.0020, 0.5152, 0.0072, 0.0021, 0.0046, 0.3985, 0.0017,\n",
      "         0.0547],\n",
      "        [0.0078, 0.0062, 0.0020, 0.4829, 0.0072, 0.0021, 0.0045, 0.4304, 0.0017,\n",
      "         0.0553]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0082, 0.0065, 0.0020, 0.4467, 0.0076, 0.0021, 0.0046, 0.4669, 0.0019,\n",
      "        0.0536], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0080, 0.0063, 0.0019, 0.4181, 0.0072, 0.0020, 0.0041, 0.4951, 0.0017,\n",
      "         0.0556],\n",
      "        [0.0084, 0.0065, 0.0020, 0.4508, 0.0076, 0.0021, 0.0044, 0.4622, 0.0019,\n",
      "         0.0542]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0084, 0.0067, 0.0020, 0.4735, 0.0079, 0.0022, 0.0050, 0.4412, 0.0020,\n",
      "         0.0511],\n",
      "        [0.0081, 0.0065, 0.0019, 0.4429, 0.0075, 0.0021, 0.0047, 0.4714, 0.0019,\n",
      "         0.0530]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0082, 0.0061, 0.0020, 0.4894, 0.0072, 0.0022, 0.0045, 0.4211, 0.0020,\n",
      "        0.0574], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0088, 0.0062, 0.0021, 0.4571, 0.0075, 0.0022, 0.0043, 0.4512, 0.0020,\n",
      "         0.0586],\n",
      "        [0.0082, 0.0060, 0.0020, 0.4932, 0.0072, 0.0022, 0.0044, 0.4169, 0.0020,\n",
      "         0.0579]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0076, 0.0060, 0.0019, 0.5189, 0.0069, 0.0022, 0.0047, 0.3936, 0.0020,\n",
      "         0.0562],\n",
      "        [0.0081, 0.0062, 0.0020, 0.4857, 0.0072, 0.0022, 0.0047, 0.4251, 0.0020,\n",
      "         0.0567]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0070, 0.0054, 0.0017, 0.4882, 0.0062, 0.0019, 0.0041, 0.4290, 0.0017,\n",
      "        0.0547], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0072, 0.0054, 0.0017, 0.4596, 0.0062, 0.0019, 0.0039, 0.4558, 0.0017,\n",
      "         0.0567],\n",
      "        [0.0071, 0.0054, 0.0017, 0.4916, 0.0062, 0.0019, 0.0041, 0.4258, 0.0017,\n",
      "         0.0547]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0070, 0.0055, 0.0017, 0.5144, 0.0063, 0.0019, 0.0043, 0.4046, 0.0017,\n",
      "         0.0525],\n",
      "        [0.0071, 0.0055, 0.0017, 0.4851, 0.0062, 0.0019, 0.0042, 0.4321, 0.0017,\n",
      "         0.0545]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0089, 0.0064, 0.0022, 0.4673, 0.0082, 0.0023, 0.0042, 0.4335, 0.0019,\n",
      "        0.0649], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0093, 0.0065, 0.0022, 0.4339, 0.0083, 0.0023, 0.0040, 0.4651, 0.0019,\n",
      "         0.0665],\n",
      "        [0.0089, 0.0063, 0.0021, 0.4715, 0.0081, 0.0023, 0.0041, 0.4292, 0.0019,\n",
      "         0.0655]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0083, 0.0062, 0.0021, 0.4971, 0.0079, 0.0023, 0.0044, 0.4069, 0.0019,\n",
      "         0.0628],\n",
      "        [0.0090, 0.0065, 0.0022, 0.4632, 0.0083, 0.0024, 0.0044, 0.4380, 0.0020,\n",
      "         0.0642]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0076, 0.0062, 0.0020, 0.4964, 0.0074, 0.0023, 0.0046, 0.4031, 0.0018,\n",
      "        0.0685], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0077, 0.0063, 0.0020, 0.4649, 0.0074, 0.0023, 0.0044, 0.4314, 0.0018,\n",
      "         0.0717],\n",
      "        [0.0078, 0.0062, 0.0020, 0.4997, 0.0075, 0.0023, 0.0045, 0.3990, 0.0018,\n",
      "         0.0691]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0075, 0.0063, 0.0020, 0.5260, 0.0074, 0.0024, 0.0047, 0.3767, 0.0019,\n",
      "         0.0652],\n",
      "        [0.0075, 0.0063, 0.0020, 0.4935, 0.0073, 0.0023, 0.0046, 0.4068, 0.0018,\n",
      "         0.0677]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0088, 0.0065, 0.0022, 0.4914, 0.0084, 0.0024, 0.0044, 0.4129, 0.0019,\n",
      "        0.0611], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0090, 0.0064, 0.0021, 0.4573, 0.0083, 0.0023, 0.0041, 0.4459, 0.0019,\n",
      "         0.0627],\n",
      "        [0.0090, 0.0065, 0.0022, 0.4946, 0.0084, 0.0024, 0.0043, 0.4082, 0.0019,\n",
      "         0.0625]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0088, 0.0066, 0.0022, 0.5240, 0.0085, 0.0024, 0.0048, 0.3813, 0.0020,\n",
      "         0.0595],\n",
      "        [0.0087, 0.0066, 0.0021, 0.4885, 0.0083, 0.0024, 0.0045, 0.4173, 0.0019,\n",
      "         0.0597]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0086, 0.0061, 0.0021, 0.5064, 0.0080, 0.0023, 0.0045, 0.4025, 0.0019,\n",
      "        0.0578], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0088, 0.0063, 0.0021, 0.4752, 0.0080, 0.0023, 0.0043, 0.4312, 0.0019,\n",
      "         0.0599],\n",
      "        [0.0086, 0.0061, 0.0021, 0.5093, 0.0080, 0.0023, 0.0044, 0.3997, 0.0019,\n",
      "         0.0577]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0083, 0.0060, 0.0020, 0.5350, 0.0079, 0.0023, 0.0045, 0.3764, 0.0019,\n",
      "         0.0557],\n",
      "        [0.0085, 0.0062, 0.0021, 0.5038, 0.0079, 0.0023, 0.0046, 0.4049, 0.0019,\n",
      "         0.0578]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0077, 0.0060, 0.0020, 0.4985, 0.0072, 0.0022, 0.0040, 0.4135, 0.0017,\n",
      "        0.0572], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0079, 0.0060, 0.0020, 0.4673, 0.0072, 0.0022, 0.0038, 0.4422, 0.0017,\n",
      "         0.0597],\n",
      "        [0.0078, 0.0060, 0.0020, 0.5027, 0.0072, 0.0022, 0.0039, 0.4090, 0.0017,\n",
      "         0.0574]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0076, 0.0060, 0.0020, 0.5267, 0.0072, 0.0022, 0.0043, 0.3882, 0.0018,\n",
      "         0.0539],\n",
      "        [0.0076, 0.0060, 0.0020, 0.4944, 0.0072, 0.0022, 0.0042, 0.4179, 0.0017,\n",
      "         0.0568]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0076, 0.0055, 0.0019, 0.4843, 0.0066, 0.0020, 0.0038, 0.4284, 0.0014,\n",
      "        0.0585], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0078, 0.0054, 0.0020, 0.4567, 0.0067, 0.0020, 0.0036, 0.4543, 0.0014,\n",
      "         0.0602],\n",
      "        [0.0077, 0.0055, 0.0019, 0.4872, 0.0067, 0.0020, 0.0037, 0.4249, 0.0014,\n",
      "         0.0590]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0076, 0.0056, 0.0019, 0.5098, 0.0067, 0.0020, 0.0041, 0.4042, 0.0015,\n",
      "         0.0566],\n",
      "        [0.0074, 0.0055, 0.0019, 0.4813, 0.0066, 0.0020, 0.0038, 0.4319, 0.0014,\n",
      "         0.0581]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0079, 0.0063, 0.0020, 0.4864, 0.0075, 0.0023, 0.0044, 0.4232, 0.0017,\n",
      "        0.0583], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0082, 0.0064, 0.0021, 0.4559, 0.0076, 0.0023, 0.0043, 0.4511, 0.0017,\n",
      "         0.0603],\n",
      "        [0.0080, 0.0062, 0.0020, 0.4900, 0.0075, 0.0023, 0.0043, 0.4189, 0.0017,\n",
      "         0.0590]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0077, 0.0063, 0.0020, 0.5136, 0.0074, 0.0022, 0.0046, 0.3984, 0.0017,\n",
      "         0.0561],\n",
      "        [0.0078, 0.0064, 0.0020, 0.4829, 0.0075, 0.0022, 0.0046, 0.4273, 0.0017,\n",
      "         0.0576]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0086, 0.0057, 0.0020, 0.5030, 0.0077, 0.0022, 0.0041, 0.4098, 0.0019,\n",
      "        0.0550], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0088, 0.0058, 0.0021, 0.4702, 0.0078, 0.0022, 0.0039, 0.4385, 0.0018,\n",
      "         0.0588],\n",
      "        [0.0087, 0.0056, 0.0020, 0.5074, 0.0077, 0.0022, 0.0039, 0.4053, 0.0019,\n",
      "         0.0552]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0083, 0.0056, 0.0020, 0.5330, 0.0075, 0.0022, 0.0041, 0.3839, 0.0019,\n",
      "         0.0514],\n",
      "        [0.0085, 0.0058, 0.0020, 0.4990, 0.0077, 0.0022, 0.0042, 0.4139, 0.0019,\n",
      "         0.0547]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0085, 0.0061, 0.0022, 0.5078, 0.0079, 0.0022, 0.0048, 0.4134, 0.0020,\n",
      "        0.0451], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0089, 0.0063, 0.0022, 0.4726, 0.0080, 0.0022, 0.0047, 0.4454, 0.0019,\n",
      "         0.0478],\n",
      "        [0.0087, 0.0061, 0.0022, 0.5103, 0.0080, 0.0022, 0.0047, 0.4102, 0.0020,\n",
      "         0.0457]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0082, 0.0060, 0.0021, 0.5382, 0.0078, 0.0022, 0.0049, 0.3859, 0.0020,\n",
      "         0.0428],\n",
      "        [0.0084, 0.0062, 0.0022, 0.5055, 0.0078, 0.0022, 0.0050, 0.4163, 0.0020,\n",
      "         0.0446]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0085, 0.0061, 0.0021, 0.4830, 0.0073, 0.0020, 0.0043, 0.4350, 0.0018,\n",
      "        0.0499], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0086, 0.0059, 0.0021, 0.4500, 0.0073, 0.0020, 0.0038, 0.4674, 0.0017,\n",
      "         0.0513],\n",
      "        [0.0086, 0.0060, 0.0021, 0.4870, 0.0074, 0.0021, 0.0042, 0.4304, 0.0018,\n",
      "         0.0506]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0085, 0.0062, 0.0021, 0.5151, 0.0074, 0.0021, 0.0048, 0.4035, 0.0020,\n",
      "         0.0483],\n",
      "        [0.0084, 0.0061, 0.0021, 0.4793, 0.0073, 0.0020, 0.0044, 0.4393, 0.0018,\n",
      "         0.0492]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0088, 0.0062, 0.0021, 0.4813, 0.0079, 0.0022, 0.0042, 0.4289, 0.0018,\n",
      "        0.0566], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0092, 0.0062, 0.0021, 0.4490, 0.0080, 0.0022, 0.0039, 0.4593, 0.0017,\n",
      "         0.0583],\n",
      "        [0.0089, 0.0062, 0.0021, 0.4847, 0.0079, 0.0022, 0.0041, 0.4247, 0.0018,\n",
      "         0.0574]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0086, 0.0063, 0.0021, 0.5102, 0.0077, 0.0022, 0.0046, 0.4014, 0.0018,\n",
      "         0.0551],\n",
      "        [0.0088, 0.0062, 0.0021, 0.4780, 0.0078, 0.0022, 0.0043, 0.4330, 0.0018,\n",
      "         0.0557]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0089, 0.0061, 0.0021, 0.4939, 0.0080, 0.0023, 0.0048, 0.4159, 0.0020,\n",
      "        0.0560], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0091, 0.0062, 0.0021, 0.4622, 0.0080, 0.0022, 0.0046, 0.4453, 0.0020,\n",
      "         0.0582],\n",
      "        [0.0090, 0.0061, 0.0022, 0.4964, 0.0080, 0.0023, 0.0047, 0.4127, 0.0020,\n",
      "         0.0566]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0086, 0.0060, 0.0021, 0.5231, 0.0079, 0.0023, 0.0050, 0.3897, 0.0020,\n",
      "         0.0534],\n",
      "        [0.0087, 0.0062, 0.0021, 0.4916, 0.0079, 0.0023, 0.0049, 0.4190, 0.0020,\n",
      "         0.0553]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0073, 0.0057, 0.0019, 0.5138, 0.0067, 0.0020, 0.0046, 0.3940, 0.0018,\n",
      "        0.0621], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0075, 0.0057, 0.0020, 0.4840, 0.0067, 0.0020, 0.0044, 0.4217, 0.0018,\n",
      "         0.0643],\n",
      "        [0.0073, 0.0056, 0.0019, 0.5159, 0.0066, 0.0020, 0.0045, 0.3920, 0.0018,\n",
      "         0.0624]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0071, 0.0057, 0.0019, 0.5415, 0.0067, 0.0020, 0.0049, 0.3687, 0.0019,\n",
      "         0.0596],\n",
      "        [0.0073, 0.0058, 0.0020, 0.5117, 0.0066, 0.0020, 0.0048, 0.3966, 0.0018,\n",
      "         0.0614]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0088, 0.0064, 0.0022, 0.4980, 0.0079, 0.0023, 0.0050, 0.4084, 0.0019,\n",
      "        0.0591], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0091, 0.0063, 0.0022, 0.4662, 0.0079, 0.0023, 0.0047, 0.4378, 0.0019,\n",
      "         0.0617],\n",
      "        [0.0089, 0.0064, 0.0022, 0.5011, 0.0079, 0.0023, 0.0049, 0.4046, 0.0019,\n",
      "         0.0598]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0087, 0.0065, 0.0022, 0.5265, 0.0079, 0.0023, 0.0052, 0.3824, 0.0019,\n",
      "         0.0564],\n",
      "        [0.0087, 0.0065, 0.0022, 0.4950, 0.0078, 0.0023, 0.0051, 0.4120, 0.0019,\n",
      "         0.0584]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0094, 0.0065, 0.0023, 0.4871, 0.0081, 0.0023, 0.0043, 0.4156, 0.0020,\n",
      "        0.0625], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0098, 0.0065, 0.0022, 0.4516, 0.0081, 0.0022, 0.0040, 0.4513, 0.0021,\n",
      "         0.0621],\n",
      "        [0.0095, 0.0064, 0.0023, 0.4924, 0.0081, 0.0023, 0.0042, 0.4092, 0.0020,\n",
      "         0.0636]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0090, 0.0064, 0.0023, 0.5194, 0.0079, 0.0023, 0.0046, 0.3840, 0.0020,\n",
      "         0.0622],\n",
      "        [0.0093, 0.0065, 0.0023, 0.4821, 0.0080, 0.0023, 0.0045, 0.4218, 0.0021,\n",
      "         0.0611]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0095, 0.0066, 0.0022, 0.4808, 0.0082, 0.0023, 0.0046, 0.4195, 0.0019,\n",
      "        0.0644], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0098, 0.0067, 0.0022, 0.4478, 0.0082, 0.0023, 0.0043, 0.4509, 0.0018,\n",
      "         0.0660],\n",
      "        [0.0096, 0.0066, 0.0022, 0.4855, 0.0082, 0.0023, 0.0045, 0.4137, 0.0019,\n",
      "         0.0655]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0092, 0.0065, 0.0022, 0.5115, 0.0081, 0.0024, 0.0049, 0.3905, 0.0019,\n",
      "         0.0627],\n",
      "        [0.0094, 0.0067, 0.0022, 0.4763, 0.0082, 0.0023, 0.0047, 0.4252, 0.0019,\n",
      "         0.0631]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1: Train=1231.2156958007813 Valid=980.6181746773098\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0088, 0.0059, 0.0022, 0.4951, 0.0079, 0.0023, 0.0040, 0.4158, 0.0017,\n",
      "        0.0565], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0088, 0.0059, 0.0021, 0.4656, 0.0078, 0.0022, 0.0038, 0.4434, 0.0016,\n",
      "         0.0588],\n",
      "        [0.0088, 0.0058, 0.0022, 0.4992, 0.0079, 0.0023, 0.0039, 0.4116, 0.0016,\n",
      "         0.0567]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0085, 0.0059, 0.0022, 0.5241, 0.0079, 0.0023, 0.0041, 0.3894, 0.0017,\n",
      "         0.0541],\n",
      "        [0.0087, 0.0060, 0.0022, 0.4914, 0.0079, 0.0022, 0.0041, 0.4198, 0.0017,\n",
      "         0.0561]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0084, 0.0059, 0.0020, 0.5076, 0.0077, 0.0022, 0.0045, 0.4054, 0.0019,\n",
      "        0.0544], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0088, 0.0059, 0.0021, 0.4721, 0.0079, 0.0022, 0.0041, 0.4381, 0.0018,\n",
      "         0.0570],\n",
      "        [0.0084, 0.0058, 0.0020, 0.5106, 0.0077, 0.0022, 0.0043, 0.4026, 0.0018,\n",
      "         0.0546]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0079, 0.0058, 0.0020, 0.5386, 0.0075, 0.0022, 0.0049, 0.3776, 0.0019,\n",
      "         0.0517],\n",
      "        [0.0084, 0.0059, 0.0020, 0.5046, 0.0077, 0.0022, 0.0046, 0.4084, 0.0019,\n",
      "         0.0542]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0077, 0.0056, 0.0020, 0.5233, 0.0070, 0.0021, 0.0044, 0.4007, 0.0017,\n",
      "        0.0456], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0081, 0.0056, 0.0020, 0.4900, 0.0070, 0.0021, 0.0039, 0.4313, 0.0017,\n",
      "         0.0483],\n",
      "        [0.0077, 0.0056, 0.0020, 0.5256, 0.0069, 0.0021, 0.0042, 0.3985, 0.0017,\n",
      "         0.0457]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0073, 0.0056, 0.0020, 0.5529, 0.0069, 0.0021, 0.0049, 0.3734, 0.0017,\n",
      "         0.0431],\n",
      "        [0.0077, 0.0057, 0.0020, 0.5211, 0.0070, 0.0021, 0.0045, 0.4026, 0.0017,\n",
      "         0.0455]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0079, 0.0058, 0.0020, 0.4840, 0.0069, 0.0020, 0.0048, 0.4258, 0.0016,\n",
      "        0.0592], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0077, 0.0054, 0.0019, 0.4565, 0.0066, 0.0020, 0.0044, 0.4536, 0.0015,\n",
      "         0.0603],\n",
      "        [0.0080, 0.0057, 0.0020, 0.4876, 0.0070, 0.0021, 0.0047, 0.4215, 0.0016,\n",
      "         0.0597]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0082, 0.0062, 0.0022, 0.5111, 0.0074, 0.0022, 0.0054, 0.3979, 0.0018,\n",
      "         0.0577],\n",
      "        [0.0077, 0.0058, 0.0020, 0.4805, 0.0069, 0.0020, 0.0049, 0.4299, 0.0016,\n",
      "         0.0585]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0082, 0.0050, 0.0019, 0.5214, 0.0067, 0.0020, 0.0038, 0.3986, 0.0016,\n",
      "        0.0507], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0082, 0.0050, 0.0019, 0.4874, 0.0066, 0.0020, 0.0036, 0.4308, 0.0016,\n",
      "         0.0529],\n",
      "        [0.0083, 0.0050, 0.0020, 0.5244, 0.0067, 0.0020, 0.0037, 0.3953, 0.0016,\n",
      "         0.0509]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0080, 0.0051, 0.0020, 0.5539, 0.0067, 0.0021, 0.0041, 0.3681, 0.0017,\n",
      "         0.0484],\n",
      "        [0.0081, 0.0051, 0.0019, 0.5185, 0.0066, 0.0020, 0.0039, 0.4017, 0.0016,\n",
      "         0.0505]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0070, 0.0047, 0.0018, 0.4996, 0.0065, 0.0020, 0.0035, 0.4250, 0.0015,\n",
      "        0.0484], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0076, 0.0048, 0.0019, 0.4685, 0.0068, 0.0021, 0.0033, 0.4530, 0.0015,\n",
      "         0.0507],\n",
      "        [0.0071, 0.0046, 0.0018, 0.5025, 0.0065, 0.0020, 0.0034, 0.4218, 0.0015,\n",
      "         0.0488]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0067, 0.0046, 0.0018, 0.5272, 0.0062, 0.0020, 0.0036, 0.4001, 0.0015,\n",
      "         0.0464],\n",
      "        [0.0070, 0.0047, 0.0018, 0.4967, 0.0065, 0.0020, 0.0036, 0.4281, 0.0015,\n",
      "         0.0481]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0075, 0.0050, 0.0019, 0.4915, 0.0064, 0.0020, 0.0042, 0.4294, 0.0016,\n",
      "        0.0505], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0078, 0.0050, 0.0019, 0.4592, 0.0064, 0.0020, 0.0038, 0.4605, 0.0015,\n",
      "         0.0519],\n",
      "        [0.0076, 0.0050, 0.0019, 0.4949, 0.0063, 0.0020, 0.0040, 0.4255, 0.0016,\n",
      "         0.0513]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0073, 0.0051, 0.0020, 0.5210, 0.0063, 0.0020, 0.0044, 0.4019, 0.0016,\n",
      "         0.0485],\n",
      "        [0.0075, 0.0051, 0.0020, 0.4884, 0.0064, 0.0020, 0.0043, 0.4331, 0.0016,\n",
      "         0.0496]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0075, 0.0045, 0.0018, 0.4826, 0.0062, 0.0019, 0.0035, 0.4428, 0.0015,\n",
      "        0.0478], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0077, 0.0044, 0.0018, 0.4479, 0.0061, 0.0019, 0.0033, 0.4755, 0.0014,\n",
      "         0.0499],\n",
      "        [0.0076, 0.0044, 0.0018, 0.4868, 0.0061, 0.0019, 0.0034, 0.4382, 0.0014,\n",
      "         0.0484]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0072, 0.0045, 0.0018, 0.5139, 0.0060, 0.0019, 0.0038, 0.4144, 0.0015,\n",
      "         0.0451],\n",
      "        [0.0075, 0.0045, 0.0018, 0.4785, 0.0062, 0.0019, 0.0036, 0.4473, 0.0015,\n",
      "         0.0472]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0069, 0.0048, 0.0019, 0.4727, 0.0059, 0.0020, 0.0041, 0.4523, 0.0015,\n",
      "        0.0479], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0070, 0.0045, 0.0018, 0.4452, 0.0057, 0.0019, 0.0035, 0.4817, 0.0013,\n",
      "         0.0474],\n",
      "        [0.0069, 0.0047, 0.0019, 0.4744, 0.0058, 0.0020, 0.0039, 0.4500, 0.0015,\n",
      "         0.0488]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0066, 0.0049, 0.0019, 0.4995, 0.0058, 0.0021, 0.0045, 0.4253, 0.0016,\n",
      "         0.0478],\n",
      "        [0.0069, 0.0049, 0.0019, 0.4712, 0.0059, 0.0020, 0.0043, 0.4546, 0.0015,\n",
      "         0.0469]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0077, 0.0052, 0.0021, 0.4983, 0.0068, 0.0023, 0.0042, 0.4209, 0.0017,\n",
      "        0.0509], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0080, 0.0053, 0.0021, 0.4649, 0.0069, 0.0022, 0.0040, 0.4524, 0.0017,\n",
      "         0.0525],\n",
      "        [0.0078, 0.0052, 0.0021, 0.5032, 0.0069, 0.0023, 0.0041, 0.4154, 0.0017,\n",
      "         0.0515]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0075, 0.0052, 0.0021, 0.5307, 0.0069, 0.0023, 0.0044, 0.3900, 0.0017,\n",
      "         0.0491],\n",
      "        [0.0076, 0.0053, 0.0021, 0.4938, 0.0068, 0.0022, 0.0043, 0.4259, 0.0017,\n",
      "         0.0504]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0082, 0.0052, 0.0022, 0.5114, 0.0073, 0.0023, 0.0043, 0.4145, 0.0016,\n",
      "        0.0431], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0084, 0.0050, 0.0021, 0.4778, 0.0071, 0.0022, 0.0039, 0.4466, 0.0016,\n",
      "         0.0452],\n",
      "        [0.0083, 0.0051, 0.0022, 0.5142, 0.0072, 0.0022, 0.0041, 0.4114, 0.0016,\n",
      "         0.0437]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0080, 0.0053, 0.0022, 0.5405, 0.0073, 0.0023, 0.0047, 0.3871, 0.0017,\n",
      "         0.0410],\n",
      "        [0.0082, 0.0053, 0.0022, 0.5086, 0.0073, 0.0023, 0.0045, 0.4177, 0.0017,\n",
      "         0.0424]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0088, 0.0056, 0.0025, 0.5042, 0.0074, 0.0025, 0.0049, 0.4129, 0.0018,\n",
      "        0.0496], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0093, 0.0056, 0.0025, 0.4651, 0.0076, 0.0025, 0.0046, 0.4519, 0.0017,\n",
      "         0.0492],\n",
      "        [0.0089, 0.0055, 0.0025, 0.5077, 0.0074, 0.0025, 0.0048, 0.4087, 0.0018,\n",
      "         0.0503]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0084, 0.0055, 0.0024, 0.5408, 0.0072, 0.0025, 0.0053, 0.3773, 0.0018,\n",
      "         0.0488],\n",
      "        [0.0086, 0.0056, 0.0024, 0.5013, 0.0073, 0.0025, 0.0051, 0.4168, 0.0018,\n",
      "         0.0485]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0077, 0.0050, 0.0022, 0.5047, 0.0061, 0.0021, 0.0042, 0.4186, 0.0015,\n",
      "        0.0479], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0079, 0.0049, 0.0021, 0.4698, 0.0061, 0.0021, 0.0039, 0.4525, 0.0014,\n",
      "         0.0492],\n",
      "        [0.0077, 0.0049, 0.0022, 0.5073, 0.0061, 0.0021, 0.0041, 0.4153, 0.0015,\n",
      "         0.0486]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0073, 0.0050, 0.0021, 0.5352, 0.0061, 0.0022, 0.0046, 0.3892, 0.0016,\n",
      "         0.0466],\n",
      "        [0.0076, 0.0050, 0.0022, 0.5022, 0.0061, 0.0021, 0.0044, 0.4218, 0.0015,\n",
      "         0.0471]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0084, 0.0050, 0.0022, 0.4875, 0.0066, 0.0021, 0.0046, 0.4433, 0.0016,\n",
      "        0.0388], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0088, 0.0049, 0.0023, 0.4546, 0.0067, 0.0021, 0.0043, 0.4741, 0.0015,\n",
      "         0.0407],\n",
      "        [0.0084, 0.0049, 0.0022, 0.4923, 0.0065, 0.0021, 0.0045, 0.4385, 0.0015,\n",
      "         0.0391]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0079, 0.0052, 0.0022, 0.5182, 0.0065, 0.0021, 0.0050, 0.4144, 0.0016,\n",
      "         0.0369],\n",
      "        [0.0083, 0.0051, 0.0022, 0.4829, 0.0066, 0.0021, 0.0047, 0.4482, 0.0016,\n",
      "         0.0384]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0089, 0.0053, 0.0026, 0.5178, 0.0074, 0.0025, 0.0053, 0.4047, 0.0017,\n",
      "        0.0438], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0094, 0.0055, 0.0027, 0.4823, 0.0076, 0.0025, 0.0055, 0.4366, 0.0018,\n",
      "         0.0462],\n",
      "        [0.0089, 0.0052, 0.0025, 0.5215, 0.0074, 0.0025, 0.0052, 0.4011, 0.0017,\n",
      "         0.0439]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0085, 0.0053, 0.0025, 0.5491, 0.0073, 0.0024, 0.0052, 0.3766, 0.0017,\n",
      "         0.0415],\n",
      "        [0.0089, 0.0054, 0.0026, 0.5145, 0.0074, 0.0025, 0.0055, 0.4079, 0.0018,\n",
      "         0.0436]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0084, 0.0059, 0.0024, 0.4939, 0.0071, 0.0024, 0.0050, 0.4283, 0.0017,\n",
      "        0.0447], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0086, 0.0057, 0.0024, 0.4632, 0.0071, 0.0024, 0.0046, 0.4570, 0.0017,\n",
      "         0.0473],\n",
      "        [0.0086, 0.0058, 0.0025, 0.4972, 0.0072, 0.0024, 0.0048, 0.4248, 0.0017,\n",
      "         0.0450]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0084, 0.0063, 0.0025, 0.5223, 0.0073, 0.0024, 0.0056, 0.4014, 0.0018,\n",
      "         0.0419],\n",
      "        [0.0083, 0.0060, 0.0024, 0.4908, 0.0071, 0.0024, 0.0052, 0.4316, 0.0018,\n",
      "         0.0443]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0084, 0.0055, 0.0026, 0.5406, 0.0068, 0.0024, 0.0055, 0.3846, 0.0017,\n",
      "        0.0419], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0088, 0.0055, 0.0026, 0.5065, 0.0070, 0.0024, 0.0053, 0.4174, 0.0017,\n",
      "         0.0429],\n",
      "        [0.0085, 0.0054, 0.0026, 0.5443, 0.0068, 0.0024, 0.0054, 0.3801, 0.0016,\n",
      "         0.0428]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0080, 0.0055, 0.0026, 0.5710, 0.0065, 0.0023, 0.0058, 0.3559, 0.0016,\n",
      "         0.0407],\n",
      "        [0.0083, 0.0056, 0.0026, 0.5372, 0.0067, 0.0024, 0.0057, 0.3889, 0.0017,\n",
      "         0.0410]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0097, 0.0063, 0.0031, 0.5171, 0.0076, 0.0027, 0.0062, 0.3931, 0.0019,\n",
      "        0.0522], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0098, 0.0062, 0.0030, 0.4850, 0.0076, 0.0027, 0.0058, 0.4257, 0.0019,\n",
      "         0.0524],\n",
      "        [0.0097, 0.0062, 0.0030, 0.5194, 0.0076, 0.0027, 0.0061, 0.3901, 0.0019,\n",
      "         0.0532]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0095, 0.0063, 0.0032, 0.5492, 0.0075, 0.0028, 0.0065, 0.3615, 0.0020,\n",
      "         0.0515],\n",
      "        [0.0097, 0.0064, 0.0031, 0.5151, 0.0076, 0.0027, 0.0064, 0.3960, 0.0020,\n",
      "         0.0511]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0094, 0.0058, 0.0029, 0.5404, 0.0075, 0.0027, 0.0063, 0.3661, 0.0018,\n",
      "        0.0570], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0098, 0.0058, 0.0029, 0.5071, 0.0076, 0.0027, 0.0062, 0.3950, 0.0019,\n",
      "         0.0610],\n",
      "        [0.0094, 0.0057, 0.0029, 0.5434, 0.0075, 0.0027, 0.0061, 0.3638, 0.0018,\n",
      "         0.0566]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0088, 0.0058, 0.0029, 0.5707, 0.0073, 0.0027, 0.0063, 0.3409, 0.0018,\n",
      "         0.0527],\n",
      "        [0.0093, 0.0059, 0.0030, 0.5375, 0.0075, 0.0027, 0.0064, 0.3685, 0.0019,\n",
      "         0.0572]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0111, 0.0066, 0.0033, 0.5001, 0.0085, 0.0031, 0.0067, 0.4035, 0.0020,\n",
      "        0.0551], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0114, 0.0066, 0.0033, 0.4656, 0.0085, 0.0031, 0.0063, 0.4357, 0.0020,\n",
      "         0.0573],\n",
      "        [0.0111, 0.0065, 0.0033, 0.5041, 0.0084, 0.0031, 0.0064, 0.3997, 0.0020,\n",
      "         0.0554]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0108, 0.0067, 0.0034, 0.5313, 0.0084, 0.0031, 0.0070, 0.3743, 0.0020,\n",
      "         0.0530],\n",
      "        [0.0110, 0.0068, 0.0034, 0.4960, 0.0085, 0.0031, 0.0069, 0.4076, 0.0020,\n",
      "         0.0546]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0087, 0.0056, 0.0029, 0.5179, 0.0065, 0.0026, 0.0056, 0.3865, 0.0015,\n",
      "        0.0622], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0095, 0.0055, 0.0029, 0.4883, 0.0068, 0.0027, 0.0050, 0.4137, 0.0015,\n",
      "         0.0641],\n",
      "        [0.0088, 0.0055, 0.0028, 0.5209, 0.0065, 0.0026, 0.0054, 0.3830, 0.0015,\n",
      "         0.0630]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0086, 0.0058, 0.0029, 0.5455, 0.0064, 0.0026, 0.0063, 0.3600, 0.0016,\n",
      "         0.0603],\n",
      "        [0.0087, 0.0057, 0.0029, 0.5152, 0.0065, 0.0026, 0.0058, 0.3897, 0.0016,\n",
      "         0.0614]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0114, 0.0066, 0.0035, 0.5328, 0.0087, 0.0030, 0.0070, 0.3716, 0.0021,\n",
      "        0.0534], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0120, 0.0067, 0.0036, 0.4995, 0.0091, 0.0031, 0.0069, 0.4015, 0.0021,\n",
      "         0.0554],\n",
      "        [0.0115, 0.0065, 0.0035, 0.5354, 0.0087, 0.0030, 0.0068, 0.3683, 0.0021,\n",
      "         0.0541]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0107, 0.0065, 0.0034, 0.5636, 0.0081, 0.0029, 0.0071, 0.3440, 0.0020,\n",
      "         0.0515],\n",
      "        [0.0113, 0.0067, 0.0035, 0.5303, 0.0087, 0.0030, 0.0072, 0.3746, 0.0021,\n",
      "         0.0526]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0121, 0.0067, 0.0036, 0.5291, 0.0082, 0.0030, 0.0065, 0.3814, 0.0019,\n",
      "        0.0475], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0126, 0.0065, 0.0036, 0.4935, 0.0082, 0.0030, 0.0058, 0.4151, 0.0018,\n",
      "         0.0498],\n",
      "        [0.0122, 0.0066, 0.0036, 0.5319, 0.0082, 0.0030, 0.0062, 0.3784, 0.0019,\n",
      "         0.0480]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0115, 0.0068, 0.0036, 0.5601, 0.0081, 0.0029, 0.0071, 0.3531, 0.0019,\n",
      "         0.0449],\n",
      "        [0.0119, 0.0068, 0.0037, 0.5266, 0.0082, 0.0030, 0.0068, 0.3842, 0.0019,\n",
      "         0.0470]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0108, 0.0065, 0.0036, 0.5139, 0.0081, 0.0033, 0.0076, 0.3850, 0.0019,\n",
      "        0.0593], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0117, 0.0066, 0.0037, 0.4807, 0.0085, 0.0034, 0.0069, 0.4170, 0.0020,\n",
      "         0.0594],\n",
      "        [0.0108, 0.0064, 0.0036, 0.5157, 0.0080, 0.0033, 0.0072, 0.3821, 0.0019,\n",
      "         0.0611]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0101, 0.0065, 0.0036, 0.5441, 0.0077, 0.0032, 0.0083, 0.3559, 0.0020,\n",
      "         0.0587],\n",
      "        [0.0108, 0.0066, 0.0036, 0.5124, 0.0081, 0.0033, 0.0079, 0.3877, 0.0020,\n",
      "         0.0575]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0116, 0.0069, 0.0041, 0.4991, 0.0088, 0.0034, 0.0070, 0.4005, 0.0019,\n",
      "        0.0567], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0124, 0.0069, 0.0041, 0.4663, 0.0092, 0.0035, 0.0067, 0.4301, 0.0019,\n",
      "         0.0588],\n",
      "        [0.0116, 0.0067, 0.0040, 0.5015, 0.0088, 0.0034, 0.0068, 0.3977, 0.0019,\n",
      "         0.0574]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0111, 0.0070, 0.0040, 0.5294, 0.0087, 0.0034, 0.0074, 0.3726, 0.0019,\n",
      "         0.0545],\n",
      "        [0.0116, 0.0070, 0.0041, 0.4975, 0.0089, 0.0034, 0.0073, 0.4025, 0.0019,\n",
      "         0.0559]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0121, 0.0066, 0.0039, 0.5051, 0.0084, 0.0033, 0.0064, 0.3875, 0.0018,\n",
      "        0.0649], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0121, 0.0064, 0.0038, 0.4762, 0.0082, 0.0032, 0.0058, 0.4171, 0.0017,\n",
      "         0.0655],\n",
      "        [0.0121, 0.0065, 0.0039, 0.5073, 0.0084, 0.0033, 0.0062, 0.3845, 0.0018,\n",
      "         0.0661]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0121, 0.0068, 0.0039, 0.5336, 0.0086, 0.0033, 0.0069, 0.3599, 0.0019,\n",
      "         0.0630],\n",
      "        [0.0120, 0.0067, 0.0039, 0.5032, 0.0084, 0.0033, 0.0067, 0.3904, 0.0018,\n",
      "         0.0636]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0115, 0.0072, 0.0039, 0.5010, 0.0084, 0.0032, 0.0074, 0.3894, 0.0021,\n",
      "        0.0661], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0115, 0.0067, 0.0038, 0.4698, 0.0083, 0.0031, 0.0066, 0.4202, 0.0020,\n",
      "         0.0680],\n",
      "        [0.0117, 0.0071, 0.0039, 0.5039, 0.0085, 0.0032, 0.0072, 0.3856, 0.0020,\n",
      "         0.0668]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0117, 0.0076, 0.0041, 0.5318, 0.0087, 0.0033, 0.0083, 0.3585, 0.0022,\n",
      "         0.0637],\n",
      "        [0.0112, 0.0072, 0.0039, 0.4984, 0.0083, 0.0032, 0.0076, 0.3927, 0.0021,\n",
      "         0.0653]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0134, 0.0073, 0.0040, 0.4858, 0.0093, 0.0035, 0.0069, 0.3938, 0.0024,\n",
      "        0.0736], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0132, 0.0071, 0.0039, 0.4497, 0.0090, 0.0034, 0.0063, 0.4298, 0.0023,\n",
      "         0.0753],\n",
      "        [0.0135, 0.0071, 0.0040, 0.4898, 0.0092, 0.0035, 0.0066, 0.3894, 0.0023,\n",
      "         0.0745]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0135, 0.0074, 0.0041, 0.5214, 0.0095, 0.0035, 0.0075, 0.3604, 0.0025,\n",
      "         0.0703],\n",
      "        [0.0133, 0.0075, 0.0040, 0.4821, 0.0093, 0.0035, 0.0071, 0.3982, 0.0024,\n",
      "         0.0724]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0123, 0.0066, 0.0040, 0.5099, 0.0084, 0.0033, 0.0074, 0.3769, 0.0020,\n",
      "        0.0691], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0128, 0.0065, 0.0040, 0.4736, 0.0084, 0.0034, 0.0072, 0.4087, 0.0020,\n",
      "         0.0734],\n",
      "        [0.0123, 0.0065, 0.0039, 0.5145, 0.0083, 0.0033, 0.0071, 0.3724, 0.0019,\n",
      "         0.0697]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0123, 0.0068, 0.0041, 0.5435, 0.0085, 0.0034, 0.0080, 0.3465, 0.0021,\n",
      "         0.0649],\n",
      "        [0.0123, 0.0068, 0.0041, 0.5053, 0.0084, 0.0033, 0.0078, 0.3814, 0.0020,\n",
      "         0.0685]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0116, 0.0073, 0.0039, 0.5212, 0.0087, 0.0035, 0.0080, 0.3757, 0.0023,\n",
      "        0.0578], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0122, 0.0074, 0.0040, 0.4822, 0.0089, 0.0035, 0.0077, 0.4103, 0.0023,\n",
      "         0.0613],\n",
      "        [0.0117, 0.0072, 0.0039, 0.5231, 0.0087, 0.0035, 0.0077, 0.3723, 0.0023,\n",
      "         0.0596]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0112, 0.0072, 0.0039, 0.5560, 0.0084, 0.0033, 0.0084, 0.3447, 0.0023,\n",
      "         0.0547],\n",
      "        [0.0115, 0.0074, 0.0039, 0.5196, 0.0086, 0.0034, 0.0083, 0.3789, 0.0023,\n",
      "         0.0560]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0130, 0.0075, 0.0042, 0.4970, 0.0094, 0.0037, 0.0071, 0.3832, 0.0021,\n",
      "        0.0729], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0131, 0.0074, 0.0042, 0.4600, 0.0093, 0.0037, 0.0065, 0.4177, 0.0020,\n",
      "         0.0762],\n",
      "        [0.0131, 0.0073, 0.0041, 0.5000, 0.0094, 0.0037, 0.0067, 0.3794, 0.0020,\n",
      "         0.0743]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0126, 0.0075, 0.0041, 0.5317, 0.0094, 0.0037, 0.0075, 0.3530, 0.0021,\n",
      "         0.0683],\n",
      "        [0.0129, 0.0077, 0.0042, 0.4943, 0.0095, 0.0037, 0.0074, 0.3868, 0.0021,\n",
      "         0.0714]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0107, 0.0066, 0.0038, 0.4973, 0.0079, 0.0032, 0.0070, 0.3953, 0.0019,\n",
      "        0.0664], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0112, 0.0065, 0.0038, 0.4625, 0.0080, 0.0032, 0.0064, 0.4240, 0.0018,\n",
      "         0.0726],\n",
      "        [0.0108, 0.0066, 0.0038, 0.4989, 0.0079, 0.0032, 0.0068, 0.3929, 0.0018,\n",
      "         0.0673]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0103, 0.0068, 0.0039, 0.5275, 0.0079, 0.0031, 0.0077, 0.3710, 0.0019,\n",
      "         0.0600],\n",
      "        [0.0106, 0.0067, 0.0038, 0.4955, 0.0079, 0.0031, 0.0073, 0.3975, 0.0019,\n",
      "         0.0657]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0124, 0.0067, 0.0040, 0.4664, 0.0080, 0.0032, 0.0067, 0.4246, 0.0017,\n",
      "        0.0662], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0129, 0.0065, 0.0040, 0.4361, 0.0081, 0.0032, 0.0063, 0.4535, 0.0017,\n",
      "         0.0677],\n",
      "        [0.0126, 0.0066, 0.0040, 0.4693, 0.0081, 0.0032, 0.0064, 0.4212, 0.0017,\n",
      "         0.0670]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0121, 0.0071, 0.0041, 0.4948, 0.0082, 0.0032, 0.0074, 0.3972, 0.0018,\n",
      "         0.0640],\n",
      "        [0.0122, 0.0068, 0.0040, 0.4638, 0.0080, 0.0032, 0.0070, 0.4278, 0.0017,\n",
      "         0.0654]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0105, 0.0068, 0.0038, 0.4984, 0.0076, 0.0030, 0.0075, 0.3918, 0.0017,\n",
      "        0.0689], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0108, 0.0063, 0.0036, 0.4676, 0.0074, 0.0030, 0.0066, 0.4210, 0.0016,\n",
      "         0.0721],\n",
      "        [0.0107, 0.0067, 0.0037, 0.4999, 0.0075, 0.0030, 0.0072, 0.3897, 0.0017,\n",
      "         0.0699]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0105, 0.0073, 0.0039, 0.5279, 0.0078, 0.0031, 0.0088, 0.3630, 0.0019,\n",
      "         0.0658],\n",
      "        [0.0104, 0.0069, 0.0038, 0.4971, 0.0076, 0.0030, 0.0079, 0.3937, 0.0017,\n",
      "         0.0678]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0131, 0.0065, 0.0041, 0.4775, 0.0088, 0.0035, 0.0064, 0.4202, 0.0019,\n",
      "        0.0581], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0133, 0.0065, 0.0041, 0.4393, 0.0089, 0.0035, 0.0062, 0.4543, 0.0019,\n",
      "         0.0621],\n",
      "        [0.0135, 0.0064, 0.0041, 0.4790, 0.0089, 0.0035, 0.0062, 0.4173, 0.0019,\n",
      "         0.0593]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0130, 0.0065, 0.0040, 0.5134, 0.0087, 0.0034, 0.0069, 0.3885, 0.0019,\n",
      "         0.0537],\n",
      "        [0.0128, 0.0065, 0.0040, 0.4762, 0.0088, 0.0035, 0.0067, 0.4227, 0.0019,\n",
      "         0.0569]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0131, 0.0082, 0.0044, 0.4409, 0.0094, 0.0036, 0.0089, 0.4389, 0.0023,\n",
      "        0.0702], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0130, 0.0079, 0.0042, 0.4053, 0.0091, 0.0035, 0.0082, 0.4746, 0.0022,\n",
      "         0.0721],\n",
      "        [0.0134, 0.0081, 0.0044, 0.4441, 0.0095, 0.0037, 0.0086, 0.4341, 0.0023,\n",
      "         0.0719]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0134, 0.0085, 0.0046, 0.4743, 0.0098, 0.0038, 0.0094, 0.4050, 0.0024,\n",
      "         0.0688],\n",
      "        [0.0128, 0.0084, 0.0044, 0.4382, 0.0094, 0.0036, 0.0092, 0.4430, 0.0023,\n",
      "         0.0687]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0109, 0.0069, 0.0038, 0.4946, 0.0077, 0.0032, 0.0083, 0.3966, 0.0019,\n",
      "        0.0662], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0110, 0.0065, 0.0037, 0.4635, 0.0075, 0.0032, 0.0072, 0.4267, 0.0017,\n",
      "         0.0690],\n",
      "        [0.0109, 0.0067, 0.0038, 0.4956, 0.0076, 0.0032, 0.0079, 0.3960, 0.0018,\n",
      "         0.0664]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0108, 0.0071, 0.0040, 0.5247, 0.0079, 0.0033, 0.0091, 0.3680, 0.0020,\n",
      "         0.0631],\n",
      "        [0.0109, 0.0070, 0.0039, 0.4937, 0.0078, 0.0033, 0.0087, 0.3969, 0.0019,\n",
      "         0.0660]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0101, 0.0055, 0.0032, 0.5148, 0.0067, 0.0030, 0.0060, 0.3838, 0.0017,\n",
      "        0.0653], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0112, 0.0055, 0.0033, 0.4832, 0.0072, 0.0031, 0.0057, 0.4113, 0.0018,\n",
      "         0.0677],\n",
      "        [0.0101, 0.0053, 0.0031, 0.5163, 0.0066, 0.0029, 0.0057, 0.3819, 0.0016,\n",
      "         0.0664]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0097, 0.0057, 0.0031, 0.5405, 0.0065, 0.0029, 0.0067, 0.3598, 0.0017,\n",
      "         0.0634],\n",
      "        [0.0101, 0.0056, 0.0032, 0.5131, 0.0068, 0.0030, 0.0064, 0.3862, 0.0017,\n",
      "         0.0637]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0125, 0.0073, 0.0040, 0.4928, 0.0086, 0.0033, 0.0075, 0.4006, 0.0022,\n",
      "        0.0612], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0127, 0.0071, 0.0040, 0.4575, 0.0086, 0.0033, 0.0070, 0.4344, 0.0021,\n",
      "         0.0633],\n",
      "        [0.0129, 0.0072, 0.0040, 0.4955, 0.0087, 0.0033, 0.0072, 0.3963, 0.0021,\n",
      "         0.0627]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0124, 0.0075, 0.0041, 0.5244, 0.0087, 0.0033, 0.0082, 0.3698, 0.0022,\n",
      "         0.0594],\n",
      "        [0.0122, 0.0074, 0.0040, 0.4907, 0.0085, 0.0033, 0.0079, 0.4039, 0.0022,\n",
      "         0.0598]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0114, 0.0068, 0.0038, 0.5034, 0.0079, 0.0031, 0.0072, 0.3927, 0.0020,\n",
      "        0.0617], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0121, 0.0069, 0.0040, 0.4697, 0.0082, 0.0032, 0.0068, 0.4226, 0.0019,\n",
      "         0.0648],\n",
      "        [0.0116, 0.0067, 0.0038, 0.5048, 0.0079, 0.0031, 0.0070, 0.3903, 0.0019,\n",
      "         0.0628]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0109, 0.0067, 0.0037, 0.5351, 0.0077, 0.0030, 0.0076, 0.3640, 0.0020,\n",
      "         0.0593],\n",
      "        [0.0113, 0.0069, 0.0038, 0.5023, 0.0079, 0.0031, 0.0074, 0.3947, 0.0020,\n",
      "         0.0606]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0110, 0.0067, 0.0035, 0.5060, 0.0074, 0.0030, 0.0066, 0.3894, 0.0019,\n",
      "        0.0644], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0112, 0.0064, 0.0034, 0.4759, 0.0073, 0.0029, 0.0057, 0.4188, 0.0018,\n",
      "         0.0666],\n",
      "        [0.0112, 0.0066, 0.0035, 0.5095, 0.0075, 0.0030, 0.0063, 0.3851, 0.0019,\n",
      "         0.0654]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0110, 0.0071, 0.0037, 0.5363, 0.0077, 0.0031, 0.0076, 0.3598, 0.0020,\n",
      "         0.0617],\n",
      "        [0.0109, 0.0068, 0.0036, 0.5030, 0.0074, 0.0030, 0.0069, 0.3933, 0.0019,\n",
      "         0.0632]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0119, 0.0065, 0.0036, 0.5324, 0.0085, 0.0033, 0.0063, 0.3663, 0.0020,\n",
      "        0.0591], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0123, 0.0065, 0.0037, 0.4984, 0.0086, 0.0033, 0.0061, 0.3974, 0.0020,\n",
      "         0.0618],\n",
      "        [0.0120, 0.0063, 0.0036, 0.5345, 0.0084, 0.0033, 0.0061, 0.3639, 0.0020,\n",
      "         0.0600]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0116, 0.0064, 0.0035, 0.5638, 0.0084, 0.0032, 0.0066, 0.3383, 0.0021,\n",
      "         0.0561],\n",
      "        [0.0118, 0.0066, 0.0036, 0.5306, 0.0085, 0.0033, 0.0067, 0.3687, 0.0021,\n",
      "         0.0582]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0118, 0.0063, 0.0038, 0.5137, 0.0080, 0.0034, 0.0072, 0.3701, 0.0019,\n",
      "        0.0738], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0128, 0.0063, 0.0039, 0.4759, 0.0083, 0.0035, 0.0068, 0.4021, 0.0019,\n",
      "         0.0784],\n",
      "        [0.0117, 0.0062, 0.0037, 0.5164, 0.0079, 0.0034, 0.0068, 0.3681, 0.0019,\n",
      "         0.0739]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0111, 0.0063, 0.0038, 0.5456, 0.0078, 0.0033, 0.0074, 0.3430, 0.0019,\n",
      "         0.0698],\n",
      "        [0.0119, 0.0064, 0.0039, 0.5111, 0.0081, 0.0034, 0.0075, 0.3721, 0.0020,\n",
      "         0.0736]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0128, 0.0070, 0.0043, 0.4840, 0.0087, 0.0034, 0.0078, 0.4013, 0.0021,\n",
      "        0.0686], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0129, 0.0069, 0.0042, 0.4468, 0.0088, 0.0034, 0.0072, 0.4364, 0.0020,\n",
      "         0.0715],\n",
      "        [0.0129, 0.0069, 0.0043, 0.4868, 0.0087, 0.0034, 0.0075, 0.3981, 0.0020,\n",
      "         0.0693]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0127, 0.0072, 0.0043, 0.5184, 0.0086, 0.0034, 0.0085, 0.3693, 0.0021,\n",
      "         0.0654],\n",
      "        [0.0127, 0.0072, 0.0043, 0.4815, 0.0087, 0.0034, 0.0081, 0.4042, 0.0021,\n",
      "         0.0678]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0122, 0.0065, 0.0037, 0.5185, 0.0087, 0.0033, 0.0073, 0.3833, 0.0021,\n",
      "        0.0542], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0127, 0.0067, 0.0037, 0.4815, 0.0087, 0.0033, 0.0071, 0.4172, 0.0022,\n",
      "         0.0569],\n",
      "        [0.0123, 0.0064, 0.0037, 0.5212, 0.0086, 0.0033, 0.0071, 0.3803, 0.0021,\n",
      "         0.0551]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0115, 0.0064, 0.0037, 0.5525, 0.0085, 0.0033, 0.0075, 0.3540, 0.0021,\n",
      "         0.0506],\n",
      "        [0.0121, 0.0067, 0.0038, 0.5161, 0.0087, 0.0033, 0.0076, 0.3862, 0.0022,\n",
      "         0.0533]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0126, 0.0085, 0.0044, 0.4834, 0.0097, 0.0035, 0.0093, 0.4128, 0.0024,\n",
      "        0.0533], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0127, 0.0081, 0.0043, 0.4491, 0.0094, 0.0033, 0.0084, 0.4473, 0.0022,\n",
      "         0.0550],\n",
      "        [0.0128, 0.0084, 0.0044, 0.4850, 0.0097, 0.0035, 0.0090, 0.4111, 0.0024,\n",
      "         0.0538]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0124, 0.0088, 0.0046, 0.5174, 0.0098, 0.0036, 0.0104, 0.3789, 0.0025,\n",
      "         0.0515],\n",
      "        [0.0125, 0.0087, 0.0045, 0.4820, 0.0096, 0.0035, 0.0096, 0.4143, 0.0024,\n",
      "         0.0528]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0126, 0.0069, 0.0041, 0.5078, 0.0088, 0.0033, 0.0077, 0.3795, 0.0021,\n",
      "        0.0672], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0131, 0.0068, 0.0041, 0.4717, 0.0088, 0.0033, 0.0072, 0.4143, 0.0020,\n",
      "         0.0688],\n",
      "        [0.0127, 0.0068, 0.0041, 0.5104, 0.0087, 0.0033, 0.0075, 0.3764, 0.0021,\n",
      "         0.0680]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0119, 0.0069, 0.0041, 0.5405, 0.0086, 0.0033, 0.0077, 0.3496, 0.0022,\n",
      "         0.0651],\n",
      "        [0.0124, 0.0070, 0.0042, 0.5057, 0.0088, 0.0033, 0.0078, 0.3825, 0.0022,\n",
      "         0.0662]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha tensor([348.4525,   0.0000,   0.0000], device='cuda:0', requires_grad=True)\n",
      "tensor([0., 0.], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.0124, 0.0058, 0.0037, 0.5220, 0.0081, 0.0032, 0.0066, 0.3704, 0.0017,\n",
      "        0.0662], device='cuda:0', grad_fn=<DivBackward0>) tensor([[0.0126, 0.0058, 0.0037, 0.4832, 0.0081, 0.0031, 0.0058, 0.4070, 0.0017,\n",
      "         0.0690],\n",
      "        [0.0124, 0.0057, 0.0036, 0.5231, 0.0080, 0.0031, 0.0063, 0.3689, 0.0017,\n",
      "         0.0672]], device='cuda:0', grad_fn=<StackBackward>) tensor([[0.0118, 0.0058, 0.0036, 0.5568, 0.0078, 0.0030, 0.0071, 0.3395, 0.0018,\n",
      "         0.0628],\n",
      "        [0.0124, 0.0060, 0.0037, 0.5210, 0.0082, 0.0032, 0.0068, 0.3719, 0.0018,\n",
      "         0.0651]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "shape_norm_sigma tensor([0.0500, 0.0200], device='cuda:0')\n",
      "Norms shape tensor([1., 1.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2: Train=917.0727612304687 Valid=927.6888003141984\n"
     ]
    }
   ],
   "source": [
    "model_inferno.fit(2, data=data, opt=partialler(optim.Adam,lr=1e-3), loss=None,\n",
    "                  cbs=[HEPInferno(b_true=qcd, mu_true=mu, n_shape_alphas=2, shape_norm_sigma=shape_norm_sigma), lt])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a54c1",
   "metadata": {},
   "source": [
    "## 5. Test with CMS Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f426b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_cmsopen\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27fb98fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu 348.45252731445095\n",
      "QCD 2689.5053333309675\n",
      "jes_06 16.70084248968277\n",
      "taue 11.82024566892062\n",
      "btag 4.612317868087416\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#features = ['ht', 'aplanarity', 'sphericity', 'chargeEta', 'MET_met', 'deltaPhiTauMet', 'mt', 'mTauJet']\n",
    "features = ['aplanarity', 'chargeEta', 'MET_met', 'deltaPhiTauMet']\n",
    "shape_syst = [\"06_jes\", \"taue\"]\n",
    "weight_syst = [\"btag_weight1\"]\n",
    "norm_syst = [\"jes_06\", \"taue\", \"btag_weight1\"]\n",
    "use_weights = False\n",
    "\n",
    "mu, qcd, sig_norm = run_cmsopen.get_norm(norm_syst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "af37ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for INFERNO training\n",
    "inferno_args = {}\n",
    "# Signal and bkg\n",
    "inferno_args[\"b_true\"] = qcd\n",
    "inferno_args[\"mu_true\"] = mu\n",
    "# Number of shape nuisances\n",
    "inferno_args[\"n_shape_alphas\"] = len(shape_syst) + len(weight_syst)\n",
    "# Constraints on the nuisance parameters - typically should be N(0,1) if +-1sigma templates are provided\n",
    "inferno_args[\"shape_aux\"] = [Normal(0,1) for i in range(len(shape_syst) + len(weight_syst))]\n",
    "# Uncertainties on signal norm - should be Normal(0,s) with s in absolute event numbers\n",
    "inferno_args[\"s_norm_aux\"] = sig_norm #[Normal(0,10), Normal(0,10), Normal(0,10)]\n",
    "# Boolean whether to let the background float\n",
    "inferno_args[\"nonaux_b_norm\"] = False\n",
    "\n",
    "train_args = {}\n",
    "train_args[\"lr\"] = 1e-3\n",
    "train_args[\"n_feats\"] = len(features)\n",
    "train_args[\"neurons\"] = 100\n",
    "train_args[\"bins\"] = 10\n",
    "train_args[\"temperature\"] = 0.1\n",
    "train_args[\"weights\"] = False\n",
    "\n",
    "OUTPATH = \"/home/centos/data/inferno_cmsopen13\"\n",
    "\n",
    "bs = 1000\n",
    "n_sig = 20000\n",
    "epochs = 200\n",
    "\n",
    "store = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5170c946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************\n",
      "Summary training data\n",
      "Features ['aplanarity', 'chargeEta', 'MET_met', 'deltaPhiTauMet']\n",
      "Shape systematics ['06_jes', 'taue']\n",
      "Weight systematics ['btag_weight1']\n",
      "Use weights False\n",
      "Number of signal training / test events: 20000 23570\n",
      "Number of bkg training / test events: 5000 6176\n",
      "*********************\n"
     ]
    }
   ],
   "source": [
    "data = run_cmsopen.train(OUTPATH, features = features, \n",
    "                                        shape_syst = shape_syst,\n",
    "                                        weight_syst = weight_syst,\n",
    "                                        norm_syst = norm_syst, \n",
    "                                        epochs=epochs, bs=bs, n_sig=n_sig, \n",
    "                                        inferno_args = inferno_args, \n",
    "                                        train_args = train_args,\n",
    "                                        use_weights = use_weights,\n",
    "                                        store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dea63f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, autograd, nn, Tensor\n",
    "from pytorch_inferno.callback import *\n",
    "from pytorch_inferno.utils import *\n",
    "from pytorch_inferno.model_wrapper import ModelWrapper\n",
    "from fastcore.all import partialler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c51aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network\n",
    "net_inferno = nn.Sequential(nn.Linear(4,100),  nn.ReLU(),\n",
    "                nn.Linear(100,100), nn.ReLU(),\n",
    "                nn.Linear(100,10), VariableSoftmax(0.1))\n",
    "lt = LossTracker()\n",
    "#init_net(net_inferno)\n",
    "model_inferno = ModelWrapper(net_inferno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac4784c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_norm_sigma = [0.05, 0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02b8535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************\n",
      "Summary INFERNO setup\n",
      "b_true 2689.5053333309675\n",
      "mu_true 348.45252731445095\n",
      "nshape_alphas 2\n",
      "shape idx [1, 2]\n",
      "shape_aux None\n",
      "s_norm_aux []\n",
      "shape_norm_sigma [0.05, 0.02]\n",
      "n_alpha 3\n",
      "*********************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "legacy constructor expects device type: cpubut device type: cuda was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e2738708bcf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_inferno.fit(2, data=data, opt=partialler(optim.Adam,lr=1e-3), loss=None,\n\u001b[0;32m----> 2\u001b[0;31m                   cbs=[HEPInferno(b_true=qcd, mu_true=mu, n_shape_alphas=2, shape_norm_sigma=shape_norm_sigma), lt])  \n\u001b[0m",
      "\u001b[0;32m~/dev/pytorch_inferno/pytorch_inferno/model_wrapper.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epochs, data, opt, loss, cbs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-1a41af01d59c>\u001b[0m in \u001b[0;36mon_train_begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss_is_meaned'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_is_meaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# Ensure that average losses are correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_norm_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_norm_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_up_down\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: legacy constructor expects device type: cpubut device type: cuda was passed"
     ]
    }
   ],
   "source": [
    "model_inferno.fit(2, data=data, opt=partialler(optim.Adam,lr=1e-3), loss=None,\n",
    "                  cbs=[HEPInferno(b_true=qcd, mu_true=mu, n_shape_alphas=2, shape_norm_sigma=shape_norm_sigma), lt])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958567f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3a6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
